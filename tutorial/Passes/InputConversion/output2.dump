// -----// IR Dump After CheckVHLOStableHloMixUsage (iree-check-vhlostablehlo-mix-usage) //----- //
module {
  func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
    %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
    %2 = shape.add %0, %1 : index, index -> index
    return %2 : index
  }
}


// -----// IR Dump After VhloToVersionPass (vhlo-to-version) //----- //
module {
  func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
    %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
    %2 = shape.add %0, %1 : index, index -> index
    return %2 : index
  }
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) //----- //
module {
  func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
    %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
    %2 = shape.add %0, %1 : index, index -> index
    return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
  %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
  %2 = shape.add %0, %1 : index, index -> index
  return %2 : index
}

// -----// IR Dump After StableHLOCanonicalize (iree-stablehlo-canonicalize) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
  %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
  %2 = shape.add %0, %1 : index, index -> index
  return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
  %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
  %2 = shape.add %0, %1 : index, index -> index
  return %2 : index
}

// -----// IR Dump After LegalizeStableHLOCustomCalls (iree-stablehlo-legalize-custom-calls) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
  %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
  %2 = shape.add %0, %1 : index, index -> index
  return %2 : index
}

// -----// IR Dump After LegalizeControlFlow (iree-stablehlo-legalize-control-flow) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
  %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
  %2 = shape.add %0, %1 : index, index -> index
  return %2 : index
}

// -----// IR Dump After FlattenTuplesInSCF (iree-stablehlo-preprocessing-flatten-scf-tuples) //----- //
module {
  func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
    %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
    %2 = shape.add %0, %1 : index, index -> index
    return %2 : index
  }
}


// -----// IR Dump After StableHLOToStableHLOPreprocessing (iree-stablehlo-to-stablehlo-preprocessing) //----- //
module {
  func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
    %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
    %2 = shape.add %0, %1 : index, index -> index
    return %2 : index
  }
}


// -----// IR Dump After StableHLOCanonicalize (iree-stablehlo-canonicalize) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
  %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
  %2 = shape.add %0, %1 : index, index -> index
  return %2 : index
}

// -----// IR Dump After ShapeToShapeLowering (shape-to-shape-lowering) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = shape.dim %arg0, %c1 : tensor<1x?xf32>, index -> index
  %1 = shape.dim %arg1, %c0 : tensor<?xf32>, index -> index
  %2 = shape.add %0, %1 : index, index -> index
  return %2 : index
}

// -----// IR Dump After ConvertShapeToStandard (convert-shape-to-std) //----- //
module {
  func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c1_0 = arith.constant 1 : index
    %c1_1 = arith.constant 1 : index
    %dim = tensor.dim %arg0, %c1_1 : tensor<1x?xf32>
    %from_elements = tensor.from_elements %c1_0, %dim : tensor<2xindex>
    %cast = tensor.cast %from_elements : tensor<2xindex> to tensor<2xindex>
    %dim_2 = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %c0_3 = arith.constant 0 : index
    %dim_4 = tensor.dim %arg1, %c0_3 : tensor<?xf32>
    %from_elements_5 = tensor.from_elements %dim_4 : tensor<1xindex>
    %cast_6 = tensor.cast %from_elements_5 : tensor<1xindex> to tensor<1xindex>
    %dim_7 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim_2, %dim_7 : index
    return %0 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After StableHLOCanonicalize (iree-stablehlo-canonicalize) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After Inliner (inline) //----- //
module {
  func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    return %0 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After StableHLOCanonicalize (iree-stablehlo-canonicalize) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After CSE (cse) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After LegalizeShapeComputations (iree-stablehlo-legalize-shape-computations) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After ConvertStableHloToLinalgExt (iree-stablehlo-to-linalg-ext) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After LegalizeChlo (iree-stablehlo-legalize-chlo) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After ConvertStableHloToIreeInputDialects (iree-stablehlo-to-iree-input) //----- //
module {
  func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    return %0 : index
  }
}


// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
module {
  func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    return %0 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After StableHLOCanonicalize (iree-stablehlo-canonicalize) //----- //
func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  return %0 : index
}

// -----// IR Dump After VerifyCompilerStableHloInputLegality (iree-stablehlo-verify-compiler-input-legality) //----- //
module {
  func.func @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    return %0 : index
  }
}


// -----// IR Dump After IREEImportPublicPass (iree-import-public) //----- //
module {
  util.func public @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    util.return %0 : index
  }
}


// -----// IR Dump After ImportMLProgramPass (iree-import-ml-program) //----- //
module {
  util.func public @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    util.return %0 : index
  }
}


// -----// IR Dump After SanitizeModuleNamesPass (iree-sanitize-module-names) //----- //
module {
  util.func public @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    util.return %0 : index
  }
}


// -----// IR Dump After ConvertMeshToFlowPass (iree-convert-mesh-to-flow) //----- //
module {
  util.func public @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    util.return %0 : index
  }
}


// -----// IR Dump After DemoteF64ToF32Pass (iree-input-conversion-demote-f64-to-f32) //----- //
module {
  util.func public @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    util.return %0 : index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::ConvertStreamableOpsPass (iree-abi-convert-streamable-ops) //----- //
module {
  util.func public @test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    util.return %0 : index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::WrapEntryPointsPass (iree-abi-wrap-entry-points) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<1x?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = util.call @_test(%1, %3) : (tensor<1x?xf32>, tensor<?xf32>) -> index
    util.return %4 : index
  }
  util.func private @_test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
    %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
    %0 = arith.addi %dim, %dim_0 : index
    util.return %0 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @_test(%arg0: tensor<1x?xf32>, %arg1: tensor<?xf32>) -> index {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c1 : tensor<1x?xf32>
  %dim_0 = tensor.dim %arg1, %c0 : tensor<?xf32>
  %0 = arith.addi %dim, %dim_0 : index
  util.return %0 : index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<1x?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = util.call @_test(%1, %3) : (tensor<1x?xf32>, tensor<?xf32>) -> index
  util.return %4 : index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After Inliner (inline) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After AssignLegacyTargetDevicesPass (iree-hal-assign-legacy-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {hal.device.targets = [#device_target_cuda]} {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After MaterializeTargetDevicesPass (iree-hal-materialize-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ResolveDevicePromisesPass (iree-hal-resolve-device-promises) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ResolveDeviceAliasesPass (iree-hal-resolve-device-aliases) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After LinalgQuantizedConvToConvPass (iree-global-opt-quantized-conv-to-conv) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After LinalgQuantizedMatmulToMatmulPass (iree-global-opt-quantized-matmul-to-matmul) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After RemoveZeroExtentTensorsPass (iree-global-opt-remove-zero-extent-tensors) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After DetachElementwiseFromNamedOpsPass (iree-global-opt-detach-elementwise-from-named-ops) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After LinalgNamedOpConversionPass (linalg-named-op-conversion) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After EraseUnusedLinalgOperandsPass (iree-global-opt-erase-unused-linalg-operands) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ExpandTensorShapesPass (iree-global-opt-expand-tensor-shapes) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ConvertElementwiseToLinalgPass (convert-elementwise-to-linalg) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After RaiseSpecialOpsPass (iree-global-opt-raise-special-ops) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After DecomposeConcatPass (iree-global-opt-decompose-concat) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After GeneralizeLinalgNamedOpsPass (iree-global-opt-generalize-linalg-named-ops) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldUnitExtentDimsPass (iree-dispatch-creation-fold-unit-extent-dims) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After DemoteContractionInputsToBF16Pass (iree-global-opt-demote-contraction-inputs-to-bf16) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SetEncodingPass (iree-dispatch-creation-set-encoding) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After MaterializeEncodingIntoNopPass (iree-codegen-materialize-encoding-into-nop) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After MaterializeHomogeneousEncodingsPass (iree-global-opt-materialize-homogeneous-encodings) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After SimplifyPackUnpackPass (iree-global-opt-simplify-pack-unpack) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After DataLayoutPropagationPass (iree-global-opt-data-layout-propagation) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After GeneralizeLinalgNamedOpsPass (iree-global-opt-generalize-linalg-named-ops) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After GlobalLoopInvariantCodeMotionPass (iree-global-opt-loop-invariant-code-motion) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After HoistIntoGlobals (iree-util-hoist-into-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After JitGlobalsPass (iree-consteval-jit-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After RaiseSpecialOpsPass (iree-global-opt-raise-special-ops) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After InjectTensorTracingPass (iree-flow-inject-tensor-tracing) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After TensorPadToTensorInsertSlicePass (iree-dispatch-creation-tensor-pad-to-tensor-insert-slice) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FusionPreprocessingPass (iree-dispatch-creation-fusion-preprocessing) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After BubbleUpExpandShapesPass (iree-dispatch-creation-bubble-up-expand-shapes) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After BubbleUpExtractSlicesPass (iree-dispatch-creation-bubble-up-extract-slices) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SinkReshapesPass (iree-dispatch-creation-sink-reshapes) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FuseMultiUseElementwiseProducerPass (iree-dispatch-creation-fuse-multi-use-elementwise-producer) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SplitReductionPass (iree-dispatch-creation-split-reduction-ops) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After TransposeGenericOpsPass (iree-dispatch-creation-transpose-generic-ops) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FormScalarDispatchesPass (iree-dispatch-creation-form-scalar-dispatches) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FormDispatchRegionsPass (iree-dispatch-creation-form-dispatch-regions) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CloneProducersIntoDispatchRegionsPass (iree-dispatch-creation-clone-producers-into-dispatch-regions) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CollapseDimensionsPass (iree-dispatch-creation-collapse-dimensions) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ConvertDispatchRegionsToWorkgroupsPass (iree-dispatch-creation-convert-dispatch-regions-to-workgroups) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ConvertTensorToFlowPass (iree-dispatch-creation-convert-tensor-to-flow) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After MaterializeDefaultWorkgroupCountRegionPass (iree-dispatch-creation-materialize-default-workgroup-count-region) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After VerifyInputLegalityPass (iree-verify-input-legality) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After CaptureDynamicDimsPass (iree-flow-capture-dynamic-dims) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After InitializeEmptyTensorsPass (iree-flow-initialize-empty-tensors) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OutlineDispatchExternsPass (iree-flow-outline-dispatch-externs) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After OutlineDispatchRegionsPass (iree-flow-outline-dispatch-regions) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After AnnotateDispatchesPass (iree-flow-annotate-dispatches) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After DeduplicateExecutablesPass (iree-flow-deduplicate-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After InjectTensorTracingPass (iree-flow-inject-tensor-tracing) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CleanupTensorShapesPass (iree-flow-cleanup-tensor-shapes) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OutlineConstantsPass (iree-flow-outline-constants) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After VerifyInputPass (iree-stream-verify-input) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ConvertToStreamPass (iree-stream-conversion) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After VerifyLoweringToTensorsPass (iree-stream-verify-lowering-to-tensors) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After EncodeHostTensorsPass (iree-stream-encode-host-tensors) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After VerifyLoweringToAsyncResourcesPass (iree-stream-verify-lowering-to-async-resources) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After MaterializeCopyOnWritePass (iree-stream-materialize-copy-on-write) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ElideAsyncCopiesPass (iree-stream-elide-async-copies) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After EmplaceAllocationsPass (iree-stream-emplace-allocations) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After RefineUsagePass (iree-stream-refine-usage) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After VerifyAsyncAccessRangesPass (iree-stream-verify-async-access-ranges) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ScheduleExecutionPass (iree-stream-schedule-execution) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ScheduleConcurrencyPass (iree-stream-schedule-concurrency) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After PropagateTimepointsPass (iree-stream-propagate-timepoints) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After MaterializeBuiltinsPass (iree-stream-materialize-builtins) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After VerifyLoweringToAsyncPass (iree-stream-verify-lowering-to-async) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ScheduleAllocationPass (iree-stream-schedule-allocation) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After PackConstantsPass (iree-stream-pack-constants) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After LayoutSlicesPass (iree-stream-layout-slices) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After VerifyLoweringToCmdPass (iree-stream-verify-lowering-to-cmd) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ElideTimepointsPass (iree-stream-elide-timepoints) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseDispatchBindingsPass (iree-stream-fuse-dispatch-bindings) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After AnnotateDispatchArgumentsPass (iree-stream-annotate-dispatch-arguments) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After AnnotateDispatchAssumptionsPass (iree-stream-annotate-dispatch-assumptions) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After PackDispatchOperandsPass (iree-stream-pack-dispatch-operands) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FoldUniformOperandsPass (iree-stream-fold-uniform-operands) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After AssignLegacyTargetDevicesPass (iree-hal-assign-legacy-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After MaterializeTargetDevicesPass (iree-hal-materialize-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ResolveDevicePromisesPass (iree-hal-resolve-device-promises) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ResolveDeviceAliasesPass (iree-hal-resolve-device-aliases) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After MaterializeInterfacesPass (iree-hal-materialize-interfaces) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After PruneExecutablesPass (iree-hal-prune-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ConvertToHALPass (iree-hal-conversion) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After OutlineMemoizeRegionsPass (iree-hal-outline-memoize-regions) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FixupLegacySyncPass (iree-hal-fixup-legacy-sync) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After PruneExecutablesPass (iree-hal-prune-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After LinkExecutablesPass (iree-hal-link-executables) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ResolveExportOrdinalsPass (iree-hal-resolve-export-ordinals) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After MaterializeResourceCachesPass (iree-hal-materialize-resource-caches) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After MemoizeDeviceQueriesPass (iree-hal-memoize-device-queries) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After InitializeDevicesPass (iree-hal-initialize-devices) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After AffineExpandIndexOps (affine-expand-index-ops) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After PruneExecutablesPass (iree-hal-prune-executables) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After Inliner (inline) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After AffineExpandIndexOps (affine-expand-index-ops) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %2 = arith.addi %0, %1 : index
  util.return %2 : index
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
module {
  util.func public @test(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> index attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %1 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %2 = arith.addi %0, %1 : index
    util.return %2 : index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ConversionPass (iree-vm-conversion) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
    vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
    vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %zero = vm.const.i32.zero
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ReifyRodataTablesPass (iree-vm-reify-rodata-tables) //----- //
vm.module public @module {
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %zero = vm.const.i32.zero
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::HoistInlinedRodataPass (iree-vm-hoist-inlined-rodata) //----- //
vm.module public @module {
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %zero = vm.const.i32.zero
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DeduplicateRodataPass (iree-vm-deduplicate-rodata) //----- //
vm.module public @module {
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %zero = vm.const.i32.zero
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropUnusedCallsPass (iree-vm-drop-unused-calls) //----- //
vm.module public @module {
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ResolveRodataLoadsPass (iree-vm-resolve-rodata-loads) //----- //
vm.module public @module {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %zero = vm.const.i32.zero
  %c1 = vm.const.i32 1
  %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %2 = vm.add.i64 %0, %1 : i64
  vm.return %2 : i64
}

// -----// IR Dump After Inliner (inline) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropUnusedCallsPass (iree-vm-drop-unused-calls) //----- //
vm.module public @module {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @module {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  vm.export @__init
  vm.func private @__init() {
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
    vm.export @__init
    vm.func private @__init() {
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After CSE (cse) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
    vm.export @__init
    vm.func private @__init() {
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
    vm.export @__init
    vm.func private @__init() {
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @module {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %2 = vm.add.i64 %0, %1 : i64
      vm.return %2 : i64
    }
    vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @module {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
  vm.export @__init
  vm.func private @__init() {
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @module {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
  %zero = vm.const.i32.zero
  %c1 = vm.const.i32 1
  %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %2 = vm.add.i64 %0, %1 : i64
  vm.return %2 : i64
}

// -----// IR Dump After Inliner (inline) //----- //
vm.module public @module {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After CSE (cse) //----- //
vm.module public @module {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.module public @module {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
vm.module public @module {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::OrdinalAllocationPass (iree-vm-ordinal-allocation) //----- //
vm.module public @module attributes {ordinal_counts = #vm.ordinal_counts<import_funcs = 1, export_funcs = 1, internal_funcs = 1, global_bytes = 0, global_refs = 0, rodatas = 0, rwdatas = 0>} {
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, ordinal = 0 : i32}
  vm.func private @test(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> i64 attributes {iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}, ordinal = 0 : i32} {
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %0 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %2 = vm.add.i64 %0, %1 : i64
    vm.return %2 : i64
  }
  vm.export @test attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @test(%input0: tensor<1x?xf32>, %input1: tensor<?xf32>) -> (%output0: index)"}, ordinal = 0 : i32}
}

