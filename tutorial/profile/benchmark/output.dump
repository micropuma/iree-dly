// -----// IR Dump After AutoInputConversionPipelinePass (iree-auto-input-conversion) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  func.func @foo(%arg0: tensor<?xf32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?xf32>
    %0 = tensor.empty(%dim) : tensor<?xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%arg0, %arg1 : tensor<?xf32>, tensor<?xf32>) outs(%0 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<?xf32>
    return %1 : tensor<?xf32>
  }
}


// -----// IR Dump After IREEImportPublicPass (iree-import-public) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @foo(%arg0: tensor<?xf32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?xf32>
    %0 = tensor.empty(%dim) : tensor<?xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%arg0, %arg1 : tensor<?xf32>, tensor<?xf32>) outs(%0 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<?xf32>
    util.return %1 : tensor<?xf32>
  }
}


// -----// IR Dump After ImportMLProgramPass (iree-import-ml-program) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @foo(%arg0: tensor<?xf32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?xf32>
    %0 = tensor.empty(%dim) : tensor<?xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%arg0, %arg1 : tensor<?xf32>, tensor<?xf32>) outs(%0 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<?xf32>
    util.return %1 : tensor<?xf32>
  }
}


// -----// IR Dump After SanitizeModuleNamesPass (iree-sanitize-module-names) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @foo(%arg0: tensor<?xf32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?xf32>
    %0 = tensor.empty(%dim) : tensor<?xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%arg0, %arg1 : tensor<?xf32>, tensor<?xf32>) outs(%0 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<?xf32>
    util.return %1 : tensor<?xf32>
  }
}


// -----// IR Dump After ConvertMeshToFlowPass (iree-convert-mesh-to-flow) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @foo(%arg0: tensor<?xf32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?xf32>
    %0 = tensor.empty(%dim) : tensor<?xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%arg0, %arg1 : tensor<?xf32>, tensor<?xf32>) outs(%0 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<?xf32>
    util.return %1 : tensor<?xf32>
  }
}


// -----// IR Dump After DemoteF64ToF32Pass (iree-input-conversion-demote-f64-to-f32) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @foo(%arg0: tensor<?xf32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?xf32>
    %0 = tensor.empty(%dim) : tensor<?xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%arg0, %arg1 : tensor<?xf32>, tensor<?xf32>) outs(%0 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<?xf32>
    util.return %1 : tensor<?xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::ConvertStreamableOpsPass (iree-abi-convert-streamable-ops) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @foo(%arg0: tensor<?xf32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?xf32>
    %0 = tensor.empty(%dim) : tensor<?xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%arg0, %arg1 : tensor<?xf32>, tensor<?xf32>) outs(%0 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<?xf32>
    util.return %1 : tensor<?xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::WrapEntryPointsPass (iree-abi-wrap-entry-points) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = util.call @_foo(%1, %3) : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %4, %c0 : tensor<?xf32>
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%dim} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
  util.func private @_foo(%arg0: tensor<?xf32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?xf32>
    %0 = tensor.empty(%dim) : tensor<?xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%arg0, %arg1 : tensor<?xf32>, tensor<?xf32>) outs(%0 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<?xf32>
    util.return %1 : tensor<?xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @_foo(%arg0: tensor<?xf32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c0 : tensor<?xf32>
  %0 = tensor.empty(%dim) : tensor<?xf32>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%arg0, %arg1 : tensor<?xf32>, tensor<?xf32>) outs(%0 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.addf %in, %in_0 : f32
    linalg.yield %2 : f32
  } -> tensor<?xf32>
  util.return %1 : tensor<?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = util.call @_foo(%1, %3) : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>
  %dim = tensor.dim %4, %c0 : tensor<?xf32>
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%dim} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After AssignLegacyTargetDevicesPass (iree-hal-assign-legacy-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {hal.device.targets = [#device_target_cuda]} {
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeTargetDevicesPass (iree-hal-materialize-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDevicePromisesPass (iree-hal-resolve-device-promises) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDeviceAliasesPass (iree-hal-resolve-device-aliases) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After LinalgQuantizedConvToConvPass (iree-global-opt-quantized-conv-to-conv) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After LinalgQuantizedMatmulToMatmulPass (iree-global-opt-quantized-matmul-to-matmul) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After RemoveZeroExtentTensorsPass (iree-global-opt-remove-zero-extent-tensors) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After DetachElementwiseFromNamedOpsPass (iree-global-opt-detach-elementwise-from-named-ops) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After LinalgNamedOpConversionPass (linalg-named-op-conversion) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After EraseUnusedLinalgOperandsPass (iree-global-opt-erase-unused-linalg-operands) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ExpandTensorShapesPass (iree-global-opt-expand-tensor-shapes) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertElementwiseToLinalgPass (convert-elementwise-to-linalg) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOpsPass (iree-global-opt-raise-special-ops) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After DecomposeConcatPass (iree-global-opt-decompose-concat) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After GeneralizeLinalgNamedOpsPass (iree-global-opt-generalize-linalg-named-ops) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldUnitExtentDimsPass (iree-dispatch-creation-fold-unit-extent-dims) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After DemoteContractionInputsToBF16Pass (iree-global-opt-demote-contraction-inputs-to-bf16) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SetEncodingPass (iree-dispatch-creation-set-encoding) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After MaterializeEncodingIntoNopPass (iree-codegen-materialize-encoding-into-nop) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After MaterializeHomogeneousEncodingsPass (iree-global-opt-materialize-homogeneous-encodings) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyPackUnpackPass (iree-global-opt-simplify-pack-unpack) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After DataLayoutPropagationPass (iree-global-opt-data-layout-propagation) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After GeneralizeLinalgNamedOpsPass (iree-global-opt-generalize-linalg-named-ops) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After GlobalLoopInvariantCodeMotionPass (iree-global-opt-loop-invariant-code-motion) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After HoistIntoGlobals (iree-util-hoist-into-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After JitGlobalsPass (iree-consteval-jit-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOpsPass (iree-global-opt-raise-special-ops) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After InjectTensorTracingPass (iree-flow-inject-tensor-tracing) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After TensorPadToTensorInsertSlicePass (iree-dispatch-creation-tensor-pad-to-tensor-insert-slice) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = tensor.empty(%0) : tensor<?xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<?xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FusionPreprocessingPass (iree-dispatch-creation-fusion-preprocessing) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After BubbleUpExpandShapesPass (iree-dispatch-creation-bubble-up-expand-shapes) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After BubbleUpExtractSlicesPass (iree-dispatch-creation-bubble-up-extract-slices) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SinkReshapesPass (iree-dispatch-creation-sink-reshapes) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FuseMultiUseElementwiseProducerPass (iree-dispatch-creation-fuse-multi-use-elementwise-producer) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SplitReductionPass (iree-dispatch-creation-split-reduction-ops) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After TransposeGenericOpsPass (iree-dispatch-creation-transpose-generic-ops) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FormScalarDispatchesPass (iree-dispatch-creation-form-scalar-dispatches) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<?xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchRegionsPass (iree-dispatch-creation-form-dispatch-regions) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = tensor.empty(%0) : tensor<?xf32>
  %5 = flow.dispatch.region -> (tensor<?xf32>{%0}) {
    %7 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%4 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %8 = arith.addf %in, %in_0 : f32
      linalg.yield %8 : f32
    } -> tensor<?xf32>
    flow.return %7 : tensor<?xf32>
  }
  %6 = hal.tensor.export %5 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CloneProducersIntoDispatchRegionsPass (iree-dispatch-creation-clone-producers-into-dispatch-regions) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.region -> (tensor<?xf32>{%0}) {
    %6 = tensor.empty(%0) : tensor<?xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%6 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %8 = arith.addf %in, %in_0 : f32
      linalg.yield %8 : f32
    } -> tensor<?xf32>
    flow.return %7 : tensor<?xf32>
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After CollapseDimensionsPass (iree-dispatch-creation-collapse-dimensions) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.region -> (tensor<?xf32>{%0}) {
    %6 = tensor.empty(%0) : tensor<?xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%1, %3 : tensor<?xf32>, tensor<?xf32>) outs(%6 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %8 = arith.addf %in, %in_0 : f32
      linalg.yield %8 : f32
    } -> tensor<?xf32>
    flow.return %7 : tensor<?xf32>
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After ConvertDispatchRegionsToWorkgroupsPass (iree-dispatch-creation-convert-dispatch-regions-to-workgroups) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.workgroups(%0, %1, %3, %0, %2, %0) : (index, tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index, index) -> tensor<?xf32>{%0} =
      (%arg2: index, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg5: index, %arg6: index, %arg7: index, %arg8: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
    %6 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [%arg7], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%arg7} -> tensor<?xf32>
    %7 = flow.dispatch.tensor.load %arg4, offsets = [0], sizes = [%arg6], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%arg6} -> tensor<?xf32>
    %8 = tensor.empty(%arg7) : tensor<?xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%6, %7 : tensor<?xf32>, tensor<?xf32>) outs(%8 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %10 = arith.addf %in, %in_0 : f32
      linalg.yield %10 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %9, %arg8, offsets = [0], sizes = [%arg7], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%arg7}
    flow.return
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After ConvertTensorToFlowPass (iree-dispatch-creation-convert-tensor-to-flow) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.workgroups(%0, %1, %3, %0, %2, %0) : (index, tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index, index) -> tensor<?xf32>{%0} =
      (%arg2: index, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg5: index, %arg6: index, %arg7: index, %arg8: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
    %6 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [%arg7], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%arg7} -> tensor<?xf32>
    %7 = flow.dispatch.tensor.load %arg4, offsets = [0], sizes = [%arg6], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%arg6} -> tensor<?xf32>
    %8 = tensor.empty(%arg7) : tensor<?xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%6, %7 : tensor<?xf32>, tensor<?xf32>) outs(%8 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %10 = arith.addf %in, %in_0 : f32
      linalg.yield %10 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %9, %arg8, offsets = [0], sizes = [%arg7], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%arg7}
    flow.return
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.workgroups(%0, %1, %3, %0, %2, %0) : (index, tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index, index) -> tensor<?xf32>{%0} =
      (%arg2: index, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg5: index, %arg6: index, %arg7: index, %arg8: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
    %6 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [%arg7], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%arg7} -> tensor<?xf32>
    %7 = flow.dispatch.tensor.load %arg4, offsets = [0], sizes = [%arg6], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%arg6} -> tensor<?xf32>
    %8 = tensor.empty(%arg7) : tensor<?xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%6, %7 : tensor<?xf32>, tensor<?xf32>) outs(%8 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %10 = arith.addf %in, %in_0 : f32
      linalg.yield %10 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %9, %arg8, offsets = [0], sizes = [%arg7], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%arg7}
    flow.return
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.workgroups(%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0} =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: index, %arg5: index, %arg6: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
    %6 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [%arg5], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%arg5} -> tensor<?xf32>
    %7 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [%arg4], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%arg4} -> tensor<?xf32>
    %8 = tensor.empty(%arg5) : tensor<?xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%6, %7 : tensor<?xf32>, tensor<?xf32>) outs(%8 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %10 = arith.addf %in, %in_0 : f32
      linalg.yield %10 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %9, %arg6, offsets = [0], sizes = [%arg5], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%arg5}
    flow.return
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After MaterializeDefaultWorkgroupCountRegionPass (iree-dispatch-creation-materialize-default-workgroup-count-region) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.workgroups[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0} =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: index, %arg5: index, %arg6: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
    %6 = flow.dispatch.workload.ordinal %arg4, 0 : index
    %7 = flow.dispatch.workload.ordinal %arg5, 1 : index
    %8 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [%7], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%7} -> tensor<?xf32>
    %9 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [%6], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%6} -> tensor<?xf32>
    %10 = tensor.empty(%7) : tensor<?xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%8, %9 : tensor<?xf32>, tensor<?xf32>) outs(%10 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %12 = arith.addf %in, %in_0 : f32
      linalg.yield %12 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %11, %arg6, offsets = [0], sizes = [%7], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%7}
    flow.return
  } count(%arg2: index, %arg3: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg2, %arg3
    flow.return %x, %y, %z : index, index, index
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After VerifyInputLegalityPass (iree-verify-input-legality) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch.workgroups[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0} =
        (%arg2: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: index, %arg5: index, %arg6: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
      %6 = flow.dispatch.workload.ordinal %arg4, 0 : index
      %7 = flow.dispatch.workload.ordinal %arg5, 1 : index
      %8 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [%7], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%7} -> tensor<?xf32>
      %9 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [%6], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%6} -> tensor<?xf32>
      %10 = tensor.empty(%7) : tensor<?xf32>
      %11 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%8, %9 : tensor<?xf32>, tensor<?xf32>) outs(%10 : tensor<?xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %12 = arith.addf %in, %in_0 : f32
        linalg.yield %12 : f32
      } -> tensor<?xf32>
      flow.dispatch.tensor.store %11, %arg6, offsets = [0], sizes = [%7], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%7}
      flow.return
    } count(%arg2: index, %arg3: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg2, %arg3
      flow.return %x, %y, %z : index, index, index
    }
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After CaptureDynamicDimsPass (iree-flow-capture-dynamic-dims) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.workgroups[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0} =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: index, %arg5: index, %arg6: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
    %6 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%arg5}
    %7 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%arg4}
    %8 = flow.dispatch.tie_shape %arg6 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%arg5}
    %9 = flow.dispatch.workload.ordinal %arg4, 0 : index
    %10 = flow.dispatch.workload.ordinal %arg5, 1 : index
    %11 = flow.dispatch.tensor.load %6, offsets = [0], sizes = [%10], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%10} -> tensor<?xf32>
    %12 = flow.dispatch.tensor.load %7, offsets = [0], sizes = [%9], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%9} -> tensor<?xf32>
    %13 = tensor.empty(%10) : tensor<?xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<?xf32>, tensor<?xf32>) outs(%13 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %15 = arith.addf %in, %in_0 : f32
      linalg.yield %15 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %14, %8, offsets = [0], sizes = [%10], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%10}
    flow.return
  } count(%arg2: index, %arg3: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg2, %arg3
    flow.return %x, %y, %z : index, index, index
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.workgroups[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0} =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: index, %arg5: index, %arg6: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
    %6 = flow.dispatch.workload.ordinal %arg4, 0 : index
    %7 = flow.dispatch.workload.ordinal %arg5, 1 : index
    %8 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%7}
    %9 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%6}
    %10 = flow.dispatch.tie_shape %arg6 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%7}
    %11 = flow.dispatch.tensor.load %8, offsets = [0], sizes = [%7], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%7} -> tensor<?xf32>
    %12 = flow.dispatch.tensor.load %9, offsets = [0], sizes = [%6], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%6} -> tensor<?xf32>
    %13 = tensor.empty(%7) : tensor<?xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<?xf32>, tensor<?xf32>) outs(%13 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %15 = arith.addf %in, %in_0 : f32
      linalg.yield %15 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %14, %10, offsets = [0], sizes = [%7], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%7}
    flow.return
  } count(%arg2: index, %arg3: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg2, %arg3
    flow.return %x, %y, %z : index, index, index
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.workgroups[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0} =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: index, %arg5: index, %arg6: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
    %6 = flow.dispatch.workload.ordinal %arg4, 0 : index
    %7 = flow.dispatch.workload.ordinal %arg5, 1 : index
    %8 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%7}
    %9 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%6}
    %10 = flow.dispatch.tie_shape %arg6 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%7}
    %11 = flow.dispatch.tensor.load %8, offsets = [0], sizes = [%7], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%7} -> tensor<?xf32>
    %12 = flow.dispatch.tensor.load %9, offsets = [0], sizes = [%6], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%6} -> tensor<?xf32>
    %13 = tensor.empty(%7) : tensor<?xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<?xf32>, tensor<?xf32>) outs(%13 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %15 = arith.addf %in, %in_0 : f32
      linalg.yield %15 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %14, %10, offsets = [0], sizes = [%7], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%7}
    flow.return
  } count(%arg2: index, %arg3: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg2, %arg3
    flow.return %x, %y, %z : index, index, index
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After InitializeEmptyTensorsPass (iree-flow-initialize-empty-tensors) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch.workgroups[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0} =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: index, %arg5: index, %arg6: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
    %6 = flow.dispatch.workload.ordinal %arg4, 0 : index
    %7 = flow.dispatch.workload.ordinal %arg5, 1 : index
    %8 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%7}
    %9 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%6}
    %10 = flow.dispatch.tie_shape %arg6 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%7}
    %11 = flow.dispatch.tensor.load %8, offsets = [0], sizes = [%7], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%7} -> tensor<?xf32>
    %12 = flow.dispatch.tensor.load %9, offsets = [0], sizes = [%6], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%6} -> tensor<?xf32>
    %13 = tensor.empty(%7) : tensor<?xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<?xf32>, tensor<?xf32>) outs(%13 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %15 = arith.addf %in, %in_0 : f32
      linalg.yield %15 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %14, %10, offsets = [0], sizes = [%7], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%7}
    flow.return
  } count(%arg2: index, %arg3: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg2, %arg3
    flow.return %x, %y, %z : index, index, index
  }
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After OutlineDispatchExternsPass (iree-flow-outline-dispatch-externs) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch.workgroups[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0} =
        (%arg2: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg4: index, %arg5: index, %arg6: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
      %6 = flow.dispatch.workload.ordinal %arg4, 0 : index
      %7 = flow.dispatch.workload.ordinal %arg5, 1 : index
      %8 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%7}
      %9 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%6}
      %10 = flow.dispatch.tie_shape %arg6 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%7}
      %11 = flow.dispatch.tensor.load %8, offsets = [0], sizes = [%7], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%7} -> tensor<?xf32>
      %12 = flow.dispatch.tensor.load %9, offsets = [0], sizes = [%6], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%6} -> tensor<?xf32>
      %13 = tensor.empty(%7) : tensor<?xf32>
      %14 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%11, %12 : tensor<?xf32>, tensor<?xf32>) outs(%13 : tensor<?xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %15 = arith.addf %in, %in_0 : f32
        linalg.yield %15 : f32
      } -> tensor<?xf32>
      flow.dispatch.tensor.store %14, %10, offsets = [0], sizes = [%7], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%7}
      flow.return
    } count(%arg2: index, %arg3: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg2, %arg3
      flow.return %x, %y, %z : index, index, index
    }
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After OutlineDispatchRegionsPass (iree-flow-outline-dispatch-regions) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchesPass (iree-flow-annotate-dispatches) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After StripDebugOps (iree-util-strip-debug-ops) //----- //
flow.executable private @foo_dispatch_0 {
  flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
      %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
      %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
      %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
      %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
      %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
      %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
      %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
      %7 = tensor.empty(%1) : tensor<?xf32>
      %8 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %9 = arith.addf %in, %in_0 : f32
        linalg.yield %9 : f32
      } -> tensor<?xf32>
      flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
      return
    }
  }
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After DeduplicateExecutablesPass (iree-flow-deduplicate-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After InjectTensorTracingPass (iree-flow-inject-tensor-tracing) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After CleanupTensorShapesPass (iree-flow-cleanup-tensor-shapes) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After OutlineConstantsPass (iree-flow-outline-constants) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInputPass (iree-stream-verify-input) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
  %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
  %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
  %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
  util.return %5 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  flow.executable private @foo_dispatch_0 {
    flow.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?xf32>>) {
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<?xf32>{%0}
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %3 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<?xf32>{%2}
    %4 = flow.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%2, %0](%1, %3, %2, %0) : (tensor<?xf32>{%0}, tensor<?xf32>{%2}, index, index) -> tensor<?xf32>{%0}
    %5 = hal.tensor.export %4 "output0" : tensor<?xf32>{%0} -> !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertToStreamPass (iree-stream-conversion) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %element_type_f32_0 = hal.element_type<f32> : i32
    %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32_0) encoding(%dense_row_major_1)
    %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %c0 = arith.constant 0 : index
    %8 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
    %9 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%8}
    %10 = stream.async.transfer %9 : !stream.resource<*>{%8} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%8}
    %11 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %10 : tensor<?xf32>{%0} in !stream.resource<external>{%8} -> !hal.buffer_view
    util.return %11 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToTensorsPass (iree-stream-verify-lowering-to-tensors) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %element_type_f32_0 = hal.element_type<f32> : i32
    %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32_0) encoding(%dense_row_major_1)
    %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %c0 = arith.constant 0 : index
    %8 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
    %9 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%8}
    %10 = stream.async.transfer %9 : !stream.resource<*>{%8} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%8}
    %11 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %10 : tensor<?xf32>{%0} in !stream.resource<external>{%8} -> !hal.buffer_view
    util.return %11 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
  %c0 = arith.constant 0 : index
  %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
  %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
  %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
  %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
  %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
  %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
  %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
  %7 = tensor.empty(%1) : tensor<?xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %9 = arith.addf %in, %in_0 : f32
    linalg.yield %9 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %element_type_f32_0 = hal.element_type<f32> : i32
  %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32_0) encoding(%dense_row_major_1)
  %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
  %9 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%8}
  %10 = stream.async.transfer %9 : !stream.resource<*>{%8} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%8}
  %11 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %10 : tensor<?xf32>{%0} in !stream.resource<external>{%8} -> !hal.buffer_view
  util.return %11 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %element_type_f32_0 = hal.element_type<f32> : i32
    %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32_0) encoding(%dense_row_major_1)
    %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %8 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
    %9 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%8}
    %10 = stream.async.transfer %9 : !stream.resource<*>{%8} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%8}
    %11 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %10 : tensor<?xf32>{%0} in !stream.resource<external>{%8} -> !hal.buffer_view
    util.return %11 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %element_type_f32_0 = hal.element_type<f32> : i32
  %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32_0) encoding(%dense_row_major_1)
  %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
  %9 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%8}
  %10 = stream.async.transfer %9 : !stream.resource<*>{%8} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%8}
  %11 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %10 : tensor<?xf32>{%0} in !stream.resource<external>{%8} -> !hal.buffer_view
  util.return %11 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
    %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
    %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
    %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
    %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
    %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
    %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%0} : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
    %5 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<?xf32>{%4} : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
    %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After EncodeDeviceTensorsPass (iree-stream-encode-device-tensors) //----- //
stream.executable private @foo_dispatch_0 {
  stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
    stream.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
      %c0 = arith.constant 0 : index
      %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
      %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
      %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
      %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
      %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
      %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
      %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
      %7 = tensor.empty(%1) : tensor<?xf32>
      %8 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %9 = arith.addf %in, %in_0 : f32
        linalg.yield %9 : f32
      } -> tensor<?xf32>
      flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
      return
    }
  }
}

// -----// IR Dump After EncodeHostTensorsPass (iree-stream-encode-host-tensors) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = arith.muli %4, %c4 : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = arith.muli %4, %c4 : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = arith.muli %4, %c4 : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = arith.muli %4, %c4 : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = arith.muli %4, %c4 : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = arith.muli %4, %c4 : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
    %5 = arith.muli %4, %c4 : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
    %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
    %5 = arith.muli %4, %c4 : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
    %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
    %5 = arith.muli %4, %c4 : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
    %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsyncResourcesPass (iree-stream-verify-lowering-to-async-resources) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
    %5 = arith.muli %4, %c4 : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
    %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeCopyOnWritePass (iree-stream-materialize-copy-on-write) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = arith.muli %4, %c4 : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = arith.muli %4, %c4 : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After ElideAsyncCopiesPass (iree-stream-elide-async-copies) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
    %5 = arith.muli %4, %c4 : index
    %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
    %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = arith.muli %4, %c4 : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After EmplaceAllocationsPass (iree-stream-emplace-allocations) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%1}
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%4]) type(%element_type_f32) encoding(%dense_row_major)
  %5 = arith.muli %4, %c4 : index
  %6 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%4} in !stream.resource<external>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<external>{%5} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%5}
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%4, %0](%3[%c0 to %1 for %1], %7[%c0 to %5 for %5], %4, %0) : (!stream.resource<*>{%1}, !stream.resource<*>{%5}, index, index) -> !stream.resource<*>{%1}
  %9 = stream.async.transfer %8 : !stream.resource<*>{%1} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%1}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After RefineUsagePass (iree-stream-refine-usage) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%2[%c0 to %1 for %1], %5[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%2[%c0 to %1 for %1], %5[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%2[%c0 to %1 for %1], %5[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%2[%c0 to %1 for %1], %5[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%2[%c0 to %1 for %1], %5[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%2[%c0 to %1 for %1], %5[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%2[%c0 to %1 for %1], %5[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%2[%c0 to %1 for %1], %5[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%2[%c0 to %1 for %1], %5[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyAsyncAccessRangesPass (iree-stream-verify-async-access-ranges) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%2[%c0 to %1 for %1], %5[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleExecutionPass (iree-stream-schedule-execution) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
    %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    stream.yield %8 : !stream.resource<external>{%1}
  } => !stream.timepoint
  %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After ScheduleConcurrencyPass (iree-stream-schedule-concurrency) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
    %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    stream.yield %8 : !stream.resource<external>{%1}
  } => !stream.timepoint
  %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After PropagateTimepointsPass (iree-stream-propagate-timepoints) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %6 = stream.timepoint.immediate => !stream.timepoint
    %7 = stream.timepoint.immediate => !stream.timepoint
    %8 = stream.timepoint.join max(%6, %7) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) await(%8) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
      %11 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
      stream.yield %11 : !stream.resource<external>{%1}
    } => !stream.timepoint
    %9 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeBuiltinsPass (iree-stream-materialize-builtins) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %6 = stream.timepoint.immediate => !stream.timepoint
    %7 = stream.timepoint.immediate => !stream.timepoint
    %8 = stream.timepoint.join max(%6, %7) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) await(%8) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
      %11 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
      stream.yield %11 : !stream.resource<external>{%1}
    } => !stream.timepoint
    %9 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
    %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    stream.yield %8 : !stream.resource<external>{%1}
  } => !stream.timepoint
  %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
    %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    stream.yield %8 : !stream.resource<external>{%1}
  } => !stream.timepoint
  %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
    %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    stream.yield %8 : !stream.resource<external>{%1}
  } => !stream.timepoint
  %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
    %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    stream.yield %8 : !stream.resource<external>{%1}
  } => !stream.timepoint
  %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
    %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
    stream.yield %8 : !stream.resource<external>{%1}
  } => !stream.timepoint
  %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
      %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
      stream.yield %8 : !stream.resource<external>{%1}
    } => !stream.timepoint
    %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
      %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
      stream.yield %8 : !stream.resource<external>{%1}
    } => !stream.timepoint
    %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
      %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
      stream.yield %8 : !stream.resource<external>{%1}
    } => !stream.timepoint
    %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsyncPass (iree-stream-verify-lowering-to-async) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}) -> !stream.resource<external>{%1} {
      %8 = stream.async.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%arg2[%c0 to %1 for %1], %arg3[%c0 to %4 for %4], %3, %0) : (!stream.resource<external>{%1}, !stream.resource<external>{%4}, index, index) -> !stream.resource<external>{%1}
      stream.yield %8 : !stream.resource<external>{%1}
    } => !stream.timepoint
    %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleAllocationPass (iree-stream-schedule-allocation) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0_0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After PackConstantsPass (iree-stream-pack-constants) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %c0_0 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0_0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After LayoutSlicesPass (iree-stream-layout-slices) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %c0_0 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0_0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0_0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToCmdPass (iree-stream-verify-lowering-to-cmd) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After ElideTimepointsPass (iree-stream-elide-timepoints) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg2, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg3, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg4[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%3, %0 : index, index) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseDispatchBindingsPass (iree-stream-fuse-dispatch-bindings) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index, %arg7: index) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg6, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg7, 1 : index
        %2 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg2[%arg5] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0, %c0, %c0, %3, %0 : index, index, index, index, index) {
        ro %arg2[%c0_0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0_0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0_0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchArgumentsPass (iree-stream-annotate-dispatch-arguments) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: index {stream.values = [0 : index]}, %arg4: index {stream.values = [0 : index]}, %arg5: index {stream.values = [0 : index]}, %arg6: index, %arg7: index) {
        %c0 = arith.constant 0 : index
        %0 = flow.dispatch.workload.ordinal %arg6, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg7, 1 : index
        %2 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %3 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0}
        %4 = stream.binding.subspan %arg2[%arg5] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%0], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%0} -> tensor<?xf32>
        %7 = tensor.empty(%1) : tensor<?xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%5, %6 : tensor<?xf32>, tensor<?xf32>) outs(%7 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %9 = arith.addf %in, %in_0 : f32
          linalg.yield %9 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %8, %4, offsets = [0], sizes = [%1], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%1}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0, %c0, %c0, %3, %0 : index, index, index, index, index) {
        ro %arg2[%c0_0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0_0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0_0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchAssumptionsPass (iree-stream-annotate-dispatch-assumptions) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: index {stream.values = [0 : index]}, %arg4: index {stream.values = [0 : index]}, %arg5: index {stream.values = [0 : index]}, %arg6: index, %arg7: index) {
        %0:5 = util.assume.int 
            %arg3<umin = 0, umax = 0>, 
            %arg4<umin = 0, umax = 0>, 
            %arg5<umin = 0, umax = 0>, 
            %arg6<umin = 0, umax = 9007199254740991>, 
            %arg7<umin = 0, umax = 9007199254740991>
          : index, index, index, index, index
        %c0 = arith.constant 0 : index
        %1 = flow.dispatch.workload.ordinal %0#3, 0 : index
        %2 = flow.dispatch.workload.ordinal %0#4, 1 : index
        %3 = stream.binding.subspan %arg0[%0#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%2}
        %4 = stream.binding.subspan %arg1[%0#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1}
        %5 = stream.binding.subspan %arg2[%0#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%2}
        %6 = flow.dispatch.tensor.load %3, offsets = [0], sizes = [%2], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%2} -> tensor<?xf32>
        %7 = flow.dispatch.tensor.load %4, offsets = [0], sizes = [%1], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%1} -> tensor<?xf32>
        %8 = tensor.empty(%2) : tensor<?xf32>
        %9 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%6, %7 : tensor<?xf32>, tensor<?xf32>) outs(%8 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %10 = arith.addf %in, %in_0 : f32
          linalg.yield %10 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %9, %5, offsets = [0], sizes = [%2], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%2}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %6 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0, %c0, %c0, %3, %0 : index, index, index, index, index) {
        ro %arg2[%c0_0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0_0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0_0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%1}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After PackDispatchOperandsPass (iree-stream-pack-dispatch-operands) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %c32_i64_0 = arith.constant 32 : i64
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64_0 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %c32_i64_1 = arith.constant 32 : i64
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64_1 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %c32_i64_2 = arith.constant 32 : i64
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64_2 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %c32_i64_3 = arith.constant 32 : i64
        %20 = arith.extui %arg12 : i32 to i64
        %21 = arith.shli %20, %c32_i64_3 : i64
        %22 = arith.extui %arg11 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %25:5 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>, 
            %14<umin = 0, umax = 0>, 
            %19<umin = 0, umax = 9007199254740991>, 
            %24<umin = 0, umax = 9007199254740991>
          : index, index, index, index, index
        %c0 = arith.constant 0 : index
        %26 = flow.dispatch.workload.ordinal %25#3, 0 : index
        %27 = flow.dispatch.workload.ordinal %25#4, 1 : index
        %28 = stream.binding.subspan %arg0[%25#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%27}
        %29 = stream.binding.subspan %arg1[%25#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%26}
        %30 = stream.binding.subspan %arg2[%25#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%27}
        %31 = flow.dispatch.tensor.load %28, offsets = [0], sizes = [%27], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%27} -> tensor<?xf32>
        %32 = flow.dispatch.tensor.load %29, offsets = [0], sizes = [%26], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%26} -> tensor<?xf32>
        %33 = tensor.empty(%27) : tensor<?xf32>
        %34 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%31, %32 : tensor<?xf32>, tensor<?xf32>) outs(%33 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_4: f32, %out: f32):
          %35 = arith.addf %in, %in_4 : f32
          linalg.yield %35 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %34, %30, offsets = [0], sizes = [%27], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%27}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %c0_i64 = arith.constant 0 : i64
    %c0_i32 = arith.constant 0 : i32
    %c32_i64 = arith.constant 32 : i64
    %c0_i64_1 = arith.constant 0 : i64
    %c0_i32_2 = arith.constant 0 : i32
    %c0_i64_3 = arith.constant 0 : i64
    %c0_i32_4 = arith.constant 0 : i32
    %c32_i64_5 = arith.constant 32 : i64
    %c0_i64_6 = arith.constant 0 : i64
    %c0_i32_7 = arith.constant 0 : i32
    %c0_i64_8 = arith.constant 0 : i64
    %c0_i32_9 = arith.constant 0 : i32
    %c32_i64_10 = arith.constant 32 : i64
    %c0_i64_11 = arith.constant 0 : i64
    %c0_i32_12 = arith.constant 0 : i32
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %c32_i64_13 = arith.constant 32 : i64
    %8 = arith.shrui %6, %c32_i64_13 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %c32_i64_14 = arith.constant 32 : i64
    %12 = arith.shrui %10, %c32_i64_14 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0_i32, %c0_i32_2, %c0_i32_4, %c0_i32_7, %c0_i32_9, %c0_i32_12, %7, %9, %11, %13 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg2[%c0_0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0_0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0_0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.trunci %6 : i64 to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %7, %9, %11, %13 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.trunci %6 : i64 to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %7, %9, %11, %13 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %7, %9, %11, %13 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %7, %9, %11, %13 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %7, %9, %11, %13 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = arith.extui %arg12 : i32 to i64
        %21 = arith.shli %20, %c32_i64 : i64
        %22 = arith.extui %arg11 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %25:5 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>, 
            %14<umin = 0, umax = 0>, 
            %19<umin = 0, umax = 9007199254740991>, 
            %24<umin = 0, umax = 9007199254740991>
          : index, index, index, index, index
        %26 = flow.dispatch.workload.ordinal %25#3, 0 : index
        %27 = flow.dispatch.workload.ordinal %25#4, 1 : index
        %28 = stream.binding.subspan %arg0[%25#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%27}
        %29 = stream.binding.subspan %arg1[%25#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%26}
        %30 = stream.binding.subspan %arg2[%25#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%27}
        %31 = flow.dispatch.tensor.load %28, offsets = [0], sizes = [%27], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%27} -> tensor<?xf32>
        %32 = flow.dispatch.tensor.load %29, offsets = [0], sizes = [%26], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%26} -> tensor<?xf32>
        %33 = tensor.empty(%27) : tensor<?xf32>
        %34 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%31, %32 : tensor<?xf32>, tensor<?xf32>) outs(%33 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %35 = arith.addf %in, %in_0 : f32
          linalg.yield %35 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %34, %30, offsets = [0], sizes = [%27], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%27}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %7, %9, %11, %13 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = arith.extui %arg12 : i32 to i64
        %21 = arith.shli %20, %c32_i64 : i64
        %22 = arith.extui %arg11 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %25:5 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>, 
            %14<umin = 0, umax = 0>, 
            %19<umin = 0, umax = 9007199254740991>, 
            %24<umin = 0, umax = 9007199254740991>
          : index, index, index, index, index
        %26 = flow.dispatch.workload.ordinal %25#3, 0 : index
        %27 = flow.dispatch.workload.ordinal %25#4, 1 : index
        %28 = stream.binding.subspan %arg0[%25#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%27}
        %29 = stream.binding.subspan %arg1[%25#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%26}
        %30 = stream.binding.subspan %arg2[%25#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%27}
        %31 = flow.dispatch.tensor.load %28, offsets = [0], sizes = [%27], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%27} -> tensor<?xf32>
        %32 = flow.dispatch.tensor.load %29, offsets = [0], sizes = [%26], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%26} -> tensor<?xf32>
        %33 = tensor.empty(%27) : tensor<?xf32>
        %34 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%31, %32 : tensor<?xf32>, tensor<?xf32>) outs(%33 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %35 = arith.addf %in, %in_0 : f32
          linalg.yield %35 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %34, %30, offsets = [0], sizes = [%27], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%27}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %7, %9, %11, %13 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = arith.extui %arg12 : i32 to i64
        %21 = arith.shli %20, %c32_i64 : i64
        %22 = arith.extui %arg11 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %25:5 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>, 
            %14<umin = 0, umax = 0>, 
            %19<umin = 0, umax = 9007199254740991>, 
            %24<umin = 0, umax = 9007199254740991>
          : index, index, index, index, index
        %26 = flow.dispatch.workload.ordinal %25#3, 0 : index
        %27 = flow.dispatch.workload.ordinal %25#4, 1 : index
        %28 = stream.binding.subspan %arg0[%25#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%27}
        %29 = stream.binding.subspan %arg1[%25#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%26}
        %30 = stream.binding.subspan %arg2[%25#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%27}
        %31 = flow.dispatch.tensor.load %28, offsets = [0], sizes = [%27], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%27} -> tensor<?xf32>
        %32 = flow.dispatch.tensor.load %29, offsets = [0], sizes = [%26], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%26} -> tensor<?xf32>
        %33 = tensor.empty(%27) : tensor<?xf32>
        %34 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%31, %32 : tensor<?xf32>, tensor<?xf32>) outs(%33 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %35 = arith.addf %in, %in_0 : f32
          linalg.yield %35 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %34, %30, offsets = [0], sizes = [%27], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%27}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %7, %9, %11, %13 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldUniformOperandsPass (iree-stream-fold-uniform-operands) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c0_i32 = arith.constant 0 : i32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %c0_i32 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %c0_i32 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %c0_i32 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %c0_i32 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %c0_i32 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %c0_i32 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15 = arith.extui %arg4 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg3 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = arith.extui %arg6 : i32 to i64
        %21 = arith.shli %20, %c32_i64 : i64
        %22 = arith.extui %arg5 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %25:5 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>, 
            %14<umin = 0, umax = 0>, 
            %19<umin = 0, umax = 9007199254740991>, 
            %24<umin = 0, umax = 9007199254740991>
          : index, index, index, index, index
        %26 = flow.dispatch.workload.ordinal %25#3, 0 : index
        %27 = flow.dispatch.workload.ordinal %25#4, 1 : index
        %28 = stream.binding.subspan %arg0[%25#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%27}
        %29 = stream.binding.subspan %arg1[%25#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%26}
        %30 = stream.binding.subspan %arg2[%25#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%27}
        %31 = flow.dispatch.tensor.load %28, offsets = [0], sizes = [%27], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%27} -> tensor<?xf32>
        %32 = flow.dispatch.tensor.load %29, offsets = [0], sizes = [%26], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%26} -> tensor<?xf32>
        %33 = tensor.empty(%27) : tensor<?xf32>
        %34 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%31, %32 : tensor<?xf32>, tensor<?xf32>) outs(%33 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %35 = arith.addf %in, %in_0 : f32
          linalg.yield %35 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %34, %30, offsets = [0], sizes = [%27], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%27}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After AssignLegacyTargetDevicesPass (iree-hal-assign-legacy-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeTargetDevicesPass (iree-hal-materialize-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDevicePromisesPass (iree-hal-resolve-device-promises) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDeviceAliasesPass (iree-hal-resolve-device-aliases) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = arith.muli %0, %c4 : index
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
  %6 = arith.index_castui %3 : index to i64
  %7 = arith.index_castui %3 : index to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.index_castui %0 : index to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
      ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
      ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
      wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
  %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
  util.return %16 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  stream.executable private @foo_dispatch_0 {
    stream.executable.export public @foo_dispatch_0_elementwise_D_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %c32_i64 = arith.constant 32 : i64
        %c0 = arith.constant 0 : index
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 9007199254740991>, 
            %9<umin = 0, umax = 9007199254740991>
          : index, index
        %11 = flow.dispatch.workload.ordinal %10#0, 0 : index
        %12 = flow.dispatch.workload.ordinal %10#1, 1 : index
        %13 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12}
        %14 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11}
        %15 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        %16 = flow.dispatch.tensor.load %13, offsets = [0], sizes = [%12], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%12} -> tensor<?xf32>
        %17 = flow.dispatch.tensor.load %14, offsets = [0], sizes = [%11], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%11} -> tensor<?xf32>
        %18 = tensor.empty(%12) : tensor<?xf32>
        %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%16, %17 : tensor<?xf32>, tensor<?xf32>) outs(%18 : tensor<?xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %20 = arith.addf %in, %in_0 : f32
          linalg.yield %20 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %19, %15, offsets = [0], sizes = [%12], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%12}
        return
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeInterfacesPass (iree-hal-materialize-interfaces) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @foo_dispatch_0_elementwise_D_f32() {
          %c0 = arith.constant 0 : index
          %c32_i64 = arith.constant 32 : i64
          %0 = hal.interface.constant.load layout(#pipeline_layout) ordinal(0) : i32
          %1 = hal.interface.constant.load layout(#pipeline_layout) ordinal(1) : i32
          %2 = hal.interface.constant.load layout(#pipeline_layout) ordinal(2) : i32
          %3 = hal.interface.constant.load layout(#pipeline_layout) ordinal(3) : i32
          %4 = arith.extui %1 : i32 to i64
          %5 = arith.shli %4, %c32_i64 : i64
          %6 = arith.extui %0 : i32 to i64
          %7 = arith.ori %6, %5 : i64
          %8 = arith.index_castui %7 : i64 to index
          %9 = arith.extui %3 : i32 to i64
          %10 = arith.shli %9, %c32_i64 : i64
          %11 = arith.extui %2 : i32 to i64
          %12 = arith.ori %11, %10 : i64
          %13 = arith.index_castui %12 : i64 to index
          %14:2 = util.assume.int 
              %8<umin = 0, umax = 9007199254740991>, 
              %13<umin = 0, umax = 9007199254740991>
            : index, index
          %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
          %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
          %17 = hal.interface.binding.subspan layout(#pipeline_layout) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
          %18 = hal.interface.binding.subspan layout(#pipeline_layout) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
          %19 = hal.interface.binding.subspan layout(#pipeline_layout) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
          %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
          %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
          %22 = tensor.empty(%16) : tensor<?xf32>
          %23 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
          ^bb0(%in: f32, %in_0: f32, %out: f32):
            %24 = arith.addf %in, %in_0 : f32
            linalg.yield %24 : f32
          } -> tensor<?xf32>
          flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
          return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After PruneExecutablesPass (iree-hal-prune-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<(d0) -> (d0)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @foo_dispatch_0_elementwise_D_f32() {
          %c0 = arith.constant 0 : index
          %c32_i64 = arith.constant 32 : i64
          %0 = hal.interface.constant.load layout(#pipeline_layout) ordinal(0) : i32
          %1 = hal.interface.constant.load layout(#pipeline_layout) ordinal(1) : i32
          %2 = hal.interface.constant.load layout(#pipeline_layout) ordinal(2) : i32
          %3 = hal.interface.constant.load layout(#pipeline_layout) ordinal(3) : i32
          %4 = arith.extui %1 : i32 to i64
          %5 = arith.shli %4, %c32_i64 : i64
          %6 = arith.extui %0 : i32 to i64
          %7 = arith.ori %6, %5 : i64
          %8 = arith.index_castui %7 : i64 to index
          %9 = arith.extui %3 : i32 to i64
          %10 = arith.shli %9, %c32_i64 : i64
          %11 = arith.extui %2 : i32 to i64
          %12 = arith.ori %11, %10 : i64
          %13 = arith.index_castui %12 : i64 to index
          %14:2 = util.assume.int 
              %8<umin = 0, umax = 9007199254740991>, 
              %13<umin = 0, umax = 9007199254740991>
            : index, index
          %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
          %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
          %17 = hal.interface.binding.subspan layout(#pipeline_layout) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
          %18 = hal.interface.binding.subspan layout(#pipeline_layout) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
          %19 = hal.interface.binding.subspan layout(#pipeline_layout) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
          %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
          %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
          %22 = tensor.empty(%16) : tensor<?xf32>
          %23 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
          ^bb0(%in: f32, %in_0: f32, %out: f32):
            %24 = arith.addf %in, %in_0 : f32
            linalg.yield %24 : f32
          } -> tensor<?xf32>
          flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
          return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<?xf32>{%0} in !stream.resource<external>{%1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<?xf32>{%3} in !stream.resource<external>{%4}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%1} => !stream.timepoint
    %6 = arith.index_castui %3 : index to i64
    %7 = arith.index_castui %3 : index to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.index_castui %0 : index to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%2 as %arg2: !stream.resource<external>{%1}, %5 as %arg3: !stream.resource<external>{%4}, %result as %arg4: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32[%3, %0](%7, %9, %11, %13 : i32, i32, i32, i32) {
        ro %arg2[%c0 for %1] : !stream.resource<external>{%1},
        ro %arg3[%c0 for %4] : !stream.resource<external>{%4},
        wo %arg4[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    %15 = stream.timepoint.await %14 => %result : !stream.resource<external>{%1}
    %16 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %15 : tensor<?xf32>{%0} in !stream.resource<external>{%1} -> !hal.buffer_view
    util.return %16 : !hal.buffer_view
  }
}


// -----// IR Dump After GPUGeneralizeNamedOpsPass (iree-codegen-gpu-generalize-named-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After TypePropagationPass (iree-codegen-type-propagation) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After BubbleUpOrdinalOpsPass (iree-codegen-bubble-up-ordinal-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After BufferizeCopyOnlyDispatchesPass (iree-codegen-bufferize-copy-only-dispatches) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After DecomposeSoftmaxPass (iree-codegen-decompose-softmax) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After MaterializeEncodingIntoNopPass (iree-codegen-materialize-encoding-into-nop) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After BufferizeCopyOnlyDispatchesPass (iree-codegen-bufferize-copy-only-dispatches) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After BlockDynamicDimensionsPass (iree-codegen-block-dynamic-dimensions) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %24 = arith.addf %in, %in_0 : f32
    linalg.yield %24 : f32
  } -> tensor<?xf32>
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After MaterializeUserConfigsPass (iree-codegen-materialize-user-configs) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() {
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %4 = arith.extui %1 : i32 to i64
    %5 = arith.shli %4, %c32_i64 : i64
    %6 = arith.extui %0 : i32 to i64
    %7 = arith.ori %6, %5 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %3 : i32 to i64
    %10 = arith.shli %9, %c32_i64 : i64
    %11 = arith.extui %2 : i32 to i64
    %12 = arith.ori %11, %10 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14:2 = util.assume.int 
        %8<umin = 0, umax = 9007199254740991>, 
        %13<umin = 0, umax = 9007199254740991>
      : index, index
    %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
    %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
    %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
    %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
    %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
    %22 = tensor.empty(%16) : tensor<?xf32>
    %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %24 = arith.addf %in, %in_0 : f32
      linalg.yield %24 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
    return
  }
}

// -----// IR Dump After LLVMGPUSelectLoweringStrategyPass (iree-llvmgpu-select-lowering-strategy) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %4 = arith.extui %1 : i32 to i64
    %5 = arith.shli %4, %c32_i64 : i64
    %6 = arith.extui %0 : i32 to i64
    %7 = arith.ori %6, %5 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %3 : i32 to i64
    %10 = arith.shli %9, %c32_i64 : i64
    %11 = arith.extui %2 : i32 to i64
    %12 = arith.ori %11, %10 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14:2 = util.assume.int 
        %8<umin = 0, umax = 9007199254740991>, 
        %13<umin = 0, umax = 9007199254740991>
      : index, index
    %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
    %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
    %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
    %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
    %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
    %22 = tensor.empty(%16) : tensor<?xf32>
    %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %24 = arith.addf %in, %in_0 : f32
      linalg.yield %24 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
    return
  }
}

// -----// IR Dump After ConfigureTargetExecutableVariantsPass (iree-hal-configure-target-executable-variants) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>) {
  hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
      %c0 = arith.constant 0 : index
      %c32_i64 = arith.constant 32 : i64
      %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
      %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
      %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
      %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
      %4 = arith.extui %1 : i32 to i64
      %5 = arith.shli %4, %c32_i64 : i64
      %6 = arith.extui %0 : i32 to i64
      %7 = arith.ori %6, %5 : i64
      %8 = arith.index_castui %7 : i64 to index
      %9 = arith.extui %3 : i32 to i64
      %10 = arith.shli %9, %c32_i64 : i64
      %11 = arith.extui %2 : i32 to i64
      %12 = arith.ori %11, %10 : i64
      %13 = arith.index_castui %12 : i64 to index
      %14:2 = util.assume.int 
          %8<umin = 0, umax = 9007199254740991>, 
          %13<umin = 0, umax = 9007199254740991>
        : index, index
      %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
      %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
      %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
      %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
      %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
      %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
      %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
      %22 = tensor.empty(%16) : tensor<?xf32>
      %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %24 = arith.addf %in, %in_0 : f32
        linalg.yield %24 : f32
      } -> tensor<?xf32>
      flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
      return
    }
  }
}

// -----// IR Dump After ConfigureExecutablesPass (iree-hal-configure-executables) //----- //
hal.executable private @foo_dispatch_0 {
  hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>) {
    hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) {
    ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
      hal.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
        %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
        %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
        %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
        %4 = arith.extui %1 : i32 to i64
        %5 = arith.shli %4, %c32_i64 : i64
        %6 = arith.extui %0 : i32 to i64
        %7 = arith.ori %6, %5 : i64
        %8 = arith.index_castui %7 : i64 to index
        %9 = arith.extui %3 : i32 to i64
        %10 = arith.shli %9, %c32_i64 : i64
        %11 = arith.extui %2 : i32 to i64
        %12 = arith.ori %11, %10 : i64
        %13 = arith.index_castui %12 : i64 to index
        %14:2 = util.assume.int 
            %8<umin = 0, umax = 9007199254740991>, 
            %13<umin = 0, umax = 9007199254740991>
          : index, index
        %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
        %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
        %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
        %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
        %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
        %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
        %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
        %22 = tensor.empty(%16) : tensor<?xf32>
        %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %24 = arith.addf %in, %in_0 : f32
          linalg.yield %24 : f32
        } -> tensor<?xf32>
        flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
        return
      }
    }
  }
}

// -----// IR Dump After LowerExecutableUsingTransformDialectPass (iree-codegen-lower-executable-using-transform-dialect) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %4 = arith.extui %1 : i32 to i64
    %5 = arith.shli %4, %c32_i64 : i64
    %6 = arith.extui %0 : i32 to i64
    %7 = arith.ori %6, %5 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %3 : i32 to i64
    %10 = arith.shli %9, %c32_i64 : i64
    %11 = arith.extui %2 : i32 to i64
    %12 = arith.ori %11, %10 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14:2 = util.assume.int 
        %8<umin = 0, umax = 9007199254740991>, 
        %13<umin = 0, umax = 9007199254740991>
      : index, index
    %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
    %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
    %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
    %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
    %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
    %22 = tensor.empty(%16) : tensor<?xf32>
    %23 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%20, %21 : tensor<?xf32>, tensor<?xf32>) outs(%22 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %24 = arith.addf %in, %in_0 : f32
      linalg.yield %24 : f32
    } -> tensor<?xf32>
    flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
    return
  }
}

// -----// IR Dump After TileAndDistributeToWorkgroupsUsingForallOpPass (iree-codegen-tile-and-distribute-to-workgroups-using-forall-op) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After GPUPromoteMatmulOperandsPass (iree-codegen-gpu-promote-matmul-operands) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After PackToIntrinsicsPass (iree-gpu-pack-to-intrinsics) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After DecomposeBoundaryPackUnPackOpsPass (iree-codegen-decompose-boundary-pack-unpack-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After ConcretizeMmaShapesPass (iree-gpu-concretize-mma-shapes) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After PropagateReshapesByExpansionPass (iree-codegen-propagate-reshapes-by-expansion) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After GPUApplyTilingLevelPass (iree-codegen-gpu-apply-tiling-level) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After DecomposePackUnPackOpsPass (iree-codegen-decompose-pack-unpack-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After ConcretizeMmaShapesPass (iree-gpu-concretize-mma-shapes) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After PropagateReshapesByExpansionPass (iree-codegen-propagate-reshapes-by-expansion) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %20[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_0 = tensor.extract_slice %21[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<?xf32>, tensor<?xf32>) outs(%extracted_slice_1 : tensor<?xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After GPUApplyTilingLevelPass (iree-codegen-gpu-apply-tiling-level) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = scf.forall (%arg2) in (%24) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %26 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %20[%26] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %27 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_1 = tensor.extract_slice %21[%27] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %28 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %29 = arith.addf %in, %in_3 : f32
        linalg.yield %29 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %28 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = scf.forall (%arg2) in (%24) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %26 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %20[%26] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %27 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_1 = tensor.extract_slice %21[%27] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %28 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %29 = arith.addf %in, %in_3 : f32
        linalg.yield %29 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %28 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = scf.forall (%arg2) in (%24) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %26 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %20[%26] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%26] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %27 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %28 = arith.addf %in, %in_3 : f32
        linalg.yield %28 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %27 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After GPUApplyTilingLevelPass (iree-codegen-gpu-apply-tiling-level) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = scf.forall (%arg2) in (%24) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %26 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %20[%26] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%26] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %27 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %28 = arith.addf %in, %in_3 : f32
        linalg.yield %28 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %27 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After DistributeMmaToLanesPass (iree-gpu-distribute-mma-to-lanes) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = scf.forall (%arg0) = (0) to (%16) step (32) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %24 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%arg0] [%24] [1] : tensor<?xf32> to tensor<?xf32>
    %25 = scf.forall (%arg2) in (%24) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %26 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %20[%26] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%26] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %27 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %28 = arith.addf %in, %in_3 : f32
        linalg.yield %28 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %27 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [%24] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %23, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After NormalizeLoopBoundsPass (iree-codegen-normalize-loop-bounds) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (-d0 + s0, 32)>(%25)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %25]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After IREELoopInvariantCodeMotionPass (iree-loop-invariant-code-motion) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After OptimizeTensorInsertExtractSlicesPass (iree-codegen-optimize-tensor-insert-extract-slices) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After FuseAndHoistParallelLoopsPass (iree-gpu-fuse-and-hoist-parallel-loops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After GPUGreedilyDistributeToThreadsPass (iree-codegen-gpu-greedily-distribute-to-threads) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After TileLargeTensorsPass (iree-codegen-tile-large-tensors) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After IREELoopInvariantCodeMotionPass (iree-loop-invariant-code-motion) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CombineBarrierRegionsPass (iree-gpu-combine-barrier-regions) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After VectorizeIREEGPUOpsPass (iree-gpu-vectorize-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After DecomposeConvolutionToLowerDimOpsPass (iree-codegen-decompose-convolution-to-lower-dim-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After DecomposeIm2colPass (iree-linalg-ext-decompose-im2col) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After VectorizeIREEVectorExtOpsPass (iree-vector-ext-vectorize-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{thread = [1], workgroup = [32]}>} {
      ^bb0(%in: f32, %in_3: f32, %out: f32):
        %30 = arith.addf %in, %in_3 : f32
        linalg.yield %30 : f32
      } -> tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %29 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After GenericVectorizationPass (iree-codegen-generic-vectorization) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %extracted_slice_0[%c0], %cst {in_bounds = [true]} : tensor<1xf32>, vector<1xf32>
      %30 = vector.transfer_read %extracted_slice_1[%c0], %cst {in_bounds = [true]} : tensor<1xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_2[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %extracted_slice_0[%c0], %cst {in_bounds = [true]} : tensor<1xf32>, vector<1xf32>
      %30 = vector.transfer_read %extracted_slice_1[%c0], %cst {in_bounds = [true]} : tensor<1xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_2[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %20[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_1 = tensor.extract_slice %21[%28] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %extracted_slice_0[%c0], %cst {in_bounds = [true]} : tensor<1xf32>, vector<1xf32>
      %30 = vector.transfer_read %extracted_slice_1[%c0], %cst {in_bounds = [true]} : tensor<1xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_2[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After OptimizeTensorInsertExtractSlicesPass (iree-codegen-optimize-tensor-insert-extract-slices) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %20[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %30 = vector.transfer_read %21[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_0[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %20[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %30 = vector.transfer_read %21[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_0[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %20[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %30 = vector.transfer_read %21[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_0[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After CleanupBufferAllocViewPass (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %20[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %30 = vector.transfer_read %21[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_0[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After GPUCombineValueBarriersPass (iree-codegen-gpu-combine-value-barriers) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = tensor.empty(%16) : tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %20[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %30 = vector.transfer_read %21[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_0[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After EliminateEmptyTensorsPass (iree-eliminate-empty-tensors) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = flow.dispatch.tensor.load %19, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %20[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %30 = vector.transfer_read %21[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_0[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After EmptyTensorToAllocTensor (empty-tensor-to-alloc-tensor) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = flow.dispatch.tensor.load %19, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %20[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %30 = vector.transfer_read %21[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_0[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After GPUInferMemorySpacePass (iree-codegen-gpu-infer-memory-space) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16}
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15}
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %21 = flow.dispatch.tensor.load %18, offsets = [0], sizes = [%15], strides = [1] : !flow.dispatch.tensor<readonly:tensor<?xf32>>{%15} -> tensor<?xf32>
  %22 = flow.dispatch.tensor.load %19, offsets = [0], sizes = [%16], strides = [1] : !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16} -> tensor<?xf32>
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  %24 = scf.forall (%arg0) in (%23) shared_outs(%arg1 = %22) -> (tensor<?xf32>) {
    %25 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %26 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %extracted_slice = tensor.extract_slice %arg1[%25] [%26] [1] : tensor<?xf32> to tensor<?xf32>
    %27 = scf.forall (%arg2) in (%26) shared_outs(%arg3 = %extracted_slice) -> (tensor<?xf32>) {
      %28 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg2]
      %extracted_slice_0 = tensor.extract_slice %arg3[%arg2] [1] [1] : tensor<?xf32> to tensor<1xf32>
      %29 = vector.transfer_read %20[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %30 = vector.transfer_read %21[%28], %cst {in_bounds = [true]} : tensor<?xf32>, vector<1xf32>
      %31 = arith.addf %29, %30 : vector<1xf32>
      %32 = vector.transfer_write %31, %extracted_slice_0[%c0] {in_bounds = [true]} : vector<1xf32>, tensor<1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg3[%arg2] [1] [1] : tensor<1xf32> into tensor<?xf32>
      }
    } {mapping = [#gpu.thread<linear_dim_0>]}
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %27 into %arg1[%25] [%26] [1] : tensor<?xf32> into tensor<?xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  flow.dispatch.tensor.store %24, %19, offsets = [0], sizes = [%16], strides = [1] : tensor<?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?xf32>>{%16}
  return
}

// -----// IR Dump After IREEComprehensiveBufferizePass (iree-codegen-iree-comprehensive-bufferize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  scf.forall (%arg0) in (%20) {
    %21 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %subview = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1) in (%22) {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_1 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %24 = vector.transfer_read %17[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %subview_1[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_2 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      memref.copy %subview_1, %subview_2 : memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<linear_dim_0>]}
    %subview_0 = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    memref.copy %subview, %subview_0 : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  memref.copy %19, %19 : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  scf.forall (%arg0) in (%20) {
    %21 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %subview = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1) in (%22) {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_1 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %24 = vector.transfer_read %17[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %subview_1[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_2 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      memref.copy %subview_1, %subview_2 : memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<linear_dim_0>]}
    %subview_0 = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    memref.copy %subview, %subview_0 : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  memref.copy %19, %19 : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  scf.forall (%arg0) in (%20) {
    %21 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %subview = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1) in (%22) {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_1 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %24 = vector.transfer_read %17[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %subview_1[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_2 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      memref.copy %subview_1, %subview_2 : memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<linear_dim_0>]}
    %subview_0 = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    memref.copy %subview, %subview_0 : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  scf.forall (%arg0) in (%20) {
    %21 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %subview = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1) in (%22) {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %24 = vector.transfer_read %17[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      memref.copy %subview_0, %subview_0 : memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<linear_dim_0>]}
    memref.copy %subview, %subview : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  scf.forall (%arg0) in (%20) {
    %21 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %subview = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1) in (%22) {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %24 = vector.transfer_read %17[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<linear_dim_0>]}
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CleanupBufferAllocViewPass (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  scf.forall (%arg0) in (%20) {
    %21 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %subview = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1) in (%22) {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %24 = vector.transfer_read %17[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<linear_dim_0>]}
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  scf.forall (%arg0) in (%20) {
    %21 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %subview = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1) in (%22) {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %24 = vector.transfer_read %17[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<linear_dim_0>]}
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  scf.forall (%arg0) in (%20) {
    %21 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %subview = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1) in (%22) {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %24 = vector.transfer_read %17[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<linear_dim_0>]}
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After NormalizeLoopBoundsPass (iree-codegen-normalize-loop-bounds) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  scf.forall (%arg0) in (%20) {
    %21 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %subview = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1) in (%22) {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %24 = vector.transfer_read %17[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<linear_dim_0>]}
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After GPUVerifyDistributionPass (iree-codegen-gpu-verify-distribution) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %4 = arith.extui %1 : i32 to i64
  %5 = arith.shli %4, %c32_i64 : i64
  %6 = arith.extui %0 : i32 to i64
  %7 = arith.ori %6, %5 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %3 : i32 to i64
  %10 = arith.shli %9, %c32_i64 : i64
  %11 = arith.extui %2 : i32 to i64
  %12 = arith.ori %11, %10 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int 
      %8<umin = 0, umax = 9007199254740991>, 
      %13<umin = 0, umax = 9007199254740991>
    : index, index
  %15 = flow.dispatch.workload.ordinal %14#0, 0 : index
  %16 = flow.dispatch.workload.ordinal %14#1, 1 : index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%16]
  scf.forall (%arg0) in (%20) {
    %21 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%16]
    %subview = memref.subview %19[%21] [%22] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1) in (%22) {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %24 = vector.transfer_read %17[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<linear_dim_0>]}
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After GPUDistributeForallPass (iree-codegen-gpu-distribute-forall) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %23 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    %subview = memref.subview %20[%22] [%23] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %c1 = arith.constant 1 : index
    scf.for %arg1 = %0 to %23 step %c1 {
      %24 = affine.delinearize_index %arg1 into (%23) : index
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%24]
      %subview_0 = memref.subview %subview[%24] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %26 = vector.transfer_read %18[%25], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %27 = vector.transfer_read %19[%25], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %28 = arith.addf %26, %27 : vector<1xf32>
      vector.transfer_write %28, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After VectorizeMemrefCopyPass (iree-codegen-vectorize-memref-copy) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %23 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    %subview = memref.subview %20[%22] [%23] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %0 to %23 step %c1 {
      %24 = affine.delinearize_index %arg1 into (%23) : index
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%24]
      %subview_0 = memref.subview %subview[%24] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %26 = vector.transfer_read %18[%25], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %27 = vector.transfer_read %19[%25], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %28 = arith.addf %26, %27 : vector<1xf32>
      vector.transfer_write %28, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After UnrollToIntrinsicsPass (iree-gpu-unroll-to-intrinsics) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %23 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    %subview = memref.subview %20[%22] [%23] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %0 to %23 step %c1 {
      %24 = affine.delinearize_index %arg1 into (%23) : index
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%24]
      %subview_0 = memref.subview %subview[%24] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %26 = vector.transfer_read %18[%25], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %27 = vector.transfer_read %19[%25], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %28 = arith.addf %26, %27 : vector<1xf32>
      vector.transfer_write %28, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %23 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    %subview = memref.subview %20[%22] [%23] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %0 to %23 step %c1 {
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %25 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = vector.transfer_read %19[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %27 = arith.addf %25, %26 : vector<1xf32>
      vector.transfer_write %27, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %23 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    %subview = memref.subview %20[%22] [%23] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %0 to %23 step %c1 {
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %25 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = vector.transfer_read %19[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %27 = arith.addf %25, %26 : vector<1xf32>
      vector.transfer_write %27, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LowerIREEGPUOpsPass (iree-gpu-lower-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %23 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    %subview = memref.subview %20[%22] [%23] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %0 to %23 step %c1 {
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %25 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = vector.transfer_read %19[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %27 = arith.addf %25, %26 : vector<1xf32>
      vector.transfer_write %27, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After UnrollAnnotatedLoopsPass (iree-codegen-unroll-annotated-loops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %23 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    %subview = memref.subview %20[%22] [%23] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %0 to %23 step %c1 {
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %25 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = vector.transfer_read %19[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %27 = arith.addf %25, %26 : vector<1xf32>
      vector.transfer_write %27, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After IREELoopInvariantCodeMotionPass (iree-loop-invariant-code-motion) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %23 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    %subview = memref.subview %20[%22] [%23] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %0 to %23 step %c1 {
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %25 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = vector.transfer_read %19[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %27 = arith.addf %25, %26 : vector<1xf32>
      vector.transfer_write %27, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After GPUReduceBankConflictsPass (iree-codegen-gpu-reduce-bank-conflicts) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.apply affine_map<(d0) -> (d0 * 32)>(%arg0)
    %23 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    %subview = memref.subview %20[%22] [%23] [1] : memref<?xf32, #hal.descriptor_type<storage_buffer>> to memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %0 to %23 step %c1 {
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %subview_0 = memref.subview %subview[%arg1] [1] [1] : memref<?xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %25 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = vector.transfer_read %19[%24], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %27 = arith.addf %25, %26 : vector<1xf32>
      vector.transfer_write %27, %subview_0[%c0] {in_bounds = [true]} : vector<1xf32>, memref<1xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    scf.for %arg1 = %0 to %22 step %c1 {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %24 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %19[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      %27 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      vector.transfer_write %26, %20[%27] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    scf.for %arg1 = %0 to %22 step %c1 {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %24 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %19[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      %27 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      vector.transfer_write %26, %20[%27] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    scf.for %arg1 = %0 to %22 step %c1 {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %24 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %19[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %20[%23] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After OptimizeVectorTransferPass (iree-codegen-optimize-vector-transfer) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    scf.for %arg1 = %0 to %22 step %c1 {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %24 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %19[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %20[%23] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After HoistStaticallyBoundAllocationsPass (iree-codegen-hoist-statically-bound-allocations) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    scf.for %arg1 = %0 to %22 step %c1 {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %24 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %19[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %20[%23] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    scf.for %arg1 = %0 to %22 step %c1 {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %24 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %19[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %20[%23] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    scf.for %arg1 = %0 to %22 step %c1 {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %24 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %19[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %20[%23] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMGPULowerExecutableTargetPass (iree-llvmgpu-lower-executable-target) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUTileAndFuse workgroup_size = [1, 1, 1] subgroup_size = 32>} {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = flow.dispatch.workload.ordinal %15#0, 0 : index
  %17 = flow.dispatch.workload.ordinal %15#1, 1 : index
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%16}
  memref.assume_alignment %19, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %20 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%17}
  memref.assume_alignment %20, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%17]
  scf.forall (%arg0) in (%21) {
    %22 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%arg0)[%17]
    scf.for %arg1 = %0 to %22 step %c1 {
      %23 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%arg0)[%arg1]
      %24 = vector.transfer_read %18[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %25 = vector.transfer_read %19[%23], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %26 = arith.addf %24, %25 : vector<1xf32>
      vector.transfer_write %26, %20[%23] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #hal.descriptor_type<storage_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After ReconcileTranslationInfoPass (iree-codegen-reconcile-translation-info) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>) {
  hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
    %0 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%arg2]
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %0, %c1, %c1_0 : index, index, index
  }
  builtin.module {
    func.func @foo_dispatch_0_elementwise_D_f32() {
      %c1 = arith.constant 1 : index
      %c32_i64 = arith.constant 32 : i64
      %c0 = arith.constant 0 : index
      %cst = arith.constant 0.000000e+00 : f32
      %thread_id_x = gpu.thread_id  x
      %thread_id_y = gpu.thread_id  y
      %thread_id_z = gpu.thread_id  z
      %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
      %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
      %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
      %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
      %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
      %5 = arith.extui %2 : i32 to i64
      %6 = arith.shli %5, %c32_i64 : i64
      %7 = arith.extui %1 : i32 to i64
      %8 = arith.ori %7, %6 : i64
      %9 = arith.index_castui %8 : i64 to index
      %10 = arith.extui %4 : i32 to i64
      %11 = arith.shli %10, %c32_i64 : i64
      %12 = arith.extui %3 : i32 to i64
      %13 = arith.ori %12, %11 : i64
      %14 = arith.index_castui %13 : i64 to index
      %15:2 = util.assume.int 
          %9<umin = 0, umax = 9007199254740991>, 
          %14<umin = 0, umax = 9007199254740991>
        : index, index
      %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15#1}
      memref.assume_alignment %16, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
      %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15#0}
      memref.assume_alignment %17, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
      %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #hal.descriptor_type<storage_buffer>>{%15#1}
      memref.assume_alignment %18, 64 : memref<?xf32, #hal.descriptor_type<storage_buffer>>
      %19 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%15#1]
      %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%15#1]
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %21 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%workgroup_id_x)[%15#1]
      scf.for %arg0 = %0 to %21 step %c1 {
        %22 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%workgroup_id_x)[%arg0]
        %23 = vector.transfer_read %16[%22], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
        %24 = vector.transfer_read %17[%22], %cst {in_bounds = [true]} : memref<?xf32, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
        %25 = arith.addf %23, %24 : vector<1xf32>
        vector.transfer_write %25, %18[%22] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #hal.descriptor_type<storage_buffer>>
      }
      return
    }
  }
}

// -----// IR Dump After ConvertHALDescriptorTypeToGPUAddressSpacePass (iree-codegen-convert-hal-descriptor-type-to-gpu-address-space) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() {
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %thread_id_x = gpu.thread_id  x
    %thread_id_y = gpu.thread_id  y
    %thread_id_z = gpu.thread_id  z
    %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
    %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %5 = arith.extui %2 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.extui %1 : i32 to i64
    %8 = arith.ori %7, %6 : i64
    %9 = arith.index_castui %8 : i64 to index
    %10 = arith.extui %4 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.extui %3 : i32 to i64
    %13 = arith.ori %12, %11 : i64
    %14 = arith.index_castui %13 : i64 to index
    %15:2 = util.assume.int 
        %9<umin = 0, umax = 9007199254740991>, 
        %14<umin = 0, umax = 9007199254740991>
      : index, index
    %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#1}
    memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#0}
    memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15#1}
    memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
    %19 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%15#1]
    %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%15#1]
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %21 = affine.min affine_map<(d0)[s0] -> (d0 * -32 + s0, 32)>(%workgroup_id_x)[%15#1]
    scf.for %arg0 = %0 to %21 step %c1 {
      %22 = affine.apply affine_map<(d0)[s0] -> (d0 * 32 + s0)>(%workgroup_id_x)[%arg0]
      %23 = vector.transfer_read %16[%22], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
      %24 = vector.transfer_read %17[%22], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
      %25 = arith.addf %23, %24 : vector<1xf32>
      vector.transfer_write %25, %18[%22] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
    }
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() {
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %thread_id_x = gpu.thread_id  x
    %thread_id_y = gpu.thread_id  y
    %thread_id_z = gpu.thread_id  z
    %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
    %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %5 = arith.extui %2 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.extui %1 : i32 to i64
    %8 = arith.ori %7, %6 : i64
    %9 = arith.index_castui %8 : i64 to index
    %10 = arith.extui %4 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.extui %3 : i32 to i64
    %13 = arith.ori %12, %11 : i64
    %14 = arith.index_castui %13 : i64 to index
    %15:2 = util.assume.int 
        %9<umin = 0, umax = 9007199254740991>, 
        %14<umin = 0, umax = 9007199254740991>
      : index, index
    %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#1}
    memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#0}
    memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15#1}
    memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %19 = affine.min affine_map<()[s0, s1] -> (32, s0 - s1 * 32)>()[%15#1, %workgroup_id_x]
    scf.for %arg0 = %0 to %19 step %c1 {
      %20 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 32)>()[%arg0, %workgroup_id_x]
      %21 = vector.transfer_read %16[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
      %22 = vector.transfer_read %17[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
      %23 = arith.addf %21, %22 : vector<1xf32>
      vector.transfer_write %23, %18[%20] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
    }
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() {
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %thread_id_x = gpu.thread_id  x
    %thread_id_y = gpu.thread_id  y
    %thread_id_z = gpu.thread_id  z
    %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
    %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %5 = arith.extui %2 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.extui %1 : i32 to i64
    %8 = arith.ori %7, %6 : i64
    %9 = arith.index_castui %8 : i64 to index
    %10 = arith.extui %4 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.extui %3 : i32 to i64
    %13 = arith.ori %12, %11 : i64
    %14 = arith.index_castui %13 : i64 to index
    %15:2 = util.assume.int 
        %9<umin = 0, umax = 9007199254740991>, 
        %14<umin = 0, umax = 9007199254740991>
      : index, index
    %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#1}
    memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#0}
    memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15#1}
    memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %19 = affine.min affine_map<()[s0, s1] -> (32, s0 - s1 * 32)>()[%15#1, %workgroup_id_x]
    scf.for %arg0 = %0 to %19 step %c1 {
      %20 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 32)>()[%arg0, %workgroup_id_x]
      %21 = vector.transfer_read %16[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
      %22 = vector.transfer_read %17[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
      %23 = arith.addf %21, %22 : vector<1xf32>
      vector.transfer_write %23, %18[%20] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
    }
    return
  }
}

// -----// IR Dump After LowerUKernelOpsToCallsPass (iree-codegen-lower-ukernel-ops-to-calls) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() {
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %thread_id_x = gpu.thread_id  x
    %thread_id_y = gpu.thread_id  y
    %thread_id_z = gpu.thread_id  z
    %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
    %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %5 = arith.extui %2 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.extui %1 : i32 to i64
    %8 = arith.ori %7, %6 : i64
    %9 = arith.index_castui %8 : i64 to index
    %10 = arith.extui %4 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.extui %3 : i32 to i64
    %13 = arith.ori %12, %11 : i64
    %14 = arith.index_castui %13 : i64 to index
    %15:2 = util.assume.int 
        %9<umin = 0, umax = 9007199254740991>, 
        %14<umin = 0, umax = 9007199254740991>
      : index, index
    %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#1}
    memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#0}
    memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15#1}
    memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %19 = affine.min affine_map<()[s0, s1] -> (32, s0 - s1 * 32)>()[%15#1, %workgroup_id_x]
    scf.for %arg0 = %0 to %19 step %c1 {
      %20 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 32)>()[%arg0, %workgroup_id_x]
      %21 = vector.transfer_read %16[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
      %22 = vector.transfer_read %17[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
      %23 = arith.addf %21, %22 : vector<1xf32>
      vector.transfer_write %23, %18[%20] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
    }
    return
  }
}

// -----// IR Dump After LinalgExtToLoopsPass (iree-linalg-ext-to-loops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#0}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %19 = affine.min affine_map<()[s0, s1] -> (32, s0 - s1 * 32)>()[%15#1, %workgroup_id_x]
  scf.for %arg0 = %0 to %19 step %c1 {
    %20 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 32)>()[%arg0, %workgroup_id_x]
    %21 = vector.transfer_read %16[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %22 = vector.transfer_read %17[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %23 = arith.addf %21, %22 : vector<1xf32>
    vector.transfer_write %23, %18[%20] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#0}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %19 = affine.min affine_map<()[s0, s1] -> (32, s0 - s1 * 32)>()[%15#1, %workgroup_id_x]
  scf.for %arg0 = %0 to %19 step %c1 {
    %20 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 32)>()[%arg0, %workgroup_id_x]
    %21 = vector.transfer_read %16[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %22 = vector.transfer_read %17[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %23 = arith.addf %21, %22 : vector<1xf32>
    vector.transfer_write %23, %18[%20] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After ConvertLinalgToLoopsPass (convert-linalg-to-loops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#0}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %19 = affine.min affine_map<()[s0, s1] -> (32, s0 - s1 * 32)>()[%15#1, %workgroup_id_x]
  scf.for %arg0 = %0 to %19 step %c1 {
    %20 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 32)>()[%arg0, %workgroup_id_x]
    %21 = vector.transfer_read %16[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %22 = vector.transfer_read %17[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %23 = arith.addf %21, %22 : vector<1xf32>
    vector.transfer_write %23, %18[%20] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#0}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %19 = affine.min affine_map<()[s0, s1] -> (32, s0 - s1 * 32)>()[%15#1, %workgroup_id_x]
  scf.for %arg0 = %0 to %19 step %c1 {
    %20 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 32)>()[%arg0, %workgroup_id_x]
    %21 = vector.transfer_read %16[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %22 = vector.transfer_read %17[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %23 = arith.addf %21, %22 : vector<1xf32>
    vector.transfer_write %23, %18[%20] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#0}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %19 = affine.min affine_map<()[s0, s1] -> (32, s0 - s1 * 32)>()[%15#1, %workgroup_id_x]
  scf.for %arg0 = %0 to %19 step %c1 {
    %20 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 32)>()[%arg0, %workgroup_id_x]
    %21 = vector.transfer_read %16[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %22 = vector.transfer_read %17[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %23 = arith.addf %21, %22 : vector<1xf32>
    vector.transfer_write %23, %18[%20] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After PadDynamicAllocPass (iree-codegen-pad-dynamic-alloc) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = affine.apply affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>()[%thread_id_x, %thread_id_y, %thread_id_z]
  %1 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %5 = arith.extui %2 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.extui %1 : i32 to i64
  %8 = arith.ori %7, %6 : i64
  %9 = arith.index_castui %8 : i64 to index
  %10 = arith.extui %4 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.extui %3 : i32 to i64
  %13 = arith.ori %12, %11 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15:2 = util.assume.int 
      %9<umin = 0, umax = 9007199254740991>, 
      %14<umin = 0, umax = 9007199254740991>
    : index, index
  %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15#0}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15#1}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %19 = affine.min affine_map<()[s0, s1] -> (32, s0 - s1 * 32)>()[%15#1, %workgroup_id_x]
  scf.for %arg0 = %0 to %19 step %c1 {
    %20 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 32)>()[%arg0, %workgroup_id_x]
    %21 = vector.transfer_read %16[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %22 = vector.transfer_read %17[%20], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %23 = arith.addf %21, %22 : vector<1xf32>
    vector.transfer_write %23, %18[%20] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %c32 = arith.constant 32 : index
  %c-32 = arith.constant -32 : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %c32, %21 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %c32_0 = arith.constant 32 : index
    %23 = arith.muli %workgroup_id_x, %c32_0 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = vector.transfer_read %17[%24], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %26 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %27 = arith.addf %25, %26 : vector<1xf32>
    vector.transfer_write %27, %19[%24] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = vector.transfer_read %17[%24], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %26 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %27 = arith.addf %25, %26 : vector<1xf32>
    vector.transfer_write %27, %19[%24] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = vector.transfer_read %17[%24], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %26 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %27 = arith.addf %25, %26 : vector<1xf32>
    vector.transfer_write %27, %19[%24] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After OneShotBufferize (one-shot-bufferize) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() {
    %c-32 = arith.constant -32 : index
    %c32 = arith.constant 32 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %thread_id_x = gpu.thread_id  x
    %thread_id_y = gpu.thread_id  y
    %thread_id_z = gpu.thread_id  z
    %0 = arith.addi %thread_id_x, %thread_id_y : index
    %1 = arith.addi %0, %thread_id_z : index
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %6 = arith.extui %3 : i32 to i64
    %7 = arith.shli %6, %c32_i64 : i64
    %8 = arith.extui %2 : i32 to i64
    %9 = arith.ori %8, %7 : i64
    %10 = arith.index_castui %9 : i64 to index
    %11 = arith.extui %5 : i32 to i64
    %12 = arith.shli %11, %c32_i64 : i64
    %13 = arith.extui %4 : i32 to i64
    %14 = arith.ori %13, %12 : i64
    %15 = arith.index_castui %14 : i64 to index
    %16:2 = util.assume.int 
        %10<umin = 0, umax = 9007199254740991>, 
        %15<umin = 0, umax = 9007199254740991>
      : index, index
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
    memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
    memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
    %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
    memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %20 = arith.muli %workgroup_id_x, %c-32 : index
    %21 = arith.addi %16#1, %20 : index
    %22 = arith.minsi %21, %c32 : index
    scf.for %arg0 = %1 to %22 step %c1 {
      %23 = arith.muli %workgroup_id_x, %c32 : index
      %24 = arith.addi %arg0, %23 : index
      %25 = vector.transfer_read %17[%24], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
      %26 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
      %27 = arith.addf %25, %26 : vector<1xf32>
      vector.transfer_write %27, %19[%24] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
    }
    return
  }
}

// -----// IR Dump After FoldTensorExtractOpPass (iree-codegen-fold-tensor-extract-op) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %cst = arith.constant 0.000000e+00 : f32
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = vector.transfer_read %17[%24], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %26 = vector.transfer_read %18[%24], %cst {in_bounds = [true]} : memref<?xf32, #gpu.address_space<global>>, vector<1xf32>
    %27 = arith.addf %25, %26 : vector<1xf32>
    vector.transfer_write %27, %19[%24] {in_bounds = [true]} : vector<1xf32>, memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After LLVMGPUVectorLoweringPass (iree-llvmgpu-vector-lowering) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = memref.load %17[%24] : memref<?xf32, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %27 = memref.load %18[%24] : memref<?xf32, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    memref.store %30, %19[%24] : memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After ExpandGPUOpsPass (iree-codegen-expand-gpu-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = memref.load %17[%24] : memref<?xf32, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %27 = memref.load %18[%24] : memref<?xf32, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    memref.store %30, %19[%24] : memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After ExtractAddressComputationGPUPass (extract-address-computation-gpu) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %subview = memref.subview %17[%24] [1] [1] : memref<?xf32, #gpu.address_space<global>> to memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
    %25 = memref.load %subview[%c0] : memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %subview_0 = memref.subview %18[%24] [1] [1] : memref<?xf32, #gpu.address_space<global>> to memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
    %27 = memref.load %subview_0[%c0] : memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    %subview_1 = memref.subview %19[%24] [1] [1] : memref<?xf32, #gpu.address_space<global>> to memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
    memref.store %30, %subview_1[%c0] : memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %subview = memref.subview %17[%24] [1] [1] : memref<?xf32, #gpu.address_space<global>> to memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
    %25 = memref.load %subview[%c0] : memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %subview_0 = memref.subview %18[%24] [1] [1] : memref<?xf32, #gpu.address_space<global>> to memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
    %27 = memref.load %subview_0[%c0] : memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    %subview_1 = memref.subview %19[%24] [1] [1] : memref<?xf32, #gpu.address_space<global>> to memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
    memref.store %30, %subview_1[%c0] : memref<1xf32, strided<[1], offset: ?>, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = memref.load %17[%24] : memref<?xf32, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %27 = memref.load %18[%24] : memref<?xf32, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    memref.store %30, %19[%24] : memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = memref.load %17[%24] : memref<?xf32, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %27 = memref.load %18[%24] : memref<?xf32, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    memref.store %30, %19[%24] : memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After IREELoopInvariantCodeMotionPass (iree-loop-invariant-code-motion) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = memref.load %17[%24] : memref<?xf32, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %27 = memref.load %18[%24] : memref<?xf32, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    memref.store %30, %19[%24] : memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After DecomposeAffineOpsPass (iree-codegen-decompose-affine-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = memref.load %17[%24] : memref<?xf32, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %27 = memref.load %18[%24] : memref<?xf32, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    memref.store %30, %19[%24] : memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = memref.load %17[%24] : memref<?xf32, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %27 = memref.load %18[%24] : memref<?xf32, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    memref.store %30, %19[%24] : memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After IREELoopInvariantCodeMotionPass (iree-loop-invariant-code-motion) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = memref.load %17[%24] : memref<?xf32, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %27 = memref.load %18[%24] : memref<?xf32, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    memref.store %30, %19[%24] : memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = memref.load %17[%24] : memref<?xf32, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %27 = memref.load %18[%24] : memref<?xf32, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    memref.store %30, %19[%24] : memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After GPUCheckResourceUsagePass (iree-codegen-gpu-check-resource-usage) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  scf.for %arg0 = %1 to %22 step %c1 {
    %23 = arith.muli %workgroup_id_x, %c32 : index
    %24 = arith.addi %arg0, %23 : index
    %25 = memref.load %17[%24] : memref<?xf32, #gpu.address_space<global>>
    %26 = vector.broadcast %25 : f32 to vector<1xf32>
    %27 = memref.load %18[%24] : memref<?xf32, #gpu.address_space<global>>
    %28 = vector.broadcast %27 : f32 to vector<1xf32>
    %29 = arith.addf %26, %28 : vector<1xf32>
    %30 = vector.extract %29[0] : f32 from vector<1xf32>
    memref.store %30, %19[%24] : memref<?xf32, #gpu.address_space<global>>
  }
  return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = vector.broadcast %27 : f32 to vector<1xf32>
  %29 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = vector.broadcast %29 : f32 to vector<1xf32>
  %31 = arith.addf %28, %30 : vector<1xf32>
  %32 = vector.extract %31[0] : f32 from vector<1xf32>
  memref.store %32, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %33 = arith.addi %23, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = vector.broadcast %27 : f32 to vector<1xf32>
  %29 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = vector.broadcast %29 : f32 to vector<1xf32>
  %31 = arith.addf %28, %30 : vector<1xf32>
  %32 = vector.extract %31[0] : f32 from vector<1xf32>
  memref.store %32, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %33 = arith.addi %23, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = vector.broadcast %27 : f32 to vector<1xf32>
  %29 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = vector.broadcast %29 : f32 to vector<1xf32>
  %31 = arith.addf %28, %30 : vector<1xf32>
  %32 = vector.extract %31[0] : f32 from vector<1xf32>
  memref.store %32, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %33 = arith.addi %23, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After ConvertComplexToStandard (convert-complex-to-standard) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = vector.broadcast %27 : f32 to vector<1xf32>
  %29 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = vector.broadcast %29 : f32 to vector<1xf32>
  %31 = arith.addf %28, %30 : vector<1xf32>
  %32 = vector.extract %31[0] : f32 from vector<1xf32>
  memref.store %32, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %33 = arith.addi %23, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After ConvertBf16ArithToF32Pass (iree-convert-bf16-arith-to-f32) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = vector.broadcast %27 : f32 to vector<1xf32>
  %29 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = vector.broadcast %29 : f32 to vector<1xf32>
  %31 = arith.addf %28, %30 : vector<1xf32>
  %32 = vector.extract %31[0] : f32 from vector<1xf32>
  memref.store %32, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %33 = arith.addi %23, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After ConvertBf16ToUInt16BuffersPass (iree-codegen-convert-bf16-to-uint16-buffers) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = vector.broadcast %27 : f32 to vector<1xf32>
  %29 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = vector.broadcast %29 : f32 to vector<1xf32>
  %31 = arith.addf %28, %30 : vector<1xf32>
  %32 = vector.extract %31[0] : f32 from vector<1xf32>
  memref.store %32, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %33 = arith.addi %23, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After PolynomialApproximationPass (iree-codegen-polynomial-approximation) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = vector.broadcast %27 : f32 to vector<1xf32>
  %29 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = vector.broadcast %29 : f32 to vector<1xf32>
  %31 = arith.addf %28, %30 : vector<1xf32>
  %32 = vector.extract %31[0] : f32 from vector<1xf32>
  memref.store %32, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %33 = arith.addi %23, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = vector.broadcast %27 : f32 to vector<1xf32>
  %29 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = vector.broadcast %29 : f32 to vector<1xf32>
  %31 = arith.addf %28, %30 : vector<1xf32>
  %32 = vector.extract %31[0] : f32 from vector<1xf32>
  memref.store %32, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %33 = arith.addi %23, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = vector.broadcast %27 : f32 to vector<1xf32>
  %29 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = vector.broadcast %29 : f32 to vector<1xf32>
  %31 = arith.addf %28, %30 : vector<1xf32>
  %32 = vector.extract %31[0] : f32 from vector<1xf32>
  memref.store %32, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %33 = arith.addi %23, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = vector.broadcast %27 : f32 to vector<1xf32>
  %29 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = vector.broadcast %29 : f32 to vector<1xf32>
  %31 = arith.addf %28, %30 : vector<1xf32>
  %32 = vector.extract %31[0] : f32 from vector<1xf32>
  memref.store %32, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %33 = arith.addi %23, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After EmulateNarrowTypePass (iree-codegen-emulate-narrow-type) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %29 = arith.addf %27, %28 : f32
  memref.store %29, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = arith.addi %23, %c1 : index
  cf.br ^bb1(%30 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After AffineExpandIndexOps (affine-expand-index-ops) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %29 = arith.addf %27, %28 : f32
  memref.store %29, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = arith.addi %23, %c1 : index
  cf.br ^bb1(%30 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %29 = arith.addf %27, %28 : f32
  memref.store %29, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = arith.addi %23, %c1 : index
  cf.br ^bb1(%30 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %29 = arith.addf %27, %28 : f32
  memref.store %29, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = arith.addi %23, %c1 : index
  cf.br ^bb1(%30 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @foo_dispatch_0_elementwise_D_f32() {
  %c-32 = arith.constant -32 : index
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %thread_id_z = gpu.thread_id  z
  %0 = arith.addi %thread_id_x, %thread_id_y : index
  %1 = arith.addi %0, %thread_id_z : index
  %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
  %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
  %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
  %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
  %6 = arith.extui %3 : i32 to i64
  %7 = arith.shli %6, %c32_i64 : i64
  %8 = arith.extui %2 : i32 to i64
  %9 = arith.ori %8, %7 : i64
  %10 = arith.index_castui %9 : i64 to index
  %11 = arith.extui %5 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.extui %4 : i32 to i64
  %14 = arith.ori %13, %12 : i64
  %15 = arith.index_castui %14 : i64 to index
  %16:2 = util.assume.int 
      %10<umin = 0, umax = 9007199254740991>, 
      %15<umin = 0, umax = 9007199254740991>
    : index, index
  %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
  %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
  memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
  %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
  memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %20 = arith.muli %workgroup_id_x, %c-32 : index
  %21 = arith.addi %16#1, %20 : index
  %22 = arith.minsi %21, %c32 : index
  cf.br ^bb1(%1 : index)
^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
  %24 = arith.cmpi slt, %23, %22 : index
  cf.cond_br %24, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %25 = arith.muli %workgroup_id_x, %c32 : index
  %26 = arith.addi %23, %25 : index
  %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
  %28 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
  %29 = arith.addf %27, %28 : f32
  memref.store %29, %19[%26] : memref<?xf32, #gpu.address_space<global>>
  %30 = arith.addi %23, %c1 : index
  cf.br ^bb1(%30 : index)
^bb3:  // pred: ^bb1
  return
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() {
    %c-32 = arith.constant -32 : index
    %c32 = arith.constant 32 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %thread_id_x = gpu.thread_id  x
    %thread_id_y = gpu.thread_id  y
    %thread_id_z = gpu.thread_id  z
    %0 = arith.addi %thread_id_x, %thread_id_y : index
    %1 = arith.addi %0, %thread_id_z : index
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %6 = arith.extui %3 : i32 to i64
    %7 = arith.shli %6, %c32_i64 : i64
    %8 = arith.extui %2 : i32 to i64
    %9 = arith.ori %8, %7 : i64
    %10 = arith.index_castui %9 : i64 to index
    %11 = arith.extui %5 : i32 to i64
    %12 = arith.shli %11, %c32_i64 : i64
    %13 = arith.extui %4 : i32 to i64
    %14 = arith.ori %13, %12 : i64
    %15 = arith.index_castui %14 : i64 to index
    %16:2 = util.assume.int 
        %10<umin = 0, umax = 9007199254740991>, 
        %15<umin = 0, umax = 9007199254740991>
      : index, index
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
    memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
    memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
    %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
    memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %20 = arith.muli %workgroup_id_x, %c-32 : index
    %21 = arith.addi %16#1, %20 : index
    %22 = arith.minsi %21, %c32 : index
    cf.br ^bb1(%1 : index)
  ^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
    %24 = arith.cmpi slt, %23, %22 : index
    cf.cond_br %24, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %25 = arith.muli %workgroup_id_x, %c32 : index
    %26 = arith.addi %23, %25 : index
    %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
    %28 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
    %29 = arith.addf %27, %28 : f32
    memref.store %29, %19[%26] : memref<?xf32, #gpu.address_space<global>>
    %30 = arith.addi %23, %c1 : index
    cf.br ^bb1(%30 : index)
  ^bb3:  // pred: ^bb1
    return
  }
}

// -----// IR Dump After LLVMGPUCastAddressSpaceFunctionPass (iree-llvmgpu-cast-address-space-function) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() {
    %c-32 = arith.constant -32 : index
    %c32 = arith.constant 32 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %thread_id_x = gpu.thread_id  x
    %thread_id_y = gpu.thread_id  y
    %thread_id_z = gpu.thread_id  z
    %0 = arith.addi %thread_id_x, %thread_id_y : index
    %1 = arith.addi %0, %thread_id_z : index
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %6 = arith.extui %3 : i32 to i64
    %7 = arith.shli %6, %c32_i64 : i64
    %8 = arith.extui %2 : i32 to i64
    %9 = arith.ori %8, %7 : i64
    %10 = arith.index_castui %9 : i64 to index
    %11 = arith.extui %5 : i32 to i64
    %12 = arith.shli %11, %c32_i64 : i64
    %13 = arith.extui %4 : i32 to i64
    %14 = arith.ori %13, %12 : i64
    %15 = arith.index_castui %14 : i64 to index
    %16:2 = util.assume.int 
        %10<umin = 0, umax = 9007199254740991>, 
        %15<umin = 0, umax = 9007199254740991>
      : index, index
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#1}
    memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%16#0}
    memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
    %19 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%16#1}
    memref.assume_alignment %19, 64 : memref<?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %20 = arith.muli %workgroup_id_x, %c-32 : index
    %21 = arith.addi %16#1, %20 : index
    %22 = arith.minsi %21, %c32 : index
    cf.br ^bb1(%1 : index)
  ^bb1(%23: index):  // 2 preds: ^bb0, ^bb2
    %24 = arith.cmpi slt, %23, %22 : index
    cf.cond_br %24, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %25 = arith.muli %workgroup_id_x, %c32 : index
    %26 = arith.addi %23, %25 : index
    %27 = memref.load %17[%26] : memref<?xf32, #gpu.address_space<global>>
    %28 = memref.load %18[%26] : memref<?xf32, #gpu.address_space<global>>
    %29 = arith.addf %27, %28 : f32
    memref.store %29, %19[%26] : memref<?xf32, #gpu.address_space<global>>
    %30 = arith.addi %23, %c1 : index
    cf.br ^bb1(%30 : index)
  ^bb3:  // pred: ^bb1
    return
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
module {
  func.func @foo_dispatch_0_elementwise_D_f32() {
    %c-32 = arith.constant -32 : index
    %c32 = arith.constant 32 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %thread_id_x = gpu.thread_id  x
    %thread_id_y = gpu.thread_id  y
    %thread_id_z = gpu.thread_id  z
    %0 = arith.addi %thread_id_x, %thread_id_y : index
    %1 = arith.addi %0, %thread_id_z : index
    %2 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(0) : i32
    %3 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(1) : i32
    %4 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(2) : i32
    %5 = hal.interface.constant.load layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) ordinal(3) : i32
    %6 = arith.extui %3 : i32 to i64
    %7 = arith.shli %6, %c32_i64 : i64
    %8 = arith.extui %2 : i32 to i64
    %9 = arith.ori %8, %7 : i64
    %10 = arith.index_castui %9 : i64 to index
    %11 = arith.extui %5 : i32 to i64
    %12 = arith.shli %11, %c32_i64 : i64
    %13 = arith.extui %4 : i32 to i64
    %14 = arith.ori %13, %12 : i64
    %15 = arith.index_castui %14 : i64 to index
    %16 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%15}
    memref.assume_alignment %16, 64 : memref<?xf32, #gpu.address_space<global>>
    %17 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<?xf32, #gpu.address_space<global>>{%10}
    memref.assume_alignment %17, 64 : memref<?xf32, #gpu.address_space<global>>
    %18 = hal.interface.binding.subspan layout(<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<?xf32, #gpu.address_space<global>>{%15}
    memref.assume_alignment %18, 64 : memref<?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %19 = arith.muli %workgroup_id_x, %c-32 : index
    %20 = arith.addi %15, %19 : index
    %21 = arith.minsi %20, %c32 : index
    cf.br ^bb1(%1 : index)
  ^bb1(%22: index):  // 2 preds: ^bb0, ^bb2
    %23 = arith.cmpi slt, %22, %21 : index
    cf.cond_br %23, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %24 = arith.muli %workgroup_id_x, %c32 : index
    %25 = arith.addi %22, %24 : index
    %26 = memref.load %16[%25] : memref<?xf32, #gpu.address_space<global>>
    %27 = memref.load %17[%25] : memref<?xf32, #gpu.address_space<global>>
    %28 = arith.addf %26, %27 : f32
    memref.store %28, %18[%25] : memref<?xf32, #gpu.address_space<global>>
    %29 = arith.addi %22, %c1 : index
    cf.br ^bb1(%29 : index)
  ^bb3:  // pred: ^bb1
    return
  }
}

// -----// IR Dump After ConvertToNVVMPass (iree-convert-to-nvvm) //----- //
module {
  llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
    %0 = llvm.mlir.constant(63 : index) : i64
    %1 = llvm.mlir.constant(-32 : index) : i64
    %2 = llvm.mlir.constant(32 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = llvm.mlir.constant(32 : i64) : i64
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = nvvm.read.ptx.sreg.tid.x : i32
    %7 = llvm.sext %6 : i32 to i64
    %8 = nvvm.read.ptx.sreg.tid.y : i32
    %9 = llvm.sext %8 : i32 to i64
    %10 = nvvm.read.ptx.sreg.tid.z : i32
    %11 = llvm.sext %10 : i32 to i64
    %12 = llvm.add %7, %9 : i64
    %13 = llvm.add %12, %11 : i64
    %14 = llvm.zext %arg6 : i32 to i64
    %15 = llvm.shl %14, %4 : i64
    %16 = llvm.zext %arg5 : i32 to i64
    %17 = llvm.or %16, %15 : i64
    %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
    %19 = llvm.and %18, %0 : i64
    %20 = llvm.icmp "eq" %19, %5 : i64
    llvm.intr.assume %20 : i1
    %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
    %22 = llvm.and %21, %0 : i64
    %23 = llvm.icmp "eq" %22, %5 : i64
    llvm.intr.assume %23 : i1
    %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %25 = llvm.and %24, %0 : i64
    %26 = llvm.icmp "eq" %25, %5 : i64
    llvm.intr.assume %26 : i1
    %27 = nvvm.read.ptx.sreg.ctaid.x : i32
    %28 = llvm.sext %27 : i32 to i64
    %29 = llvm.mul %28, %1 : i64
    %30 = llvm.add %17, %29 : i64
    %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
    llvm.br ^bb1(%13 : i64)
  ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
    %33 = llvm.icmp "slt" %32, %31 : i64
    llvm.cond_br %33, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %34 = llvm.mul %28, %2 : i64
    %35 = llvm.add %32, %34 : i64
    %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %37 = llvm.load %36 : !llvm.ptr<1> -> f32
    %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %39 = llvm.load %38 : !llvm.ptr<1> -> f32
    %40 = llvm.fadd %37, %39 : f32
    %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    llvm.store %40, %41 : f32, !llvm.ptr<1>
    %42 = llvm.add %32, %3 : i64
    llvm.br ^bb1(%42 : i64)
  ^bb3:  // pred: ^bb1
    llvm.return
  }
}

// -----// IR Dump After TranslateTargetExecutableVariantsPass (iree-hal-translate-target-executable-variants) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>) {
  hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
    %0 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%arg2]
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %0, %c1, %c1_0 : index, index, index
  }
  builtin.module {
    llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
      %0 = llvm.mlir.constant(63 : index) : i64
      %1 = llvm.mlir.constant(-32 : index) : i64
      %2 = llvm.mlir.constant(32 : index) : i64
      %3 = llvm.mlir.constant(1 : index) : i64
      %4 = llvm.mlir.constant(32 : i64) : i64
      %5 = llvm.mlir.constant(0 : index) : i64
      %6 = nvvm.read.ptx.sreg.tid.x : i32
      %7 = llvm.sext %6 : i32 to i64
      %8 = nvvm.read.ptx.sreg.tid.y : i32
      %9 = llvm.sext %8 : i32 to i64
      %10 = nvvm.read.ptx.sreg.tid.z : i32
      %11 = llvm.sext %10 : i32 to i64
      %12 = llvm.add %7, %9 : i64
      %13 = llvm.add %12, %11 : i64
      %14 = llvm.zext %arg6 : i32 to i64
      %15 = llvm.shl %14, %4 : i64
      %16 = llvm.zext %arg5 : i32 to i64
      %17 = llvm.or %16, %15 : i64
      %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
      %19 = llvm.and %18, %0 : i64
      %20 = llvm.icmp "eq" %19, %5 : i64
      llvm.intr.assume %20 : i1
      %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
      %22 = llvm.and %21, %0 : i64
      %23 = llvm.icmp "eq" %22, %5 : i64
      llvm.intr.assume %23 : i1
      %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %25 = llvm.and %24, %0 : i64
      %26 = llvm.icmp "eq" %25, %5 : i64
      llvm.intr.assume %26 : i1
      %27 = nvvm.read.ptx.sreg.ctaid.x : i32
      %28 = llvm.sext %27 : i32 to i64
      %29 = llvm.mul %28, %1 : i64
      %30 = llvm.add %17, %29 : i64
      %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
      llvm.br ^bb1(%13 : i64)
    ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
      %33 = llvm.icmp "slt" %32, %31 : i64
      llvm.cond_br %33, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %34 = llvm.mul %28, %2 : i64
      %35 = llvm.add %32, %34 : i64
      %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %37 = llvm.load %36 : !llvm.ptr<1> -> f32
      %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %39 = llvm.load %38 : !llvm.ptr<1> -> f32
      %40 = llvm.fadd %37, %39 : f32
      %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      llvm.store %40, %41 : f32, !llvm.ptr<1>
      %42 = llvm.add %32, %3 : i64
      llvm.br ^bb1(%42 : i64)
    ^bb3:  // pred: ^bb1
      llvm.return
    }
  }
}

// -----// IR Dump After TranslateExecutablesPass (iree-hal-translate-executables) //----- //
hal.executable private @foo_dispatch_0 {
  hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>) {
    hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
    ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
      %0 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%arg2]
      %c1 = arith.constant 1 : index
      %c1_0 = arith.constant 1 : index
      hal.return %0, %c1, %c1_0 : index, index, index
    }
    builtin.module {
      llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %0 = llvm.mlir.constant(63 : index) : i64
        %1 = llvm.mlir.constant(-32 : index) : i64
        %2 = llvm.mlir.constant(32 : index) : i64
        %3 = llvm.mlir.constant(1 : index) : i64
        %4 = llvm.mlir.constant(32 : i64) : i64
        %5 = llvm.mlir.constant(0 : index) : i64
        %6 = nvvm.read.ptx.sreg.tid.x : i32
        %7 = llvm.sext %6 : i32 to i64
        %8 = nvvm.read.ptx.sreg.tid.y : i32
        %9 = llvm.sext %8 : i32 to i64
        %10 = nvvm.read.ptx.sreg.tid.z : i32
        %11 = llvm.sext %10 : i32 to i64
        %12 = llvm.add %7, %9 : i64
        %13 = llvm.add %12, %11 : i64
        %14 = llvm.zext %arg6 : i32 to i64
        %15 = llvm.shl %14, %4 : i64
        %16 = llvm.zext %arg5 : i32 to i64
        %17 = llvm.or %16, %15 : i64
        %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
        %19 = llvm.and %18, %0 : i64
        %20 = llvm.icmp "eq" %19, %5 : i64
        llvm.intr.assume %20 : i1
        %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
        %22 = llvm.and %21, %0 : i64
        %23 = llvm.icmp "eq" %22, %5 : i64
        llvm.intr.assume %23 : i1
        %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
        %25 = llvm.and %24, %0 : i64
        %26 = llvm.icmp "eq" %25, %5 : i64
        llvm.intr.assume %26 : i1
        %27 = nvvm.read.ptx.sreg.ctaid.x : i32
        %28 = llvm.sext %27 : i32 to i64
        %29 = llvm.mul %28, %1 : i64
        %30 = llvm.add %17, %29 : i64
        %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
        llvm.br ^bb1(%13 : i64)
      ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
        %33 = llvm.icmp "slt" %32, %31 : i64
        llvm.cond_br %33, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        %34 = llvm.mul %28, %2 : i64
        %35 = llvm.add %32, %34 : i64
        %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %37 = llvm.load %36 : !llvm.ptr<1> -> f32
        %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %39 = llvm.load %38 : !llvm.ptr<1> -> f32
        %40 = llvm.fadd %37, %39 : f32
        %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        llvm.store %40, %41 : f32, !llvm.ptr<1>
        %42 = llvm.add %32, %3 : i64
        llvm.br ^bb1(%42 : i64)
      ^bb3:  // pred: ^bb1
        llvm.return
      }
    }
  }
}

// -----// IR Dump After ConvertToHALPass (iree-hal-conversion) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %0 = affine.apply #map()[%arg2]
        %c1 = arith.constant 1 : index
        %c1_0 = arith.constant 1 : index
        hal.return %0, %c1, %c1_0 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%1) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%2]) type(%element_type_f32) encoding(%dense_row_major)
    %3 = arith.muli %2, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    %__device_0_1 = util.global.load immutable @__device_0 : !hal.device
    %allocator_2 = hal.device.allocator<%__device_0_1 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator_2 : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %__device_0_3 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%__device_0_3 : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %transient_buffer = hal.device.queue.alloca<%__device_0_3 : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%1}
    %5 = arith.index_castui %2 : index to i64
    %6 = arith.index_castui %2 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %0 : index to i64
    %10 = arith.index_castui %0 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %__device_0_4 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64_5 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%__device_0_4 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64_5) : !hal.command_buffer
    %13 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %14 = affine.apply #map()[%0]
    %c1 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %exe = hal.executable.lookup device(%13 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%14, %c1, %c1_6]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %1], 
      (%buffer_0 : !hal.buffer)[%c0, %3], 
      (%transient_buffer : !hal.buffer)[%c0, %1]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_7 = hal.fence.create device(%__device_0_4 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0_4 : !hal.device> affinity(%c-1_i64_5) wait(%fence) signal(%fence_7) commands([%cmd])
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%fence_7]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %dense_row_major_8 = hal.encoding_type<dense_row_major> : i32
    %element_type_f32_9 = hal.element_type<f32> : i32
    %c0_10 = arith.constant 0 : index
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0_10, %1] shape([%0]) type(%element_type_f32_9) encoding(%dense_row_major_8) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After OutlineMemoizeRegionsPass (iree-hal-outline-memoize-regions) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %0 = affine.apply #map()[%arg2]
        %c1 = arith.constant 1 : index
        %c1_0 = arith.constant 1 : index
        hal.return %0, %c1, %c1_0 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%1) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%2]) type(%element_type_f32) encoding(%dense_row_major)
    %3 = arith.muli %2, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    %__device_0_1 = util.global.load immutable @__device_0 : !hal.device
    %allocator_2 = hal.device.allocator<%__device_0_1 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator_2 : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %__device_0_3 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%__device_0_3 : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %transient_buffer = hal.device.queue.alloca<%__device_0_3 : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%1}
    %5 = arith.index_castui %2 : index to i64
    %6 = arith.index_castui %2 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %0 : index to i64
    %10 = arith.index_castui %0 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %__device_0_4 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64_5 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%__device_0_4 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64_5) : !hal.command_buffer
    %13 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %14 = affine.apply #map()[%0]
    %c1 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %exe = hal.executable.lookup device(%13 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%14, %c1, %c1_6]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %1], 
      (%buffer_0 : !hal.buffer)[%c0, %3], 
      (%transient_buffer : !hal.buffer)[%c0, %1]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_7 = hal.fence.create device(%__device_0_4 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0_4 : !hal.device> affinity(%c-1_i64_5) wait(%fence) signal(%fence_7) commands([%cmd])
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%fence_7]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %dense_row_major_8 = hal.encoding_type<dense_row_major> : i32
    %element_type_f32_9 = hal.element_type<f32> : i32
    %c0_10 = arith.constant 0 : index
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0_10, %1] shape([%0]) type(%element_type_f32_9) encoding(%dense_row_major_8) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FixupLegacySyncPass (iree-hal-fixup-legacy-sync) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %0 = affine.apply #map()[%arg2]
        %c1 = arith.constant 1 : index
        %c1_0 = arith.constant 1 : index
        hal.return %0, %c1, %c1_0 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%1) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%2]) type(%element_type_f32) encoding(%dense_row_major)
    %3 = arith.muli %2, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    %__device_0_1 = util.global.load immutable @__device_0 : !hal.device
    %allocator_2 = hal.device.allocator<%__device_0_1 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator_2 : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %__device_0_3 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%__device_0_3 : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %transient_buffer = hal.device.queue.alloca<%__device_0_3 : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%1}
    %5 = arith.index_castui %2 : index to i64
    %6 = arith.index_castui %2 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %0 : index to i64
    %10 = arith.index_castui %0 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %__device_0_4 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64_5 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%__device_0_4 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64_5) : !hal.command_buffer
    %13 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %14 = affine.apply #map()[%0]
    %c1 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %exe = hal.executable.lookup device(%13 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%14, %c1, %c1_6]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %1], 
      (%buffer_0 : !hal.buffer)[%c0, %3], 
      (%transient_buffer : !hal.buffer)[%c0, %1]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_7 = hal.fence.create device(%__device_0_4 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0_4 : !hal.device> affinity(%c-1_i64_5) wait(%fence) signal(%fence_7) commands([%cmd])
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%fence_7]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %dense_row_major_8 = hal.encoding_type<dense_row_major> : i32
    %element_type_f32_9 = hal.element_type<f32> : i32
    %c0_10 = arith.constant 0 : index
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0_10, %1] shape([%0]) type(%element_type_f32_9) encoding(%dense_row_major_8) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After PruneExecutablesPass (iree-hal-prune-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %0 = affine.apply #map()[%arg2]
        %c1 = arith.constant 1 : index
        %c1_0 = arith.constant 1 : index
        hal.return %0, %c1, %c1_0 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%0]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = arith.muli %0, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%1) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %2 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%2]) type(%element_type_f32) encoding(%dense_row_major)
    %3 = arith.muli %2, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    %__device_0_1 = util.global.load immutable @__device_0 : !hal.device
    %allocator_2 = hal.device.allocator<%__device_0_1 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator_2 : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %__device_0_3 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%__device_0_3 : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %transient_buffer = hal.device.queue.alloca<%__device_0_3 : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%1}
    %5 = arith.index_castui %2 : index to i64
    %6 = arith.index_castui %2 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %0 : index to i64
    %10 = arith.index_castui %0 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %__device_0_4 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64_5 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%__device_0_4 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64_5) : !hal.command_buffer
    %13 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %14 = affine.apply #map()[%0]
    %c1 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %exe = hal.executable.lookup device(%13 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%14, %c1, %c1_6]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %1], 
      (%buffer_0 : !hal.buffer)[%c0, %3], 
      (%transient_buffer : !hal.buffer)[%c0, %1]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_7 = hal.fence.create device(%__device_0_4 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0_4 : !hal.device> affinity(%c-1_i64_5) wait(%fence) signal(%fence_7) commands([%cmd])
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%fence_7]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %dense_row_major_8 = hal.encoding_type<dense_row_major> : i32
    %element_type_f32_9 = hal.element_type<f32> : i32
    %c0_10 = arith.constant 0 : index
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0_10, %1] shape([%0]) type(%element_type_f32_9) encoding(%dense_row_major_8) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c1 = arith.constant 1 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  %__device_0_1 = util.global.load immutable @__device_0 : !hal.device
  %allocator_2 = hal.device.allocator<%__device_0_1 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator_2 : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %__device_0_3 = util.global.load immutable @__device_0 : !hal.device
  %fence = hal.fence.create device(%__device_0_3 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0_3 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %__device_0_4 = util.global.load immutable @__device_0 : !hal.device
  %cmd = hal.command_buffer.create device(%__device_0_4 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%1]
  %exe = hal.executable.lookup device(%__device_0_4 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
  %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_5 = hal.fence.create device(%__device_0_4 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0_4 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_5) commands([%cmd])
  %status = hal.fence.await until([%fence_5]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %dense_row_major_6 = hal.encoding_type<dense_row_major> : i32
  %element_type_f32_7 = hal.element_type<f32> : i32
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32_7) encoding(%dense_row_major_6) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c1 = arith.constant 1 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%1]
  %exe = hal.executable.lookup device(%__device_0 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
  %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %c-1_i32 = arith.constant -1 : i32
  %c1 = arith.constant 1 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%1]
  %exe = hal.executable.lookup device(%__device_0 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
  %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%1]
  %exe = hal.executable.lookup device(%__device_0 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
  %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    %exe = hal.executable.lookup device(%__device_0 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    %exe = hal.executable.lookup device(%__device_0 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After LLVMGPULinkExecutablesPass (iree-llvmgpu-link-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    %exe = hal.executable.lookup device(%__device_0 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
hal.executable private @foo_dispatch_0 {
  hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>) {
    hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
    ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
      %c1 = arith.constant 1 : index
      %0 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%arg2]
      hal.return %0, %c1, %c1 : index, index, index
    }
    builtin.module {
      llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
        %0 = llvm.mlir.constant(63 : index) : i64
        %1 = llvm.mlir.constant(-32 : index) : i64
        %2 = llvm.mlir.constant(32 : index) : i64
        %3 = llvm.mlir.constant(1 : index) : i64
        %4 = llvm.mlir.constant(32 : i64) : i64
        %5 = llvm.mlir.constant(0 : index) : i64
        %6 = nvvm.read.ptx.sreg.tid.x : i32
        %7 = llvm.sext %6 : i32 to i64
        %8 = nvvm.read.ptx.sreg.tid.y : i32
        %9 = llvm.sext %8 : i32 to i64
        %10 = nvvm.read.ptx.sreg.tid.z : i32
        %11 = llvm.sext %10 : i32 to i64
        %12 = llvm.add %7, %9 : i64
        %13 = llvm.add %12, %11 : i64
        %14 = llvm.zext %arg6 : i32 to i64
        %15 = llvm.shl %14, %4 : i64
        %16 = llvm.zext %arg5 : i32 to i64
        %17 = llvm.or %16, %15 : i64
        %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
        %19 = llvm.and %18, %0 : i64
        %20 = llvm.icmp "eq" %19, %5 : i64
        llvm.intr.assume %20 : i1
        %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
        %22 = llvm.and %21, %0 : i64
        %23 = llvm.icmp "eq" %22, %5 : i64
        llvm.intr.assume %23 : i1
        %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
        %25 = llvm.and %24, %0 : i64
        %26 = llvm.icmp "eq" %25, %5 : i64
        llvm.intr.assume %26 : i1
        %27 = nvvm.read.ptx.sreg.ctaid.x : i32
        %28 = llvm.sext %27 : i32 to i64
        %29 = llvm.mul %28, %1 : i64
        %30 = llvm.add %17, %29 : i64
        %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
        llvm.br ^bb1(%13 : i64)
      ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
        %33 = llvm.icmp "slt" %32, %31 : i64
        llvm.cond_br %33, ^bb2, ^bb3
      ^bb2:  // pred: ^bb1
        %34 = llvm.mul %28, %2 : i64
        %35 = llvm.add %32, %34 : i64
        %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %37 = llvm.load %36 : !llvm.ptr<1> -> f32
        %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %39 = llvm.load %38 : !llvm.ptr<1> -> f32
        %40 = llvm.fadd %37, %39 : f32
        %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        llvm.store %40, %41 : f32, !llvm.ptr<1>
        %42 = llvm.add %32, %3 : i64
        llvm.br ^bb1(%42 : i64)
      ^bb3:  // pred: ^bb1
        llvm.return
      }
    }
  }
}

// -----// IR Dump After LLVMGPUAssignConstantOrdinalsPass (iree-llvmgpu-assign-constant-ordinals) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>) {
  hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
    %c1 = arith.constant 1 : index
    %0 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%arg2]
    hal.return %0, %c1, %c1 : index, index, index
  }
  builtin.module {
    llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
      %0 = llvm.mlir.constant(63 : index) : i64
      %1 = llvm.mlir.constant(-32 : index) : i64
      %2 = llvm.mlir.constant(32 : index) : i64
      %3 = llvm.mlir.constant(1 : index) : i64
      %4 = llvm.mlir.constant(32 : i64) : i64
      %5 = llvm.mlir.constant(0 : index) : i64
      %6 = nvvm.read.ptx.sreg.tid.x : i32
      %7 = llvm.sext %6 : i32 to i64
      %8 = nvvm.read.ptx.sreg.tid.y : i32
      %9 = llvm.sext %8 : i32 to i64
      %10 = nvvm.read.ptx.sreg.tid.z : i32
      %11 = llvm.sext %10 : i32 to i64
      %12 = llvm.add %7, %9 : i64
      %13 = llvm.add %12, %11 : i64
      %14 = llvm.zext %arg6 : i32 to i64
      %15 = llvm.shl %14, %4 : i64
      %16 = llvm.zext %arg5 : i32 to i64
      %17 = llvm.or %16, %15 : i64
      %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
      %19 = llvm.and %18, %0 : i64
      %20 = llvm.icmp "eq" %19, %5 : i64
      llvm.intr.assume %20 : i1
      %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
      %22 = llvm.and %21, %0 : i64
      %23 = llvm.icmp "eq" %22, %5 : i64
      llvm.intr.assume %23 : i1
      %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %25 = llvm.and %24, %0 : i64
      %26 = llvm.icmp "eq" %25, %5 : i64
      llvm.intr.assume %26 : i1
      %27 = nvvm.read.ptx.sreg.ctaid.x : i32
      %28 = llvm.sext %27 : i32 to i64
      %29 = llvm.mul %28, %1 : i64
      %30 = llvm.add %17, %29 : i64
      %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
      llvm.br ^bb1(%13 : i64)
    ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
      %33 = llvm.icmp "slt" %32, %31 : i64
      llvm.cond_br %33, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %34 = llvm.mul %28, %2 : i64
      %35 = llvm.add %32, %34 : i64
      %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %37 = llvm.load %36 : !llvm.ptr<1> -> f32
      %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %39 = llvm.load %38 : !llvm.ptr<1> -> f32
      %40 = llvm.fadd %37, %39 : f32
      %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      llvm.store %40, %41 : f32, !llvm.ptr<1>
      %42 = llvm.add %32, %3 : i64
      llvm.br ^bb1(%42 : i64)
    ^bb3:  // pred: ^bb1
      llvm.return
    }
  }
}

// -----// IR Dump After LinkTargetExecutablesPass (iree-hal-link-target-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    %exe = hal.executable.lookup device(%__device_0 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    %exe = hal.executable.lookup device(%__device_0 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After LinkExecutablesPass (iree-hal-link-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    %exe = hal.executable.lookup device(%__device_0 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@foo_dispatch_0::@cuda_nvptx_fb::@foo_dispatch_0_elementwise_D_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveExportOrdinalsPass (iree-hal-resolve-export-ordinals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    %exe = hal.executable.lookup device(%__device_0 : !hal.device) executable(@foo_dispatch_0) : !hal.executable
    %c0_1 = arith.constant 0 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%c0_1] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_2 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_2) commands([%cmd])
    %status = hal.fence.await until([%fence_2]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeResourceCachesPass (iree-hal-materialize-resource-caches) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    }
    default {
      %c14_i32 = arith.constant 14 : i32
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    %__device_0_executable_0_foo_dispatch_0 = util.global.load @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %c0_1 = arith.constant 0 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0_1] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_2 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_2) commands([%cmd])
    %status = hal.fence.await until([%fence_2]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After MemoizeDeviceQueriesPass (iree-hal-memoize-device-queries) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb_ok : i1
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %ok, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb_ok : i1
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb_ok = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb_ok : i1
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    }
    default {
      %c14_i32 = arith.constant 14 : i32
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    %__device_0_executable_0_foo_dispatch_0 = util.global.load @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %c0_1 = arith.constant 0 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0_1] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_2 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_2) commands([%cmd])
    %status = hal.fence.await until([%fence_2]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %ok, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb_ok : i1
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %ok, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb_ok : i1
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.global.store %ok, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb_ok : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %__device_0 = util.global.load @__device_0 : !hal.device
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = scf.index_switch %1 -> !hal.executable 
  case 0 {
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    scf.yield %executable : !hal.executable
  }
  default {
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    scf.yield %0 : !hal.executable
  }
  util.global.store %2, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%1]
  %__device_0_executable_0_foo_dispatch_0 = util.global.load @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %__device_0 = util.global.load @__device_0 : !hal.device
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = scf.index_switch %1 -> !hal.executable 
  case 0 {
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    scf.yield %executable : !hal.executable
  }
  default {
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    scf.yield %0 : !hal.executable
  }
  util.global.store %2, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.global.store %ok, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb_ok : i1
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%1]
  %__device_0_executable_0_foo_dispatch_0 = util.global.load @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = scf.index_switch %1 -> !hal.executable 
  case 0 {
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    scf.yield %executable : !hal.executable
  }
  default {
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    scf.yield %0 : !hal.executable
  }
  util.global.store %2, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%1]
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  %3 = scf.if %2 -> (!hal.executable) {
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    scf.yield %executable : !hal.executable
  } else {
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    scf.yield %0 : !hal.executable
  }
  util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c1 = arith.constant 1 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%1]
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    %3 = scf.if %2 -> (!hal.executable) {
      %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    } else {
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
      scf.yield %0 : !hal.executable
    }
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_cuda = #hal.device.target<"cuda", [#executable_target_cuda_nvptx_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_cuda
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    %3 = scf.if %2 -> (!hal.executable) {
      %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    } else {
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
      scf.yield %0 : !hal.executable
    }
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.return
}

// -----// IR Dump After ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  %3 = scf.if %2 -> (!hal.executable) {
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    scf.yield %executable : !hal.executable
  } else {
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    scf.yield %0 : !hal.executable
  }
  util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c1 = arith.constant 1 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = affine.apply affine_map<()[s0] -> (s0 ceildiv 32)>()[%1]
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After InitializeDevicesPass (iree-hal-initialize-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    %1:3 = scf.while (%arg0 = %c0, %arg1 = %c0, %arg2 = %0) : (index, index, !hal.device) -> (index, index, !hal.device) {
      %4 = util.cmp.eq %arg2, %0 : !hal.device
      %5 = arith.cmpi slt, %arg0, %device_count : index
      %6 = arith.andi %4, %5 : i1
      scf.condition(%6) %arg0, %arg1, %arg2 : index, index, !hal.device
    } do {
    ^bb0(%arg0: index, %arg1: index, %arg2: !hal.device):
      %device_n = hal.devices.get %arg0 : !hal.device
      %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
      %4 = scf.if %value -> (i1) {
        %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
        scf.yield %value_1 : i1
      } else {
        %false = arith.constant false
        scf.yield %false : i1
      }
      %5 = arith.cmpi eq, %arg1, %c0 : index
      %6 = arith.select %4, %c1, %c0 : index
      %7 = arith.addi %arg1, %6 : index
      %8 = arith.andi %4, %5 : i1
      %9 = arith.select %8, %device_n, %0 : !hal.device
      %10 = arith.addi %arg0, %c1 : index
      scf.yield %10, %7, %9 : index, index, !hal.device
    }
    %2 = util.null : !hal.device
    %3 = util.cmp.eq %1#2, %2 : !hal.device
    scf.if %3 {
      %c18_i32 = arith.constant 18 : i32
      util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    }
    util.global.store %1#2, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    %3 = scf.if %2 -> (!hal.executable) {
      %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    } else {
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
      scf.yield %0 : !hal.executable
    }
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After AffineExpandIndexOps (affine-expand-index-ops) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#map = affine_map<()[s0] -> (s0 ceildiv 32)>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    %1:3 = scf.while (%arg0 = %c0, %arg1 = %c0, %arg2 = %0) : (index, index, !hal.device) -> (index, index, !hal.device) {
      %3 = util.cmp.eq %arg2, %0 : !hal.device
      %4 = arith.cmpi slt, %arg0, %device_count : index
      %5 = arith.andi %3, %4 : i1
      scf.condition(%5) %arg0, %arg1, %arg2 : index, index, !hal.device
    } do {
    ^bb0(%arg0: index, %arg1: index, %arg2: !hal.device):
      %device_n = hal.devices.get %arg0 : !hal.device
      %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
      %3 = scf.if %value -> (i1) {
        %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
        scf.yield %value_1 : i1
      } else {
        scf.yield %false : i1
      }
      %4 = arith.cmpi eq, %arg1, %c0 : index
      %5 = arith.select %3, %c1, %c0 : index
      %6 = arith.addi %arg1, %5 : index
      %7 = arith.andi %3, %4 : i1
      %8 = arith.select %7, %device_n, %0 : !hal.device
      %9 = arith.addi %arg0, %c1 : index
      scf.yield %9, %6, %8 : index, index, !hal.device
    }
    %2 = util.cmp.eq %1#2, %0 : !hal.device
    scf.if %2 {
      util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    }
    util.global.store %1#2, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    %3 = scf.if %2 -> (!hal.executable) {
      %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    } else {
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
      scf.yield %0 : !hal.executable
    }
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = affine.apply #map()[%1]
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%13, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>
#pipeline_layout = #hal.pipeline.layout<constants = 4, bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    %1:3 = scf.while (%arg0 = %c0, %arg1 = %c0, %arg2 = %0) : (index, index, !hal.device) -> (index, index, !hal.device) {
      %3 = util.cmp.eq %arg2, %0 : !hal.device
      %4 = arith.cmpi slt, %arg0, %device_count : index
      %5 = arith.andi %3, %4 : i1
      scf.condition(%5) %arg0, %arg1, %arg2 : index, index, !hal.device
    } do {
    ^bb0(%arg0: index, %arg1: index, %arg2: !hal.device):
      %device_n = hal.devices.get %arg0 : !hal.device
      %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
      %3 = scf.if %value -> (i1) {
        %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
        scf.yield %value_1 : i1
      } else {
        scf.yield %false : i1
      }
      %4 = arith.cmpi eq, %arg1, %c0 : index
      %5 = arith.select %3, %c1, %c0 : index
      %6 = arith.addi %arg1, %5 : index
      %7 = arith.andi %3, %4 : i1
      %8 = arith.select %7, %device_n, %0 : !hal.device
      %9 = arith.addi %arg0, %c1 : index
      scf.yield %9, %6, %8 : index, index, !hal.device
    }
    %2 = util.cmp.eq %1#2, %0 : !hal.device
    scf.if %2 {
      util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    }
    util.global.store %1#2, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    %3 = scf.if %2 -> (!hal.executable) {
      %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    } else {
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
      scf.yield %0 : !hal.executable
    }
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @foo_dispatch_0_elementwise_D_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 32 : index, workgroup_size = [1 : index, 1 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %c32 = arith.constant 32 : index
        %c0 = arith.constant 0 : index
        %c1_0 = arith.constant 1 : index
        %0 = arith.cmpi sle, %arg2, %c0 : index
        %1 = arith.subi %c0, %arg2 : index
        %2 = arith.subi %arg2, %c1_0 : index
        %3 = arith.select %0, %1, %2 : index
        %4 = arith.divsi %3, %c32 : index
        %5 = arith.subi %c0, %4 : index
        %6 = arith.addi %4, %c1_0 : index
        %7 = arith.select %0, %5, %6 : index
        hal.return %7, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @foo_dispatch_0_elementwise_D_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(-32 : index) : i64
          %2 = llvm.mlir.constant(32 : index) : i64
          %3 = llvm.mlir.constant(1 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.mlir.constant(0 : index) : i64
          %6 = nvvm.read.ptx.sreg.tid.x : i32
          %7 = llvm.sext %6 : i32 to i64
          %8 = nvvm.read.ptx.sreg.tid.y : i32
          %9 = llvm.sext %8 : i32 to i64
          %10 = nvvm.read.ptx.sreg.tid.z : i32
          %11 = llvm.sext %10 : i32 to i64
          %12 = llvm.add %7, %9 : i64
          %13 = llvm.add %12, %11 : i64
          %14 = llvm.zext %arg6 : i32 to i64
          %15 = llvm.shl %14, %4 : i64
          %16 = llvm.zext %arg5 : i32 to i64
          %17 = llvm.or %16, %15 : i64
          %18 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %0 : i64
          %20 = llvm.icmp "eq" %19, %5 : i64
          llvm.intr.assume %20 : i1
          %21 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0 : i64
          %23 = llvm.icmp "eq" %22, %5 : i64
          llvm.intr.assume %23 : i1
          %24 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0 : i64
          %26 = llvm.icmp "eq" %25, %5 : i64
          llvm.intr.assume %26 : i1
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.mul %28, %1 : i64
          %30 = llvm.add %17, %29 : i64
          %31 = llvm.intr.smin(%30, %2) : (i64, i64) -> i64
          llvm.br ^bb1(%13 : i64)
        ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb2
          %33 = llvm.icmp "slt" %32, %31 : i64
          llvm.cond_br %33, ^bb2, ^bb3
        ^bb2:  // pred: ^bb1
          %34 = llvm.mul %28, %2 : i64
          %35 = llvm.add %32, %34 : i64
          %36 = llvm.getelementptr %arg0[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %37 = llvm.load %36 : !llvm.ptr<1> -> f32
          %38 = llvm.getelementptr %arg1[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %39 = llvm.load %38 : !llvm.ptr<1> -> f32
          %40 = llvm.fadd %37, %39 : f32
          %41 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %40, %41 : f32, !llvm.ptr<1>
          %42 = llvm.add %32, %3 : i64
          llvm.br ^bb1(%42 : i64)
        ^bb3:  // pred: ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %c32 = arith.constant 32 : index
    %c0_1 = arith.constant 0 : index
    %c1_2 = arith.constant 1 : index
    %13 = arith.cmpi sle, %1, %c0_1 : index
    %14 = arith.subi %c0_1, %1 : index
    %15 = arith.subi %1, %c1_2 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0_1, %17 : index
    %19 = arith.addi %17, %c1_2 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_3 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_3) commands([%cmd])
    %status = hal.fence.await until([%fence_3]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  cf.br ^bb4
^bb4:  // pred: ^bb3
  util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c1 = arith.constant 1 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %c32 = arith.constant 32 : index
  %c0_1 = arith.constant 0 : index
  %c1_2 = arith.constant 1 : index
  %13 = arith.cmpi sle, %1, %c0_1 : index
  %14 = arith.subi %c0_1, %1 : index
  %15 = arith.subi %1, %c1_2 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0_1, %17 : index
  %19 = arith.addi %17, %c1_2 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_3 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_3) commands([%cmd])
  %status = hal.fence.await until([%fence_3]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb6
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2(%1, %2, %3 : index, index, !hal.device), ^bb7
^bb2(%7: index, %8: index, %9: !hal.device):  // pred: ^bb1
  %device_n = hal.devices.get %7 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb5(%value_1 : i1)
^bb4:  // pred: ^bb2
  cf.br ^bb5(%false : i1)
^bb5(%10: i1):  // 2 preds: ^bb3, ^bb4
  cf.br ^bb6
^bb6:  // pred: ^bb5
  %11 = arith.cmpi eq, %8, %c0 : index
  %12 = arith.select %10, %c1, %c0 : index
  %13 = arith.addi %8, %12 : index
  %14 = arith.andi %10, %11 : i1
  %15 = arith.select %14, %device_n, %0 : !hal.device
  %16 = arith.addi %7, %c1 : index
  cf.br ^bb1(%16, %13, %15 : index, index, !hal.device)
^bb7:  // pred: ^bb1
  %17 = util.cmp.eq %3, %0 : !hal.device
  cf.cond_br %17, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb9
^bb9:  // 2 preds: ^bb7, ^bb8
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After SerializeTargetExecutablesPass (iree-hal-serialize-target-executables) //----- //
hal.executable private @foo_dispatch_0 {
  hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
}

// -----// IR Dump After SerializeExecutablesPass (iree-hal-serialize-executables) //----- //
hal.executable private @foo_dispatch_0 {
  hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
}

// -----// IR Dump After PruneExecutablesPass (iree-hal-prune-executables) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb6
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2(%1, %2, %3 : index, index, !hal.device), ^bb7
  ^bb2(%7: index, %8: index, %9: !hal.device):  // pred: ^bb1
    %device_n = hal.devices.get %7 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb5(%value_1 : i1)
  ^bb4:  // pred: ^bb2
    cf.br ^bb5(%false : i1)
  ^bb5(%10: i1):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb6
  ^bb6:  // pred: ^bb5
    %11 = arith.cmpi eq, %8, %c0 : index
    %12 = arith.select %10, %c1, %c0 : index
    %13 = arith.addi %8, %12 : index
    %14 = arith.andi %10, %11 : i1
    %15 = arith.select %14, %device_n, %0 : !hal.device
    %16 = arith.addi %7, %c1 : index
    cf.br ^bb1(%16, %13, %15 : index, index, !hal.device)
  ^bb7:  // pred: ^bb1
    %17 = util.cmp.eq %3, %0 : !hal.device
    cf.cond_br %17, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb9
  ^bb9:  // 2 preds: ^bb7, ^bb8
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %c32 = arith.constant 32 : index
    %c0_1 = arith.constant 0 : index
    %c1_2 = arith.constant 1 : index
    %13 = arith.cmpi sle, %1, %c0_1 : index
    %14 = arith.subi %c0_1, %1 : index
    %15 = arith.subi %1, %c1_2 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0_1, %17 : index
    %19 = arith.addi %17, %c1_2 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_3 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_3) commands([%cmd])
    %status = hal.fence.await until([%fence_3]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb6
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2(%1, %2, %3 : index, index, !hal.device), ^bb7
  ^bb2(%7: index, %8: index, %9: !hal.device):  // pred: ^bb1
    %device_n = hal.devices.get %7 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb5(%value_1 : i1)
  ^bb4:  // pred: ^bb2
    cf.br ^bb5(%false : i1)
  ^bb5(%10: i1):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb6
  ^bb6:  // pred: ^bb5
    %11 = arith.cmpi eq, %8, %c0 : index
    %12 = arith.select %10, %c1, %c0 : index
    %13 = arith.addi %8, %12 : index
    %14 = arith.andi %10, %11 : i1
    %15 = arith.select %14, %device_n, %0 : !hal.device
    %16 = arith.addi %7, %c1 : index
    cf.br ^bb1(%16, %13, %15 : index, index, !hal.device)
  ^bb7:  // pred: ^bb1
    %17 = util.cmp.eq %3, %0 : !hal.device
    cf.cond_br %17, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb9
  ^bb9:  // 2 preds: ^bb7, ^bb8
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %c32 = arith.constant 32 : index
    %c0_1 = arith.constant 0 : index
    %c1_2 = arith.constant 1 : index
    %13 = arith.cmpi sle, %1, %c0_1 : index
    %14 = arith.subi %c0_1, %1 : index
    %15 = arith.subi %1, %c1_2 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0_1, %17 : index
    %19 = arith.addi %17, %c1_2 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_3 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_3) commands([%cmd])
    %status = hal.fence.await until([%fence_3]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2(%1, %2 : index, index), ^bb5
^bb2(%7: index, %8: index):  // pred: ^bb1
  %device_n = hal.devices.get %7 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%9: i1):  // 2 preds: ^bb2, ^bb3
  %10 = arith.cmpi eq, %8, %c0 : index
  %11 = arith.select %9, %c1, %c0 : index
  %12 = arith.addi %8, %11 : index
  %13 = arith.andi %9, %10 : i1
  %14 = arith.select %13, %device_n, %0 : !hal.device
  %15 = arith.addi %7, %c1 : index
  cf.br ^bb1(%15, %12, %14 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  %16 = util.cmp.eq %3, %0 : !hal.device
  cf.cond_br %16, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32 = arith.constant 32 : index
  %c-1_i32 = arith.constant -1 : i32
  %c1 = arith.constant 1 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi sle, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2(%1, %2 : index, index), ^bb5
^bb2(%7: index, %8: index):  // pred: ^bb1
  %device_n = hal.devices.get %7 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%9: i1):  // 2 preds: ^bb2, ^bb3
  %10 = arith.cmpi eq, %8, %c0 : index
  %11 = arith.select %9, %c1, %c0 : index
  %12 = arith.addi %8, %11 : index
  %13 = arith.andi %9, %10 : i1
  %14 = arith.select %13, %device_n, %0 : !hal.device
  %15 = arith.addi %7, %c1 : index
  cf.br ^bb1(%15, %12, %14 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2(%1, %2 : index, index), ^bb5
^bb2(%7: index, %8: index):  // pred: ^bb1
  %device_n = hal.devices.get %7 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%9: i1):  // 2 preds: ^bb2, ^bb3
  %10 = arith.cmpi eq, %8, %c0 : index
  %11 = arith.select %9, %c1, %c0 : index
  %12 = arith.addi %8, %11 : index
  %13 = arith.andi %9, %10 : i1
  %14 = arith.select %13, %device_n, %0 : !hal.device
  %15 = arith.addi %7, %c1 : index
  cf.br ^bb1(%15, %12, %14 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32 = arith.constant 32 : index
  %c-1_i32 = arith.constant -1 : i32
  %c1 = arith.constant 1 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi sle, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %c32 = arith.constant 32 : index
  %c-1_i32 = arith.constant -1 : i32
  %c1 = arith.constant 1 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi sle, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi sle, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi sle, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi sle, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi sle, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi sle, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi sle, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"0x08000000434441310AF6FFFF08000000C0000000010000000400000016F6FFFF380000000100000001000000010000000400000008000000480000000300000003000000000000000300000000000000020000000000000020000000666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633320000000082F6FFFF24000000040000008EF6FFFF08000000030000000B0000006C696E616C672E6D6C69720020000000666F6F5F64697370617463685F305F656C656D656E74776973655F445F663332000000000100000004000000E0F6FFFF04000000100900002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E360A2E74617267657420736D5F38360A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C09666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633320A0A2E76697369626C65202E656E74727920666F6F5F64697370617463685F305F656C656D656E74776973655F445F663332280A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F302C0A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F312C0A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F322C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F332C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F342C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F352C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F360A290A2E6D61786E74696420312C20312C20310A7B0A092E726567202E70726564200925703C353E3B0A092E726567202E623332200925723C323E3B0A092E726567202E663332200925663C31303E3B0A092E726567202E62363420092572643C34303E3B0A0A096C642E706172616D2E753332200925726432352C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F365D3B0A0973686C2E623634200925726432362C2025726432352C2033323B0A096D6F762E75333220092572312C202563746169642E783B0A096C642E706172616D2E753332200925726432372C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F355D3B0A096D756C2E776964652E7533322009257264322C202572312C2033323B0A097375622E733634200925726432382C2025726432372C20257264323B0A096164642E7336342009257264332C2025726432382C2025726432363B0A09736574702E6C742E73363420092570312C20257264332C20313B0A0940257031206272612009244C5F5F4242305F363B0A096C642E706172616D2E753634200925726432342C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F325D3B0A096C642E706172616D2E753634200925726432332C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F315D3B0A096C642E706172616D2E753634200925726432322C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F305D3B0A096D696E2E7536342009257264342C20257264332C2033323B0A09616E642E623634202009257264352C20257264342C20313B0A09736574702E65712E73363420092570322C20257264332C20313B0A096D6F762E753634200925726433392C20303B0A0940257032206272612009244C5F5F4242305F343B0A096376742E7536342E7533322009257264312C202572313B0A09616E642E623634202009257264362C20257264342C2036323B0A0973686C2E623634200925726433312C20257264312C20373B0A096F722E62363420200925726433322C2025726433312C20343B0A096164642E733634200925726433372C2025726432342C2025726433323B0A096164642E733634200925726433362C2025726432322C2025726433323B0A096164642E733634200925726433352C2025726432332C2025726433323B0A096D6F762E753634200925726433392C20303B0A244C5F5F4242305F333A0A096C642E676C6F62616C2E6E632E76322E66333220097B2566312C202566327D2C205B25726433362B2D345D3B0A096C642E676C6F62616C2E6E632E76322E66333220097B2566332C202566347D2C205B25726433352B2D345D3B0A096164642E726E2E66333220092566352C202566312C202566333B0A096164642E726E2E66333220092566362C202566322C202566343B0A0973742E676C6F62616C2E76322E66333220095B25726433372B2D345D2C207B2566352C202566367D3B0A096164642E733634200925726433392C2025726433392C20323B0A096164642E733634200925726433372C2025726433372C20383B0A096164642E733634200925726433362C2025726433362C20383B0A096164642E733634200925726433352C2025726433352C20383B0A09736574702E6E652E73363420092570332C20257264362C2025726433393B0A0940257033206272612009244C5F5F4242305F333B0A244C5F5F4242305F343A0A09736574702E65712E73363420092570342C20257264352C20303B0A0940257034206272612009244C5F5F4242305F363B0A096164642E733634200925726433332C2025726433392C20257264323B0A0973686C2E623634200925726433342C2025726433332C20323B0A096164642E733634200925726431392C2025726432322C2025726433343B0A096164642E733634200925726432302C2025726432332C2025726433343B0A096164642E733634200925726432312C2025726432342C2025726433343B0A096C642E676C6F62616C2E6E632E66333220092566372C205B25726431395D3B0A096C642E676C6F62616C2E6E632E66333220092566382C205B25726432305D3B0A096164642E726E2E66333220092566392C202566372C202566383B0A0973742E676C6F62616C2E66333220095B25726432315D2C202566393B0A244C5F5F4242305F363A0A097265743B0A0A7D0A0000000006000800040008000C0004000800120020000000040008000000140018001C00"> : vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi sle, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi sle, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    cf.br ^bb8
  ^bb8:  // pred: ^bb7
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %14 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0_4 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0_5 = util.global.load @__device_0 : !hal.device
    %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0_4, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0_4 : index
    cf.cond_br %16, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    %executable = hal.executable.create device(%__device_0_5 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb11(%executable : !hal.executable)
  ^bb10:  // pred: ^bb8
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb11(%14 : !hal.executable)
  ^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
    util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    cf.br ^bb12
  ^bb12:  // pred: ^bb11
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi sle, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  util.return
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  util.return
}

// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi sle, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  util.return
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi sle, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After AffineExpandIndexOps (affine-expand-index-ops) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  util.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi sle, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  util.return
}

// -----// IR Dump After AffineExpandIndexOps (affine-expand-index-ops) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi sle, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  util.return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi sle, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi ule, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
  ^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
    %5 = util.cmp.eq %4, %1 : !hal.device
    %6 = arith.cmpi slt, %2, %device_count : index
    %7 = arith.andi %5, %6 : i1
    cf.cond_br %7, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %2 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
    %9 = arith.cmpi eq, %3, %c0 : index
    %10 = arith.select %8, %c1, %c0 : index
    %11 = arith.addi %3, %10 : index
    %12 = arith.andi %8, %9 : i1
    %13 = arith.select %12, %device_n, %1 : !hal.device
    %14 = arith.addi %2, %c1 : index
    cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %4, @__device_0 : !hal.device
    cf.br ^bb8
  ^bb8:  // pred: ^bb7
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0_4 = util.global.load @__device_0 : !hal.device
    %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0 : index
    cf.cond_br %16, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    %executable = hal.executable.create device(%__device_0_4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb11(%executable : !hal.executable)
  ^bb10:  // pred: ^bb8
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb11(%0 : !hal.executable)
  ^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
    util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    cf.br ^bb12
  ^bb12:  // pred: ^bb11
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi ule, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi ule, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb10(%executable : !hal.executable)
^bb9:  // pred: ^bb7
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb10(%0 : !hal.executable)
^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
  util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi ule, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb10(%executable : !hal.executable)
^bb9:  // pred: ^bb7
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb10(%0 : !hal.executable)
^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
  util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
  ^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
    %5 = util.cmp.eq %4, %1 : !hal.device
    %6 = arith.cmpi slt, %2, %device_count : index
    %7 = arith.andi %5, %6 : i1
    cf.cond_br %7, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %2 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
    %9 = arith.cmpi eq, %3, %c0 : index
    %10 = arith.select %8, %c1, %c0 : index
    %11 = arith.addi %3, %10 : index
    %12 = arith.andi %8, %9 : i1
    %13 = arith.select %12, %device_n, %1 : !hal.device
    %14 = arith.addi %2, %c1 : index
    cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %4, @__device_0 : !hal.device
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0_query_0_hal_executable_format_cuda_nvptx_fb = util.global.load @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
    %__device_0_4 = util.global.load @__device_0 : !hal.device
    %15 = arith.select %__device_0_query_0_hal_executable_format_cuda_nvptx_fb, %c0, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0 : index
    cf.cond_br %16, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %executable = hal.executable.create device(%__device_0_4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb10(%executable : !hal.executable)
  ^bb9:  // pred: ^bb7
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb10(%0 : !hal.executable)
  ^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
    util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi ule, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  %ok_2, %value_3 = hal.device.query<%4 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %15 = arith.select %value_3, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  util.global.store %4, @__device_0 : !hal.device
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  cf.cond_br %16, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %executable = hal.executable.create device(%4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb10(%executable : !hal.executable)
^bb9:  // pred: ^bb7
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb10(%0 : !hal.executable)
^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
  util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c32 = arith.constant 32 : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi ule, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  %ok_2, %value_3 = hal.device.query<%4 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %15 = arith.select %value_3, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  util.global.store %4, @__device_0 : !hal.device
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_cuda_nvptx_fb : i1
  cf.cond_br %16, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %executable = hal.executable.create device(%4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
  cf.br ^bb10(%executable : !hal.executable)
^bb9:  // pred: ^bb7
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  cf.br ^bb10(%0 : !hal.executable)
^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
  util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c32 = arith.constant 32 : index
  %c-1_i32 = arith.constant -1 : i32
  %c1 = arith.constant 1 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %1, %c4 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
  %4 = arith.muli %3, %c4 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
  %5 = arith.index_castui %3 : index to i64
  %6 = arith.index_castui %3 : index to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.index_castui %1 : index to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
  %13 = arith.cmpi ule, %1, %c0 : index
  %14 = arith.subi %c0, %1 : index
  %15 = arith.subi %1, %c1 : index
  %16 = arith.select %13, %14, %15 : index
  %17 = arith.divsi %16, %c32 : index
  %18 = arith.subi %c0, %17 : index
  %19 = arith.addi %17, %c1 : index
  %20 = arith.select %13, %18, %19 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
    (%buffer : !hal.buffer)[%c0, %2], 
    (%buffer_0 : !hal.buffer)[%c0, %4], 
    (%transient_buffer : !hal.buffer)[%c0, %2]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
  %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
  ^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
    %5 = util.cmp.eq %4, %1 : !hal.device
    %6 = arith.cmpi slt, %2, %device_count : index
    %7 = arith.andi %5, %6 : i1
    cf.cond_br %7, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %2 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
    %9 = arith.cmpi eq, %3, %c0 : index
    %10 = arith.select %8, %c1, %c0 : index
    %11 = arith.addi %3, %10 : index
    %12 = arith.andi %8, %9 : i1
    %13 = arith.select %12, %device_n, %1 : !hal.device
    %14 = arith.addi %2, %c1 : index
    cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %ok_2, %value_3 = hal.device.query<%4 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %15 = arith.select %value_3, %c0, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0 : index
    util.global.store %4, @__device_0 : !hal.device
    cf.cond_br %16, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %executable = hal.executable.create device(%4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb10(%executable : !hal.executable)
  ^bb9:  // pred: ^bb7
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb10(%0 : !hal.executable)
  ^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
    util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32 = arith.constant 32 : index
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi ule, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
  ^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
    %5 = util.cmp.eq %4, %1 : !hal.device
    %6 = arith.cmpi slt, %2, %device_count : index
    %7 = arith.andi %5, %6 : i1
    cf.cond_br %7, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %2 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "cuda") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
    %9 = arith.cmpi eq, %3, %c0 : index
    %10 = arith.select %8, %c1, %c0 : index
    %11 = arith.addi %3, %10 : index
    %12 = arith.andi %8, %9 : i1
    %13 = arith.select %12, %device_n, %1 : !hal.device
    %14 = arith.addi %2, %c1 : index
    cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %ok_2, %value_3 = hal.device.query<%4 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %15 = arith.select %value_3, %c0, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0 : index
    util.global.store %4, @__device_0 : !hal.device
    cf.cond_br %16, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %executable = hal.executable.create device(%4 : !hal.device) target(@foo_dispatch_0::@cuda_nvptx_fb) : !hal.executable
    cf.br ^bb10(%executable : !hal.executable)
  ^bb9:  // pred: ^bb7
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    cf.br ^bb10(%0 : !hal.executable)
  ^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
    util.global.store %17, @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    util.return
  }
  util.global private @__device_0_executable_0_foo_dispatch_0 : !hal.executable
  hal.executable private @foo_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<2584xi8>, format = "cuda-nvptx-fb"}
  }
  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32 = arith.constant 32 : index
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_foo_dispatch_0 = util.global.load immutable @__device_0_executable_0_foo_dispatch_0 : !hal.executable
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %1, %c4 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%2) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%3]) type(%element_type_f32) encoding(%dense_row_major)
    %4 = arith.muli %3, %c4 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%4) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%2}
    %5 = arith.index_castui %3 : index to i64
    %6 = arith.index_castui %3 : index to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.index_castui %1 : index to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") affinity(%c-1_i64) : !hal.command_buffer
    %13 = arith.cmpi ule, %1, %c0 : index
    %14 = arith.subi %c0, %1 : index
    %15 = arith.subi %1, %c1 : index
    %16 = arith.select %13, %14, %15 : index
    %17 = arith.divsi %16, %c32 : index
    %18 = arith.subi %c0, %17 : index
    %19 = arith.addi %17, %c1 : index
    %20 = arith.select %13, %18, %19 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_foo_dispatch_0 : !hal.executable)[%c0] workgroups([%20, %c1, %c1]) constants([%6, %8, %10, %12]) bindings([
      (%buffer : !hal.buffer)[%c0, %2], 
      (%buffer_0 : !hal.buffer)[%c0, %4], 
      (%transient_buffer : !hal.buffer)[%c0, %2]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_1) commands([%cmd])
    %status = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %2] shape([%1]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ConversionPass (iree-vm-conversion) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.initializer {
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1 = vm.const.i64 1
      %null_1 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_1 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %req = vm.cmp.eq.ref %4, %null_1 : !vm.ref<!hal.device>
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %5 = vm.and.i32 %req, %slt : i32
      vm.cond_br %5, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %6 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %buffer = vm.rodata.inline "_utf8_hal_device_id_C1DCB7DBC4F49AE6" {alignment = 1 : i64} : !vm.buffer = "hal.device.id"
      %buffer_2 = vm.rodata.inline "_utf8_cuda_EC9D846C9E731CDE" {alignment = 1 : i64} : !vm.buffer = "cuda"
      %7:2 = vm.call @hal.device.query.i64(%ref, %buffer, %buffer_2) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %7#1 : i64
      %zero_3 = vm.const.i32.zero
      %8 = vm.select.i32 %7#0, %nz, %zero_3 : i32
      %c1_4 = vm.const.i32 1
      vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %buffer_5 = vm.rodata.inline "_utf8_hal_executable_format_EAB228F999C2D3A1" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
      %buffer_6 = vm.rodata.inline "_utf8_cuda_nvptx_fb_B15B42B96FDBACC" {alignment = 1 : i64} : !vm.buffer = "cuda-nvptx-fb"
      %9:2 = vm.call @hal.device.query.i64(%ref, %buffer_5, %buffer_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %9#1 : i64
      %zero_8 = vm.const.i32.zero
      %10 = vm.select.i32 %9#0, %nz_7, %zero_8 : i32
      %c1_9 = vm.const.i32 1
      vm.br ^bb4(%10 : i32)
    ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %12 = vm.select.i64 %11, %c1, %zero_0 : i64
      %13 = vm.add.i64 %3, %12 : i64
      %14 = vm.and.i32 %11, %eq : i32
      %ref_10 = vm.select.ref %14, %ref, %null_1 : !vm.ref<!hal.device>
      %15 = vm.add.i64 %2, %c1 : i64
      vm.br ^bb1(%15, %13, %ref_10 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %req, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"cuda", [#hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
      vm.br ^bb7
    ^bb7:  // 2 preds: ^bb5, ^bb6
      %buffer_11 = vm.rodata.inline "_utf8_hal_executable_format_EAB228F999C2D3A1" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
      %buffer_12 = vm.rodata.inline "_utf8_cuda_nvptx_fb_B15B42B96FDBACC" {alignment = 1 : i64} : !vm.buffer = "cuda-nvptx-fb"
      %16:2 = vm.call @hal.device.query.i64(%4, %buffer_11, %buffer_12) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_13 = vm.cmp.nz.i64 %16#1 : i64
      %zero_14 = vm.const.i32.zero
      %17 = vm.select.i32 %16#0, %nz_13, %zero_14 : i32
      %c1_15 = vm.const.i32 1
      %18 = vm.select.i64 %17, %zero_0, %c-1 : i64
      %eq_16 = vm.cmp.eq.i64 %18, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_16, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %buffer_17 = vm.rodata.inline "foo_dispatch_0_cuda_nvptx_fb" {alignment = 16 : i64} : !vm.buffer = dense<"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vector<2584xi8>
      %buffer_18 = vm.rodata.inline "_utf8_cuda_nvptx_fb_B15B42B96FDBACC" {alignment = 1 : i64} : !vm.buffer = "cuda-nvptx-fb"
      %null_19 = vm.const.ref.zero : !vm.buffer
      %ref_20 = vm.call @hal.executable.create(%4, %buffer_18, %buffer_17, %null_19) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.br ^bb10(%ref_20 : !vm.ref<!hal.executable>)
    ^bb9:  // pred: ^bb7
      vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
      vm.br ^bb10(%null : !vm.ref<!hal.executable>)
    ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
      vm.global.store.ref %19, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
    vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
    vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c32 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1 = vm.const.i64 1
      %zero = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i64 -1
      %c32_1 = vm.const.i64 32
      %c4 = vm.const.i64 4
      %zero_2 = vm.const.i64.zero
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %zero_3 = vm.const.i32.zero
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero_3) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %c553648160 = vm.const.i32 553648160
      %c1_4 = vm.const.i32 1
      %buffer = vm.rodata.inline "_utf8_input0_F74E046E5FFA3735" {alignment = 1 : i64} : !vm.buffer = "input0"
      vm.call.variadic @hal.buffer_view.assert(%arg0, %buffer, %c553648160, %c1_4, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_5 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %buffer_6 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      %c16 = vm.const.i32 16
      %c3075 = vm.const.i32 3075
      vm.call @hal.buffer.assert(%ref, %buffer_6, %ref_5, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %zero_7 = vm.const.i32.zero
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero_7) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %buffer_8 = vm.rodata.inline "_utf8_input1_E2E5222C371315B9" {alignment = 1 : i64} : !vm.buffer = "input1"
      vm.call.variadic @hal.buffer_view.assert(%arg1, %buffer_8, %c553648160, %c1_4, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_9 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %buffer_10 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      %c16_11 = vm.const.i32 16
      %c3075_12 = vm.const.i32 3075
      vm.call @hal.buffer.assert(%ref_9, %buffer_10, %ref_5, %3, %c16_11, %c3075_12) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %zero_13 = vm.const.i32.zero
      %ref_14 = vm.call @hal.fence.create(%__device_0, %zero_13) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %zero_15 = vm.const.i32.zero
      %c48 = vm.const.i32 48
      %c3075_16 = vm.const.i32 3075
      %ref_17 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_0, %null, %ref_14, %zero_15, %c48, %c3075_16, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %c32_18 = vm.const.i32 32
      %5 = vm.shr.i64.u %2, %c32_18 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %c32_19 = vm.const.i32 32
      %8 = vm.shr.i64.u %0, %c32_19 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %c1_20 = vm.const.i32 1
      %c3 = vm.const.i32 3
      %zero_21 = vm.const.i32.zero
      %ref_22 = vm.call @hal.command_buffer.create(%__device_0, %c1_20, %c3, %c-1_0, %zero_21) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ulte = vm.cmp.lte.i64.u %0, %zero_2 : i64
      %10 = vm.sub.i64 %zero_2, %0 : i64
      %11 = vm.sub.i64 %0, %c1 : i64
      %12 = vm.select.i64 %ulte, %10, %11 : i64
      %13 = vm.div.i64.s %12, %c32 : i64
      %14 = vm.sub.i64 %zero_2, %13 : i64
      %15 = vm.add.i64 %13, %c1 : i64
      %16 = vm.select.i64 %ulte, %14, %15 : i64
      %zero_23 = vm.const.i32.zero
      %zero_24 = vm.const.i64 0
      %zero_25 = vm.const.i32.zero
      %17 = vm.trunc.i64.i32 %16 : i64 -> i32
      %c1_26 = vm.const.i32 1
      %c1_27 = vm.const.i32 1
      %zero_28 = vm.const.i32.zero
      %zero_29 = vm.const.i32.zero
      %zero_30 = vm.const.i32.zero
      vm.call.variadic @hal.command_buffer.dispatch(%ref_22, %__device_0_executable_0_foo_dispatch_0, %zero_25, %17, %c1_26, %c1_27, %zero_24, [%4, %6, %7, %9], [(%zero_23, %zero_28, %ref, %zero_2, %1), (%zero_23, %zero_29, %ref_9, %zero_2, %3), (%zero_23, %zero_30, %ref_17, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %c28 = vm.const.i32 28
      %c13 = vm.const.i32 13
      %zero_31 = vm.const.i32.zero
      vm.call @hal.command_buffer.execution_barrier(%ref_22, %c28, %c13, %zero_31) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_22) : (!vm.ref<!hal.command_buffer>) -> ()
      %zero_32 = vm.const.i32.zero
      %ref_33 = vm.call @hal.fence.create(%__device_0, %zero_32) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_0, %ref_14, %ref_33, [%ref_22]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %18 = vm.call.variadic @hal.fence.await(%c-1, [%ref_33]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_fail %18, "failed to wait on timepoint"
      %ref_34 = vm.call.variadic @hal.buffer_view.create(%ref_17, %zero_2, %1, %c553648160, %c1_4, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_34 : !vm.ref<!hal.buffer_view>
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ReifyRodataTablesPass (iree-vm-reify-rodata-tables) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.initializer {
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1 = vm.const.i64 1
    %null_1 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_1 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %req = vm.cmp.eq.ref %4, %null_1 : !vm.ref<!hal.device>
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %5 = vm.and.i32 %req, %slt : i32
    vm.cond_br %5, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %6 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %buffer = vm.rodata.inline "_utf8_hal_device_id_C1DCB7DBC4F49AE6" {alignment = 1 : i64} : !vm.buffer = "hal.device.id"
    %buffer_2 = vm.rodata.inline "_utf8_cuda_EC9D846C9E731CDE" {alignment = 1 : i64} : !vm.buffer = "cuda"
    %7:2 = vm.call @hal.device.query.i64(%ref, %buffer, %buffer_2) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %7#1 : i64
    %zero_3 = vm.const.i32.zero
    %8 = vm.select.i32 %7#0, %nz, %zero_3 : i32
    %c1_4 = vm.const.i32 1
    vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %buffer_5 = vm.rodata.inline "_utf8_hal_executable_format_EAB228F999C2D3A1" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
    %buffer_6 = vm.rodata.inline "_utf8_cuda_nvptx_fb_B15B42B96FDBACC" {alignment = 1 : i64} : !vm.buffer = "cuda-nvptx-fb"
    %9:2 = vm.call @hal.device.query.i64(%ref, %buffer_5, %buffer_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %9#1 : i64
    %zero_8 = vm.const.i32.zero
    %10 = vm.select.i32 %9#0, %nz_7, %zero_8 : i32
    %c1_9 = vm.const.i32 1
    vm.br ^bb4(%10 : i32)
  ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %12 = vm.select.i64 %11, %c1, %zero_0 : i64
    %13 = vm.add.i64 %3, %12 : i64
    %14 = vm.and.i32 %11, %eq : i32
    %ref_10 = vm.select.ref %14, %ref, %null_1 : !vm.ref<!hal.device>
    %15 = vm.add.i64 %2, %c1 : i64
    vm.br ^bb1(%15, %13, %ref_10 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %req, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"cuda", [#hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    vm.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %buffer_11 = vm.rodata.inline "_utf8_hal_executable_format_EAB228F999C2D3A1" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
    %buffer_12 = vm.rodata.inline "_utf8_cuda_nvptx_fb_B15B42B96FDBACC" {alignment = 1 : i64} : !vm.buffer = "cuda-nvptx-fb"
    %16:2 = vm.call @hal.device.query.i64(%4, %buffer_11, %buffer_12) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_13 = vm.cmp.nz.i64 %16#1 : i64
    %zero_14 = vm.const.i32.zero
    %17 = vm.select.i32 %16#0, %nz_13, %zero_14 : i32
    %c1_15 = vm.const.i32 1
    %18 = vm.select.i64 %17, %zero_0, %c-1 : i64
    %eq_16 = vm.cmp.eq.i64 %18, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_16, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %buffer_17 = vm.rodata.inline "foo_dispatch_0_cuda_nvptx_fb" {alignment = 16 : i64} : !vm.buffer = dense<"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vector<2584xi8>
    %buffer_18 = vm.rodata.inline "_utf8_cuda_nvptx_fb_B15B42B96FDBACC" {alignment = 1 : i64} : !vm.buffer = "cuda-nvptx-fb"
    %null_19 = vm.const.ref.zero : !vm.buffer
    %ref_20 = vm.call @hal.executable.create(%4, %buffer_18, %buffer_17, %null_19) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.br ^bb10(%ref_20 : !vm.ref<!hal.executable>)
  ^bb9:  // pred: ^bb7
    vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    vm.br ^bb10(%null : !vm.ref<!hal.executable>)
  ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
    vm.global.store.ref %19, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1 = vm.const.i64 1
    %zero = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i64 -1
    %c32_1 = vm.const.i64 32
    %c4 = vm.const.i64 4
    %zero_2 = vm.const.i64.zero
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %zero_3 = vm.const.i32.zero
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero_3) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %c553648160 = vm.const.i32 553648160
    %c1_4 = vm.const.i32 1
    %buffer = vm.rodata.inline "_utf8_input0_F74E046E5FFA3735" {alignment = 1 : i64} : !vm.buffer = "input0"
    vm.call.variadic @hal.buffer_view.assert(%arg0, %buffer, %c553648160, %c1_4, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_5 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %buffer_6 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
    %c16 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %buffer_6, %ref_5, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_7 = vm.const.i32.zero
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero_7) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %buffer_8 = vm.rodata.inline "_utf8_input1_E2E5222C371315B9" {alignment = 1 : i64} : !vm.buffer = "input1"
    vm.call.variadic @hal.buffer_view.assert(%arg1, %buffer_8, %c553648160, %c1_4, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_9 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %buffer_10 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
    %c16_11 = vm.const.i32 16
    %c3075_12 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref_9, %buffer_10, %ref_5, %3, %c16_11, %c3075_12) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_13 = vm.const.i32.zero
    %ref_14 = vm.call @hal.fence.create(%__device_0, %zero_13) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %zero_15 = vm.const.i32.zero
    %c48 = vm.const.i32 48
    %c3075_16 = vm.const.i32 3075
    %ref_17 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_0, %null, %ref_14, %zero_15, %c48, %c3075_16, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %c32_18 = vm.const.i32 32
    %5 = vm.shr.i64.u %2, %c32_18 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %c32_19 = vm.const.i32 32
    %8 = vm.shr.i64.u %0, %c32_19 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %c1_20 = vm.const.i32 1
    %c3 = vm.const.i32 3
    %zero_21 = vm.const.i32.zero
    %ref_22 = vm.call @hal.command_buffer.create(%__device_0, %c1_20, %c3, %c-1_0, %zero_21) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ulte = vm.cmp.lte.i64.u %0, %zero_2 : i64
    %10 = vm.sub.i64 %zero_2, %0 : i64
    %11 = vm.sub.i64 %0, %c1 : i64
    %12 = vm.select.i64 %ulte, %10, %11 : i64
    %13 = vm.div.i64.s %12, %c32 : i64
    %14 = vm.sub.i64 %zero_2, %13 : i64
    %15 = vm.add.i64 %13, %c1 : i64
    %16 = vm.select.i64 %ulte, %14, %15 : i64
    %zero_23 = vm.const.i32.zero
    %zero_24 = vm.const.i64 0
    %zero_25 = vm.const.i32.zero
    %17 = vm.trunc.i64.i32 %16 : i64 -> i32
    %c1_26 = vm.const.i32 1
    %c1_27 = vm.const.i32 1
    %zero_28 = vm.const.i32.zero
    %zero_29 = vm.const.i32.zero
    %zero_30 = vm.const.i32.zero
    vm.call.variadic @hal.command_buffer.dispatch(%ref_22, %__device_0_executable_0_foo_dispatch_0, %zero_25, %17, %c1_26, %c1_27, %zero_24, [%4, %6, %7, %9], [(%zero_23, %zero_28, %ref, %zero_2, %1), (%zero_23, %zero_29, %ref_9, %zero_2, %3), (%zero_23, %zero_30, %ref_17, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_31 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_22, %c28, %c13, %zero_31) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_22) : (!vm.ref<!hal.command_buffer>) -> ()
    %zero_32 = vm.const.i32.zero
    %ref_33 = vm.call @hal.fence.create(%__device_0, %zero_32) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_0, %ref_14, %ref_33, [%ref_22]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %18 = vm.call.variadic @hal.fence.await(%c-1, [%ref_33]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %18, "failed to wait on timepoint"
    %ref_34 = vm.call.variadic @hal.buffer_view.create(%ref_17, %zero_2, %1, %c553648160, %c1_4, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_34 : !vm.ref<!hal.buffer_view>
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::HoistInlinedRodataPass (iree-vm-hoist-inlined-rodata) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1_0 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC_1 {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"0x08000000434441310AF6FFFF08000000C0000000010000000400000016F6FFFF380000000100000001000000010000000400000008000000480000000300000003000000000000000300000000000000020000000000000020000000666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633320000000082F6FFFF24000000040000008EF6FFFF08000000030000000B0000006C696E616C672E6D6C69720020000000666F6F5F64697370617463685F305F656C656D656E74776973655F445F663332000000000100000004000000E0F6FFFF04000000100900002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E360A2E74617267657420736D5F38360A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C09666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633320A0A2E76697369626C65202E656E74727920666F6F5F64697370617463685F305F656C656D656E74776973655F445F663332280A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F302C0A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F312C0A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F322C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F332C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F342C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F352C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F360A290A2E6D61786E74696420312C20312C20310A7B0A092E726567202E70726564200925703C353E3B0A092E726567202E623332200925723C323E3B0A092E726567202E663332200925663C31303E3B0A092E726567202E62363420092572643C34303E3B0A0A096C642E706172616D2E753332200925726432352C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F365D3B0A0973686C2E623634200925726432362C2025726432352C2033323B0A096D6F762E75333220092572312C202563746169642E783B0A096C642E706172616D2E753332200925726432372C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F355D3B0A096D756C2E776964652E7533322009257264322C202572312C2033323B0A097375622E733634200925726432382C2025726432372C20257264323B0A096164642E7336342009257264332C2025726432382C2025726432363B0A09736574702E6C742E73363420092570312C20257264332C20313B0A0940257031206272612009244C5F5F4242305F363B0A096C642E706172616D2E753634200925726432342C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F325D3B0A096C642E706172616D2E753634200925726432332C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F315D3B0A096C642E706172616D2E753634200925726432322C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F305D3B0A096D696E2E7536342009257264342C20257264332C2033323B0A09616E642E623634202009257264352C20257264342C20313B0A09736574702E65712E73363420092570322C20257264332C20313B0A096D6F762E753634200925726433392C20303B0A0940257032206272612009244C5F5F4242305F343B0A096376742E7536342E7533322009257264312C202572313B0A09616E642E623634202009257264362C20257264342C2036323B0A0973686C2E623634200925726433312C20257264312C20373B0A096F722E62363420200925726433322C2025726433312C20343B0A096164642E733634200925726433372C2025726432342C2025726433323B0A096164642E733634200925726433362C2025726432322C2025726433323B0A096164642E733634200925726433352C2025726432332C2025726433323B0A096D6F762E753634200925726433392C20303B0A244C5F5F4242305F333A0A096C642E676C6F62616C2E6E632E76322E66333220097B2566312C202566327D2C205B25726433362B2D345D3B0A096C642E676C6F62616C2E6E632E76322E66333220097B2566332C202566347D2C205B25726433352B2D345D3B0A096164642E726E2E66333220092566352C202566312C202566333B0A096164642E726E2E66333220092566362C202566322C202566343B0A0973742E676C6F62616C2E76322E66333220095B25726433372B2D345D2C207B2566352C202566367D3B0A096164642E733634200925726433392C2025726433392C20323B0A096164642E733634200925726433372C2025726433372C20383B0A096164642E733634200925726433362C2025726433362C20383B0A096164642E733634200925726433352C2025726433352C20383B0A09736574702E6E652E73363420092570332C20257264362C2025726433393B0A0940257033206272612009244C5F5F4242305F333B0A244C5F5F4242305F343A0A09736574702E65712E73363420092570342C20257264352C20303B0A0940257034206272612009244C5F5F4242305F363B0A096164642E733634200925726433332C2025726433392C20257264323B0A0973686C2E623634200925726433342C2025726433332C20323B0A096164642E733634200925726431392C2025726432322C2025726433343B0A096164642E733634200925726432302C2025726432332C2025726433343B0A096164642E733634200925726432312C2025726432342C2025726433343B0A096C642E676C6F62616C2E6E632E66333220092566372C205B25726431395D3B0A096C642E676C6F62616C2E6E632E66333220092566382C205B25726432305D3B0A096164642E726E2E66333220092566392C202566372C202566383B0A0973742E676C6F62616C2E66333220095B25726432315D2C202566393B0A244C5F5F4242305F363A0A097265743B0A0A7D0A0000000006000800040008000C0004000800120020000000040008000000140018001C00"> : vector<2584xi8>
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC_2 {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.initializer {
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1 = vm.const.i64 1
    %null_1 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_1 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %req = vm.cmp.eq.ref %4, %null_1 : !vm.ref<!hal.device>
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %5 = vm.and.i32 %req, %slt : i32
    vm.cond_br %5, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %6 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %7:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %7#1 : i64
    %zero_2 = vm.const.i32.zero
    %8 = vm.select.i32 %7#0, %nz, %zero_2 : i32
    %c1_3 = vm.const.i32 1
    vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %9:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_4 = vm.cmp.nz.i64 %9#1 : i64
    %zero_5 = vm.const.i32.zero
    %10 = vm.select.i32 %9#0, %nz_4, %zero_5 : i32
    %c1_6 = vm.const.i32 1
    vm.br ^bb4(%10 : i32)
  ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %12 = vm.select.i64 %11, %c1, %zero_0 : i64
    %13 = vm.add.i64 %3, %12 : i64
    %14 = vm.and.i32 %11, %eq : i32
    %ref_7 = vm.select.ref %14, %ref, %null_1 : !vm.ref<!hal.device>
    %15 = vm.add.i64 %2, %c1 : i64
    vm.br ^bb1(%15, %13, %ref_7 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %req, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"cuda", [#hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    vm.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %_utf8_hal_executable_format_EAB228F999C2D3A1_0 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1_0 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_1 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC_1 : !vm.buffer
    %16:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_0, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_1) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_8 = vm.cmp.nz.i64 %16#1 : i64
    %zero_9 = vm.const.i32.zero
    %17 = vm.select.i32 %16#0, %nz_8, %zero_9 : i32
    %c1_10 = vm.const.i32 1
    %18 = vm.select.i64 %17, %zero_0, %c-1 : i64
    %eq_11 = vm.cmp.eq.i64 %18, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_11, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_2 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC_2 : !vm.buffer
    %null_12 = vm.const.ref.zero : !vm.buffer
    %ref_13 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_2, %foo_dispatch_0_cuda_nvptx_fb, %null_12) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.br ^bb10(%ref_13 : !vm.ref<!hal.executable>)
  ^bb9:  // pred: ^bb7
    vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    vm.br ^bb10(%null : !vm.ref<!hal.executable>)
  ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
    vm.global.store.ref %19, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC_3 {alignment = 1 : i64} "tensor"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1 = vm.const.i64 1
    %zero = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i64 -1
    %c32_1 = vm.const.i64 32
    %c4 = vm.const.i64 4
    %zero_2 = vm.const.i64.zero
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %zero_3 = vm.const.i32.zero
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero_3) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %c553648160 = vm.const.i32 553648160
    %c1_4 = vm.const.i32 1
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1_4, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_5 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_6 = vm.const.i32.zero
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero_6) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1_4, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_3 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC_3 : !vm.buffer
    %c16_8 = vm.const.i32 16
    %c3075_9 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC_3, %ref_5, %3, %c16_8, %c3075_9) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_10 = vm.const.i32.zero
    %ref_11 = vm.call @hal.fence.create(%__device_0, %zero_10) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %zero_12 = vm.const.i32.zero
    %c48 = vm.const.i32 48
    %c3075_13 = vm.const.i32 3075
    %ref_14 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_0, %null, %ref_11, %zero_12, %c48, %c3075_13, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %c32_15 = vm.const.i32 32
    %5 = vm.shr.i64.u %2, %c32_15 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %c32_16 = vm.const.i32 32
    %8 = vm.shr.i64.u %0, %c32_16 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %c1_17 = vm.const.i32 1
    %c3 = vm.const.i32 3
    %zero_18 = vm.const.i32.zero
    %ref_19 = vm.call @hal.command_buffer.create(%__device_0, %c1_17, %c3, %c-1_0, %zero_18) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ulte = vm.cmp.lte.i64.u %0, %zero_2 : i64
    %10 = vm.sub.i64 %zero_2, %0 : i64
    %11 = vm.sub.i64 %0, %c1 : i64
    %12 = vm.select.i64 %ulte, %10, %11 : i64
    %13 = vm.div.i64.s %12, %c32 : i64
    %14 = vm.sub.i64 %zero_2, %13 : i64
    %15 = vm.add.i64 %13, %c1 : i64
    %16 = vm.select.i64 %ulte, %14, %15 : i64
    %zero_20 = vm.const.i32.zero
    %zero_21 = vm.const.i64 0
    %zero_22 = vm.const.i32.zero
    %17 = vm.trunc.i64.i32 %16 : i64 -> i32
    %c1_23 = vm.const.i32 1
    %c1_24 = vm.const.i32 1
    %zero_25 = vm.const.i32.zero
    %zero_26 = vm.const.i32.zero
    %zero_27 = vm.const.i32.zero
    vm.call.variadic @hal.command_buffer.dispatch(%ref_19, %__device_0_executable_0_foo_dispatch_0, %zero_22, %17, %c1_23, %c1_24, %zero_21, [%4, %6, %7, %9], [(%zero_20, %zero_25, %ref, %zero_2, %1), (%zero_20, %zero_26, %ref_7, %zero_2, %3), (%zero_20, %zero_27, %ref_14, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_28 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_19, %c28, %c13, %zero_28) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_19) : (!vm.ref<!hal.command_buffer>) -> ()
    %zero_29 = vm.const.i32.zero
    %ref_30 = vm.call @hal.fence.create(%__device_0, %zero_29) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_0, %ref_11, %ref_30, [%ref_19]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %18 = vm.call.variadic @hal.fence.await(%c-1, [%ref_30]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %18, "failed to wait on timepoint"
    %ref_31 = vm.call.variadic @hal.buffer_view.create(%ref_14, %zero_2, %1, %c553648160, %c1_4, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_31 : !vm.ref<!hal.buffer_view>
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DeduplicateRodataPass (iree-vm-deduplicate-rodata) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
  vm.initializer {
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1 = vm.const.i64 1
    %null_1 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_1 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %req = vm.cmp.eq.ref %4, %null_1 : !vm.ref<!hal.device>
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %5 = vm.and.i32 %req, %slt : i32
    vm.cond_br %5, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %6 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %7:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %7#1 : i64
    %zero_2 = vm.const.i32.zero
    %8 = vm.select.i32 %7#0, %nz, %zero_2 : i32
    %c1_3 = vm.const.i32 1
    vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %9:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_4 = vm.cmp.nz.i64 %9#1 : i64
    %zero_5 = vm.const.i32.zero
    %10 = vm.select.i32 %9#0, %nz_4, %zero_5 : i32
    %c1_6 = vm.const.i32 1
    vm.br ^bb4(%10 : i32)
  ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %12 = vm.select.i64 %11, %c1, %zero_0 : i64
    %13 = vm.add.i64 %3, %12 : i64
    %14 = vm.and.i32 %11, %eq : i32
    %ref_7 = vm.select.ref %14, %ref, %null_1 : !vm.ref<!hal.device>
    %15 = vm.add.i64 %2, %c1 : i64
    vm.br ^bb1(%15, %13, %ref_7 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %req, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"cuda", [#hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    vm.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %_utf8_hal_executable_format_EAB228F999C2D3A1_8 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %16:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_8, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_10 = vm.cmp.nz.i64 %16#1 : i64
    %zero_11 = vm.const.i32.zero
    %17 = vm.select.i32 %16#0, %nz_10, %zero_11 : i32
    %c1_12 = vm.const.i32 1
    %18 = vm.select.i64 %17, %zero_0, %c-1 : i64
    %eq_13 = vm.cmp.eq.i64 %18, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_13, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_14 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %null_15 = vm.const.ref.zero : !vm.buffer
    %ref_16 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_14, %foo_dispatch_0_cuda_nvptx_fb, %null_15) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.br ^bb10(%ref_16 : !vm.ref<!hal.executable>)
  ^bb9:  // pred: ^bb7
    vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    vm.br ^bb10(%null : !vm.ref<!hal.executable>)
  ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
    vm.global.store.ref %19, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c32 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1 = vm.const.i64 1
    %zero = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i64 -1
    %c32_1 = vm.const.i64 32
    %c4 = vm.const.i64 4
    %zero_2 = vm.const.i64.zero
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %zero_3 = vm.const.i32.zero
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero_3) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %c553648160 = vm.const.i32 553648160
    %c1_4 = vm.const.i32 1
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1_4, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_5 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_6 = vm.const.i32.zero
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero_6) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1_4, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_8 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16_9 = vm.const.i32 16
    %c3075_10 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC_8, %ref_5, %3, %c16_9, %c3075_10) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_11 = vm.const.i32.zero
    %ref_12 = vm.call @hal.fence.create(%__device_0, %zero_11) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %zero_13 = vm.const.i32.zero
    %c48 = vm.const.i32 48
    %c3075_14 = vm.const.i32 3075
    %ref_15 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_0, %null, %ref_12, %zero_13, %c48, %c3075_14, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %c32_16 = vm.const.i32 32
    %5 = vm.shr.i64.u %2, %c32_16 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %c32_17 = vm.const.i32 32
    %8 = vm.shr.i64.u %0, %c32_17 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %c1_18 = vm.const.i32 1
    %c3 = vm.const.i32 3
    %zero_19 = vm.const.i32.zero
    %ref_20 = vm.call @hal.command_buffer.create(%__device_0, %c1_18, %c3, %c-1_0, %zero_19) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ulte = vm.cmp.lte.i64.u %0, %zero_2 : i64
    %10 = vm.sub.i64 %zero_2, %0 : i64
    %11 = vm.sub.i64 %0, %c1 : i64
    %12 = vm.select.i64 %ulte, %10, %11 : i64
    %13 = vm.div.i64.s %12, %c32 : i64
    %14 = vm.sub.i64 %zero_2, %13 : i64
    %15 = vm.add.i64 %13, %c1 : i64
    %16 = vm.select.i64 %ulte, %14, %15 : i64
    %zero_21 = vm.const.i32.zero
    %zero_22 = vm.const.i64 0
    %zero_23 = vm.const.i32.zero
    %17 = vm.trunc.i64.i32 %16 : i64 -> i32
    %c1_24 = vm.const.i32 1
    %c1_25 = vm.const.i32 1
    %zero_26 = vm.const.i32.zero
    %zero_27 = vm.const.i32.zero
    %zero_28 = vm.const.i32.zero
    vm.call.variadic @hal.command_buffer.dispatch(%ref_20, %__device_0_executable_0_foo_dispatch_0, %zero_23, %17, %c1_24, %c1_25, %zero_22, [%4, %6, %7, %9], [(%zero_21, %zero_26, %ref, %zero_2, %1), (%zero_21, %zero_27, %ref_7, %zero_2, %3), (%zero_21, %zero_28, %ref_15, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_29 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_20, %c28, %c13, %zero_29) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_20) : (!vm.ref<!hal.command_buffer>) -> ()
    %zero_30 = vm.const.i32.zero
    %ref_31 = vm.call @hal.fence.create(%__device_0, %zero_30) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_0, %ref_12, %ref_31, [%ref_20]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %18 = vm.call.variadic @hal.fence.await(%c-1, [%ref_31]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %18, "failed to wait on timepoint"
    %ref_32 = vm.call.variadic @hal.buffer_view.create(%ref_15, %zero_2, %1, %c553648160, %c1_4, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_32 : !vm.ref<!hal.buffer_view>
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropUnusedCallsPass (iree-vm-drop-unused-calls) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
  vm.initializer {
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_1 = vm.const.i64.zero
    %c1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_1, %zero_1, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %req = vm.cmp.eq.ref %4, %null_2 : !vm.ref<!hal.device>
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %5 = vm.and.i32 %req, %slt : i32
    vm.cond_br %5, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %6 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %7:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %7#1 : i64
    %8 = vm.select.i32 %7#0, %nz, %zero : i32
    vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %9:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %9#1 : i64
    %10 = vm.select.i32 %9#0, %nz_3, %zero : i32
    vm.br ^bb4(%10 : i32)
  ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_1 : i64
    %12 = vm.select.i64 %11, %c1, %zero_1 : i64
    %13 = vm.add.i64 %3, %12 : i64
    %14 = vm.and.i32 %11, %eq : i32
    %ref_4 = vm.select.ref %14, %ref, %null_2 : !vm.ref<!hal.device>
    %15 = vm.add.i64 %2, %c1 : i64
    vm.br ^bb1(%15, %13, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %req, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"cuda", [#hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    vm.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %16:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %16#1 : i64
    %17 = vm.select.i32 %16#0, %nz_7, %zero : i32
    %18 = vm.select.i64 %17, %zero_1, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %18, %zero_1 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.br ^bb10(%ref_10 : !vm.ref<!hal.executable>)
  ^bb9:  // pred: ^bb7
    vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    vm.br ^bb10(%null_0 : !vm.ref<!hal.executable>)
  ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
    vm.global.store.ref %19, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ulte = vm.cmp.lte.i64.u %0, %zero_2 : i64
    %10 = vm.sub.i64 %zero_2, %0 : i64
    %11 = vm.sub.i64 %0, %c1_1 : i64
    %12 = vm.select.i64 %ulte, %10, %11 : i64
    %13 = vm.div.i64.s %12, %c32_0 : i64
    %14 = vm.sub.i64 %zero_2, %13 : i64
    %15 = vm.add.i64 %13, %c1_1 : i64
    %16 = vm.select.i64 %ulte, %14, %15 : i64
    %17 = vm.trunc.i64.i32 %16 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %17, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %18 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %18, "failed to wait on timepoint"
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.initializer {
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_1 = vm.const.i64.zero
      %c1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_1, %zero_1, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %req = vm.cmp.eq.ref %4, %null_2 : !vm.ref<!hal.device>
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %5 = vm.and.i32 %req, %slt : i32
      vm.cond_br %5, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %6 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %7:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %7#1 : i64
      %8 = vm.select.i32 %7#0, %nz, %zero : i32
      vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %9:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %9#1 : i64
      %10 = vm.select.i32 %9#0, %nz_3, %zero : i32
      vm.br ^bb4(%10 : i32)
    ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_1 : i64
      %12 = vm.select.i64 %11, %c1, %zero_1 : i64
      %13 = vm.add.i64 %3, %12 : i64
      %14 = vm.and.i32 %11, %eq : i32
      %ref_4 = vm.select.ref %14, %ref, %null_2 : !vm.ref<!hal.device>
      %15 = vm.add.i64 %2, %c1 : i64
      vm.br ^bb1(%15, %13, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %req, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"cuda", [#hal.executable.target<"cuda", "cuda-nvptx-fb", {iree.gpu.target = #iree_gpu.target<arch = "sm_86", features = "+ptx76", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
      vm.br ^bb7
    ^bb7:  // 2 preds: ^bb5, ^bb6
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %16:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %16#1 : i64
      %17 = vm.select.i32 %16#0, %nz_7, %zero : i32
      %18 = vm.select.i64 %17, %zero_1, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %18, %zero_1 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.br ^bb10(%ref_10 : !vm.ref<!hal.executable>)
    ^bb9:  // pred: ^bb7
      vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
      vm.br ^bb10(%null_0 : !vm.ref<!hal.executable>)
    ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
      vm.global.store.ref %19, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ulte = vm.cmp.lte.i64.u %0, %zero_2 : i64
      %10 = vm.sub.i64 %zero_2, %0 : i64
      %11 = vm.sub.i64 %0, %c1_1 : i64
      %12 = vm.select.i64 %ulte, %10, %11 : i64
      %13 = vm.div.i64.s %12, %c32_0 : i64
      %14 = vm.sub.i64 %zero_2, %13 : i64
      %15 = vm.add.i64 %13, %c1_1 : i64
      %16 = vm.select.i64 %ulte, %14, %15 : i64
      %17 = vm.trunc.i64.i32 %16 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %17, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %18 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_fail %18, "failed to wait on timepoint"
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
    vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
    vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ResolveRodataLoadsPass (iree-vm-resolve-rodata-loads) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
  vm.initializer {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  }
  vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.initializer {
  %c1 = vm.const.i32 1
  %null = vm.const.ref.zero : !vm.buffer
  %c-1 = vm.const.i64 -1
  %c14 = vm.const.i32 14
  %c18 = vm.const.i32 18
  %zero = vm.const.i32.zero
  %zero_0 = vm.const.i64.zero
  %c1_1 = vm.const.i64 1
  %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
  %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
  %1 = vm.ext.i32.i64.s %0 : i32 -> i64
  vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
  %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
  %5 = vm.xor.i32 %rnz, %c1 : i32
  %slt = vm.cmp.lt.i64.s %2, %1 : i64
  %6 = vm.and.i32 %5, %slt : i32
  vm.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %7 = vm.trunc.i64.i32 %2 : i64 -> i32
  %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
  %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
  %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
  %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz = vm.cmp.nz.i64 %8#1 : i64
  %9 = vm.select.i32 %8#0, %nz, %zero : i32
  vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
^bb3:  // pred: ^bb2
  %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
  %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz_3 = vm.cmp.nz.i64 %10#1 : i64
  %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
  vm.br ^bb4(%11 : i32)
^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
  %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
  %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
  %14 = vm.add.i64 %3, %13 : i64
  %15 = vm.and.i32 %12, %eq : i32
  %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
  %16 = vm.add.i64 %2, %c1_1 : i64
  vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
^bb5:  // pred: ^bb1
  vm.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
^bb7:  // pred: ^bb5
  %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
  %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz_7 = vm.cmp.nz.i64 %17#1 : i64
  %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
  %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
  %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
  vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
  vm.cond_br %eq_8, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
  %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
  %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
  vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.return
^bb9:  // pred: ^bb7
  vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %c3 = vm.const.i32 3
  %c32 = vm.const.i32 32
  %c48 = vm.const.i32 48
  %c3075 = vm.const.i32 3075
  %c16 = vm.const.i32 16
  %c1 = vm.const.i32 1
  %c553648160 = vm.const.i32 553648160
  %zero = vm.const.i32.zero
  %c32_0 = vm.const.i64 32
  %c-1 = vm.const.i32 -1
  %c1_1 = vm.const.i64 1
  %zero_2 = vm.const.i64.zero
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %c-1_3 = vm.const.i64 -1
  %c4 = vm.const.i64 4
  %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
  %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %1 = vm.mul.i64 %0, %c4 : i64
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %3 = vm.mul.i64 %2, %c4 : i64
  %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
  %4 = vm.trunc.i64.i32 %2 : i64 -> i32
  %5 = vm.shr.i64.u %2, %c32 : i64
  %6 = vm.trunc.i64.i32 %5 : i64 -> i32
  %7 = vm.trunc.i64.i32 %0 : i64 -> i32
  %8 = vm.shr.i64.u %0, %c32 : i64
  %9 = vm.trunc.i64.i32 %8 : i64 -> i32
  %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
  %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
  %10 = vm.xor.i32 %ult, %c1 : i32
  %11 = vm.sub.i64 %zero_2, %0 : i64
  %12 = vm.sub.i64 %0, %c1_1 : i64
  %13 = vm.select.i64 %10, %11, %12 : i64
  %14 = vm.div.i64.s %13, %c32_0 : i64
  %15 = vm.sub.i64 %zero_2, %14 : i64
  %16 = vm.add.i64 %14, %c1_1 : i64
  %17 = vm.select.i64 %10, %15, %16 : i64
  %18 = vm.trunc.i64.i32 %17 : i64 -> i32
  vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
  %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
  %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %19, ^bb2, ^bb1
^bb1:  // pred: ^bb0
  %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_11 : !vm.ref<!hal.buffer_view>
^bb2:  // pred: ^bb0
  vm.fail %19, "failed to wait on timepoint"
}

// -----// IR Dump After Inliner (inline) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
    vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
    vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropUnusedCallsPass (iree-vm-drop-unused-calls) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
  vm.initializer {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  }
  vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
    vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
    vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
    vm.global.ref private @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
  vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb10
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  ^bb10:  // pred: ^bb8
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_7 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_7, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_9 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_9, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_8, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_9, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_9) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_7, %ref_10, [%ref_9]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
    vm.export @__init
    vm.func private @__init() {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_9, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After CSE (cse) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
    vm.export @__init
    vm.func private @__init() {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
    vm.export @__init
    vm.func private @__init() {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
  vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
    vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
    vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
    vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i32 -1
      %c1_1 = vm.const.i64 1
      %zero_2 = vm.const.i64.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_3 = vm.const.i64 -1
      %c4 = vm.const.i64 4
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %1 = vm.mul.i64 %0, %c4 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %3 = vm.mul.i64 %2, %c4 : i64
      %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.trunc.i64.i32 %2 : i64 -> i32
      %5 = vm.shr.i64.u %2, %c32 : i64
      %6 = vm.trunc.i64.i32 %5 : i64 -> i32
      %7 = vm.trunc.i64.i32 %0 : i64 -> i32
      %8 = vm.shr.i64.u %0, %c32 : i64
      %9 = vm.trunc.i64.i32 %8 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
      %10 = vm.xor.i32 %ult, %c1 : i32
      %11 = vm.sub.i64 %zero_2, %0 : i64
      %12 = vm.sub.i64 %0, %c1_1 : i64
      %13 = vm.select.i64 %10, %11, %12 : i64
      %14 = vm.div.i64.s %13, %c32_0 : i64
      %15 = vm.sub.i64 %zero_2, %14 : i64
      %16 = vm.add.i64 %14, %c1_1 : i64
      %17 = vm.select.i64 %10, %15, %16 : i64
      %18 = vm.trunc.i64.i32 %17 : i64 -> i32
      vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %19, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %19, "failed to wait on timepoint"
    }
    vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
    vm.export @__init
    vm.func private @__init() {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c-1 = vm.const.i64 -1
      %c14 = vm.const.i32 14
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
      %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"0x08000000434441310AF6FFFF08000000C0000000010000000400000016F6FFFF380000000100000001000000010000000400000008000000480000000300000003000000000000000300000000000000020000000000000020000000666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633320000000082F6FFFF24000000040000008EF6FFFF08000000030000000B0000006C696E616C672E6D6C69720020000000666F6F5F64697370617463685F305F656C656D656E74776973655F445F663332000000000100000004000000E0F6FFFF04000000100900002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E360A2E74617267657420736D5F38360A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C09666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633320A0A2E76697369626C65202E656E74727920666F6F5F64697370617463685F305F656C656D656E74776973655F445F663332280A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F302C0A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F312C0A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F322C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F332C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F342C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F352C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F360A290A2E6D61786E74696420312C20312C20310A7B0A092E726567202E70726564200925703C353E3B0A092E726567202E623332200925723C323E3B0A092E726567202E663332200925663C31303E3B0A092E726567202E62363420092572643C34303E3B0A0A096C642E706172616D2E753332200925726432352C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F365D3B0A0973686C2E623634200925726432362C2025726432352C2033323B0A096D6F762E75333220092572312C202563746169642E783B0A096C642E706172616D2E753332200925726432372C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F355D3B0A096D756C2E776964652E7533322009257264322C202572312C2033323B0A097375622E733634200925726432382C2025726432372C20257264323B0A096164642E7336342009257264332C2025726432382C2025726432363B0A09736574702E6C742E73363420092570312C20257264332C20313B0A0940257031206272612009244C5F5F4242305F363B0A096C642E706172616D2E753634200925726432342C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F325D3B0A096C642E706172616D2E753634200925726432332C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F315D3B0A096C642E706172616D2E753634200925726432322C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F305D3B0A096D696E2E7536342009257264342C20257264332C2033323B0A09616E642E623634202009257264352C20257264342C20313B0A09736574702E65712E73363420092570322C20257264332C20313B0A096D6F762E753634200925726433392C20303B0A0940257032206272612009244C5F5F4242305F343B0A096376742E7536342E7533322009257264312C202572313B0A09616E642E623634202009257264362C20257264342C2036323B0A0973686C2E623634200925726433312C20257264312C20373B0A096F722E62363420200925726433322C2025726433312C20343B0A096164642E733634200925726433372C2025726432342C2025726433323B0A096164642E733634200925726433362C2025726432322C2025726433323B0A096164642E733634200925726433352C2025726432332C2025726433323B0A096D6F762E753634200925726433392C20303B0A244C5F5F4242305F333A0A096C642E676C6F62616C2E6E632E76322E66333220097B2566312C202566327D2C205B25726433362B2D345D3B0A096C642E676C6F62616C2E6E632E76322E66333220097B2566332C202566347D2C205B25726433352B2D345D3B0A096164642E726E2E66333220092566352C202566312C202566333B0A096164642E726E2E66333220092566362C202566322C202566343B0A0973742E676C6F62616C2E76322E66333220095B25726433372B2D345D2C207B2566352C202566367D3B0A096164642E733634200925726433392C2025726433392C20323B0A096164642E733634200925726433372C2025726433372C20383B0A096164642E733634200925726433362C2025726433362C20383B0A096164642E733634200925726433352C2025726433352C20383B0A09736574702E6E652E73363420092570332C20257264362C2025726433393B0A0940257033206272612009244C5F5F4242305F333B0A244C5F5F4242305F343A0A09736574702E65712E73363420092570342C20257264352C20303B0A0940257034206272612009244C5F5F4242305F363B0A096164642E733634200925726433332C2025726433392C20257264323B0A0973686C2E623634200925726433342C2025726433332C20323B0A096164642E733634200925726431392C2025726432322C2025726433343B0A096164642E733634200925726432302C2025726432332C2025726433343B0A096164642E733634200925726432312C2025726432342C2025726433343B0A096C642E676C6F62616C2E6E632E66333220092566372C205B25726431395D3B0A096C642E676C6F62616C2E6E632E66333220092566382C205B25726432305D3B0A096164642E726E2E66333220092566392C202566372C202566383B0A0973742E676C6F62616C2E66333220095B25726432315D2C202566393B0A244C5F5F4242305F363A0A097265743B0A0A7D0A0000000006000800040008000C0004000800120020000000040008000000140018001C00"> : vector<2584xi8>
  vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb10
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  ^bb10:  // pred: ^bb8
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
  vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb10
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  ^bb10:  // pred: ^bb8
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %c3 = vm.const.i32 3
  %c32 = vm.const.i32 32
  %c48 = vm.const.i32 48
  %c3075 = vm.const.i32 3075
  %c16 = vm.const.i32 16
  %c1 = vm.const.i32 1
  %c553648160 = vm.const.i32 553648160
  %zero = vm.const.i32.zero
  %c32_0 = vm.const.i64 32
  %c-1 = vm.const.i32 -1
  %c1_1 = vm.const.i64 1
  %zero_2 = vm.const.i64.zero
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %c-1_3 = vm.const.i64 -1
  %c4 = vm.const.i64 4
  %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
  %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %1 = vm.mul.i64 %0, %c4 : i64
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %3 = vm.mul.i64 %2, %c4 : i64
  %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
  %4 = vm.trunc.i64.i32 %2 : i64 -> i32
  %5 = vm.shr.i64.u %2, %c32 : i64
  %6 = vm.trunc.i64.i32 %5 : i64 -> i32
  %7 = vm.trunc.i64.i32 %0 : i64 -> i32
  %8 = vm.shr.i64.u %0, %c32 : i64
  %9 = vm.trunc.i64.i32 %8 : i64 -> i32
  %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
  %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
  %10 = vm.xor.i32 %ult, %c1 : i32
  %11 = vm.sub.i64 %zero_2, %0 : i64
  %12 = vm.sub.i64 %0, %c1_1 : i64
  %13 = vm.select.i64 %10, %11, %12 : i64
  %14 = vm.div.i64.s %13, %c32_0 : i64
  %15 = vm.sub.i64 %zero_2, %14 : i64
  %16 = vm.add.i64 %14, %c1_1 : i64
  %17 = vm.select.i64 %10, %15, %16 : i64
  %18 = vm.trunc.i64.i32 %17 : i64 -> i32
  vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
  %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
  %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %19, ^bb2, ^bb1
^bb1:  // pred: ^bb0
  %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_10 : !vm.ref<!hal.buffer_view>
^bb2:  // pred: ^bb0
  vm.fail %19, "failed to wait on timepoint"
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @__init() {
  %c1 = vm.const.i32 1
  %null = vm.const.ref.zero : !vm.buffer
  %c-1 = vm.const.i64 -1
  %c14 = vm.const.i32 14
  %c18 = vm.const.i32 18
  %zero = vm.const.i32.zero
  %zero_0 = vm.const.i64.zero
  %c1_1 = vm.const.i64 1
  %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
  %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
  %1 = vm.ext.i32.i64.s %0 : i32 -> i64
  vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
  %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
  %5 = vm.xor.i32 %rnz, %c1 : i32
  %slt = vm.cmp.lt.i64.s %2, %1 : i64
  %6 = vm.and.i32 %5, %slt : i32
  vm.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %7 = vm.trunc.i64.i32 %2 : i64 -> i32
  %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
  %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
  %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
  %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz = vm.cmp.nz.i64 %8#1 : i64
  %9 = vm.select.i32 %8#0, %nz, %zero : i32
  vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
^bb3:  // pred: ^bb2
  %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
  %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz_3 = vm.cmp.nz.i64 %10#1 : i64
  %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
  vm.br ^bb4(%11 : i32)
^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
  %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
  %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
  %14 = vm.add.i64 %3, %13 : i64
  %15 = vm.and.i32 %12, %eq : i32
  %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
  %16 = vm.add.i64 %2, %c1_1 : i64
  vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
^bb5:  // pred: ^bb1
  vm.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
^bb7:  // pred: ^bb5
  %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
  %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz_7 = vm.cmp.nz.i64 %17#1 : i64
  %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
  %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
  %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
  vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
  vm.cond_br %eq_8, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
  %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
  vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.return
^bb9:  // pred: ^bb7
  vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
}

// -----// IR Dump After Inliner (inline) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
  vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  }
}

// -----// IR Dump After CSE (cse) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"0x08000000434441310AF6FFFF08000000C0000000010000000400000016F6FFFF380000000100000001000000010000000400000008000000480000000300000003000000000000000300000000000000020000000000000020000000666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633320000000082F6FFFF24000000040000008EF6FFFF08000000030000000B0000006C696E616C672E6D6C69720020000000666F6F5F64697370617463685F305F656C656D656E74776973655F445F663332000000000100000004000000E0F6FFFF04000000100900002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E360A2E74617267657420736D5F38360A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C09666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633320A0A2E76697369626C65202E656E74727920666F6F5F64697370617463685F305F656C656D656E74776973655F445F663332280A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F302C0A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F312C0A092E706172616D202E753634202E707472202E676C6F62616C202E616C69676E20313620666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F322C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F332C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F342C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F352C0A092E706172616D202E75333220666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F360A290A2E6D61786E74696420312C20312C20310A7B0A092E726567202E70726564200925703C353E3B0A092E726567202E623332200925723C323E3B0A092E726567202E663332200925663C31303E3B0A092E726567202E62363420092572643C34303E3B0A0A096C642E706172616D2E753332200925726432352C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F365D3B0A0973686C2E623634200925726432362C2025726432352C2033323B0A096D6F762E75333220092572312C202563746169642E783B0A096C642E706172616D2E753332200925726432372C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F355D3B0A096D756C2E776964652E7533322009257264322C202572312C2033323B0A097375622E733634200925726432382C2025726432372C20257264323B0A096164642E7336342009257264332C2025726432382C2025726432363B0A09736574702E6C742E73363420092570312C20257264332C20313B0A0940257031206272612009244C5F5F4242305F363B0A096C642E706172616D2E753634200925726432342C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F325D3B0A096C642E706172616D2E753634200925726432332C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F315D3B0A096C642E706172616D2E753634200925726432322C205B666F6F5F64697370617463685F305F656C656D656E74776973655F445F6633325F706172616D5F305D3B0A096D696E2E7536342009257264342C20257264332C2033323B0A09616E642E623634202009257264352C20257264342C20313B0A09736574702E65712E73363420092570322C20257264332C20313B0A096D6F762E753634200925726433392C20303B0A0940257032206272612009244C5F5F4242305F343B0A096376742E7536342E7533322009257264312C202572313B0A09616E642E623634202009257264362C20257264342C2036323B0A0973686C2E623634200925726433312C20257264312C20373B0A096F722E62363420200925726433322C2025726433312C20343B0A096164642E733634200925726433372C2025726432342C2025726433323B0A096164642E733634200925726433362C2025726432322C2025726433323B0A096164642E733634200925726433352C2025726432332C2025726433323B0A096D6F762E753634200925726433392C20303B0A244C5F5F4242305F333A0A096C642E676C6F62616C2E6E632E76322E66333220097B2566312C202566327D2C205B25726433362B2D345D3B0A096C642E676C6F62616C2E6E632E76322E66333220097B2566332C202566347D2C205B25726433352B2D345D3B0A096164642E726E2E66333220092566352C202566312C202566333B0A096164642E726E2E66333220092566362C202566322C202566343B0A0973742E676C6F62616C2E76322E66333220095B25726433372B2D345D2C207B2566352C202566367D3B0A096164642E733634200925726433392C2025726433392C20323B0A096164642E733634200925726433372C2025726433372C20383B0A096164642E733634200925726433362C2025726433362C20383B0A096164642E733634200925726433352C2025726433352C20383B0A09736574702E6E652E73363420092570332C20257264362C2025726433393B0A0940257033206272612009244C5F5F4242305F333B0A244C5F5F4242305F343A0A09736574702E65712E73363420092570342C20257264352C20303B0A0940257034206272612009244C5F5F4242305F363B0A096164642E733634200925726433332C2025726433392C20257264323B0A0973686C2E623634200925726433342C2025726433332C20323B0A096164642E733634200925726431392C2025726432322C2025726433343B0A096164642E733634200925726432302C2025726432332C2025726433343B0A096164642E733634200925726432312C2025726432342C2025726433343B0A096C642E676C6F62616C2E6E632E66333220092566372C205B25726431395D3B0A096C642E676C6F62616C2E6E632E66333220092566382C205B25726432305D3B0A096164642E726E2E66333220092566392C202566372C202566383B0A0973742E676C6F62616C2E66333220095B25726432315D2C202566393B0A244C5F5F4242305F363A0A097265743B0A0A7D0A0000000006000800040008000C0004000800120020000000040008000000140018001C00"> : vector<2584xi8>
  vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
  vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64} dense<"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vector<2584xi8>
  vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::OrdinalAllocationPass (iree-vm-ordinal-allocation) //----- //
vm.module public @module attributes {ordinal_counts = #vm.ordinal_counts<import_funcs = 18, export_funcs = 2, internal_funcs = 2, global_bytes = 0, global_refs = 2, rodatas = 8, rwdatas = 0>} {
  vm.global.ref private mutable @__device_0 {ordinal = 0 : i32} : !vm.ref<!hal.device>
  vm.rodata private @_utf8_hal_device_id_C1DCB7DBC4F49AE6 {alignment = 1 : i64, ordinal = 0 : i32} "hal.device.id"
  vm.rodata private @_utf8_cuda_EC9D846C9E731CDE {alignment = 1 : i64, ordinal = 1 : i32} "cuda"
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64, ordinal = 2 : i32} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64, ordinal = 3 : i32} "cuda-nvptx-fb"
  vm.rodata private @foo_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, ordinal = 4 : i32} dense<"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vector<2584xi8>
  vm.global.ref private mutable @__device_0_executable_0_foo_dispatch_0 {ordinal = 1 : i32} : !vm.ref<!hal.executable>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {ordinal = 0 : i32}
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, ordinal = 1 : i32}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {ordinal = 2 : i32}
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, ordinal = 3 : i32}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, ordinal = 4 : i32}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 5 : i32, ordinal = 5 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {ordinal = 6 : i32}
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {ordinal = 7 : i32}
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {ordinal = 8 : i32}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, ordinal = 9 : i32}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, ordinal = 10 : i32}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {ordinal = 11 : i32}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {ordinal = 12 : i32}
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects, ordinal = 13 : i32}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects, ordinal = 14 : i32}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects, ordinal = 15 : i32}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {ordinal = 16 : i32}
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {ordinal = 17 : i32, vm.yield}
  vm.rodata private @_utf8_input0_F74E046E5FFA3735 {alignment = 1 : i64, ordinal = 5 : i32} "input0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64, ordinal = 6 : i32} "tensor"
  vm.rodata private @_utf8_input1_E2E5222C371315B9 {alignment = 1 : i64, ordinal = 7 : i32} "input1"
  vm.func private @foo(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}, ordinal = 0 : i32} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i32 -1
    %c1_1 = vm.const.i64 1
    %zero_2 = vm.const.i64.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_3 = vm.const.i64 -1
    %c4 = vm.const.i64 4
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_foo_dispatch_0 = vm.global.load.ref @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input0_F74E046E5FFA3735 = vm.const.ref.rodata @_utf8_input0_F74E046E5FFA3735 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_F74E046E5FFA3735, %c553648160, %c1, [%0]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %1 = vm.mul.i64 %0, %c4 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %1, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %2 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input1_E2E5222C371315B9 = vm.const.ref.rodata @_utf8_input1_E2E5222C371315B9 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input1_E2E5222C371315B9, %c553648160, %c1, [%2]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %3 = vm.mul.i64 %2, %c4 : i64
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC, %ref_4, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1_3, %null, %ref_6, %zero, %c48, %c3075, %1) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.trunc.i64.i32 %2 : i64 -> i32
    %5 = vm.shr.i64.u %2, %c32 : i64
    %6 = vm.trunc.i64.i32 %5 : i64 -> i32
    %7 = vm.trunc.i64.i32 %0 : i64 -> i32
    %8 = vm.shr.i64.u %0, %c32 : i64
    %9 = vm.trunc.i64.i32 %8 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%__device_0, %c1, %c3, %c-1_3, %zero) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %ult = vm.cmp.lt.i64.u %zero_2, %0 : i64
    %10 = vm.xor.i32 %ult, %c1 : i32
    %11 = vm.sub.i64 %zero_2, %0 : i64
    %12 = vm.sub.i64 %0, %c1_1 : i64
    %13 = vm.select.i64 %10, %11, %12 : i64
    %14 = vm.div.i64.s %13, %c32_0 : i64
    %15 = vm.sub.i64 %zero_2, %14 : i64
    %16 = vm.add.i64 %14, %c1_1 : i64
    %17 = vm.select.i64 %10, %15, %16 : i64
    %18 = vm.trunc.i64.i32 %17 : i64 -> i32
    vm.call.variadic @hal.command_buffer.dispatch(%ref_8, %__device_0_executable_0_foo_dispatch_0, %zero, %18, %c1, %c1, %zero_2, [%4, %6, %7, %9], [(%zero, %zero, %ref, %zero_2, %1), (%zero, %zero, %ref_5, %zero_2, %3), (%zero, %zero, %ref_7, %zero_2, %1)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%__device_0, %c-1_3, %ref_6, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %19 = vm.call.variadic @hal.fence.await(%c-1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %19, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %1, %c553648160, %c1, [%0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %19, "failed to wait on timepoint"
  }
  vm.export @foo attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @foo(%input0: tensor<?xf32>, %input1: tensor<?xf32>) -> (%output0: tensor<?xf32>)"}, ordinal = 0 : i32}
  vm.export @__init attributes {ordinal = 1 : i32}
  vm.func private @__init() attributes {ordinal = 1 : i32} {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c-1 = vm.const.i64 -1
    %c14 = vm.const.i32 14
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C1DCB7DBC4F49AE6 = vm.const.ref.rodata @_utf8_hal_device_id_C1DCB7DBC4F49AE6 : !vm.buffer
    %_utf8_cuda_EC9D846C9E731CDE = vm.const.ref.rodata @_utf8_cuda_EC9D846C9E731CDE : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C1DCB7DBC4F49AE6, %_utf8_cuda_EC9D846C9E731CDE) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22cuda\22, [#hal.executable.target<\22cuda\22, \22cuda-nvptx-fb\22, {iree.gpu.target = #iree_gpu.target<arch = \22sm_86\22, features = \22+ptx76\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<WMMA_F32_16x16x16_F16>, <WMMA_F16_16x16x16_F16>], subgroup_size_choices = [32], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 166912, max_workgroup_counts = [2147483647, 65535, 65535]>>}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_EAB228F999C2D3A1_5 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_EAB228F999C2D3A1_5, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %foo_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @foo_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_6, %foo_dispatch_0_cuda_nvptx_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_foo_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `foo_dispatch_0`; available formats: [cuda-nvptx-fb]"
  }
}

